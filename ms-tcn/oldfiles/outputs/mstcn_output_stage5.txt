cuda
MultiStageTCN
Finish Load the Training data and labels!!!
--- 8.23023509979248 seconds ---
batch_number = 10, loss = 21.128753, acc = 0.051069
--- 15.79143500328064 seconds ---
batch_number = 20, loss = 20.376362, acc = 0.080517
--- 23.31996989250183 seconds ---
batch_number = 30, loss = 19.600841, acc = 0.091524
--- 33.15527892112732 seconds ---
batch_number = 40, loss = 18.885446, acc = 0.102420
--- 43.207794189453125 seconds ---
batch_number = 50, loss = 18.328626, acc = 0.119317
--- 51.78442692756653 seconds ---
batch_number = 60, loss = 17.988094, acc = 0.123835
--- 60.37685012817383 seconds ---
batch_number = 70, loss = 17.615556, acc = 0.124424
--- 68.29560995101929 seconds ---
batch_number = 80, loss = 17.337713, acc = 0.128386
--- 77.43857479095459 seconds ---
batch_number = 90, loss = 17.083638, acc = 0.136854
--- 86.15621089935303 seconds ---
batch_number = 100, loss = 16.852159, acc = 0.148160
--- 94.63039255142212 seconds ---
batch_number = 110, loss = 16.618503, acc = 0.152754
--- 102.21092057228088 seconds ---
batch_number = 120, loss = 16.399289, acc = 0.157097
--- 111.61987137794495 seconds ---
batch_number = 130, loss = 16.133133, acc = 0.169299
--- 120.71854329109192 seconds ---
batch_number = 140, loss = 15.930147, acc = 0.176936
--- 129.4126741886139 seconds ---
batch_number = 150, loss = 15.737796, acc = 0.182101
--- 137.84994792938232 seconds ---
batch_number = 160, loss = 15.555596, acc = 0.186934
[epoch 1]: train_loss = 1.951820, train_acc = 0.189532, validation_loss = 11.459836, validation_acc = 0.373268
--- 154.31246542930603 seconds ---
batch_number = 10, loss = 11.618680, acc = 0.233856
--- 162.37138748168945 seconds ---
batch_number = 20, loss = 12.275738, acc = 0.243330
--- 172.03468823432922 seconds ---
batch_number = 30, loss = 12.135994, acc = 0.267087
--- 179.86645770072937 seconds ---
batch_number = 40, loss = 12.205279, acc = 0.262441
--- 187.8291370868683 seconds ---
batch_number = 50, loss = 12.212035, acc = 0.267423
--- 197.17899680137634 seconds ---
batch_number = 60, loss = 12.118908, acc = 0.279165
--- 207.61387085914612 seconds ---
batch_number = 70, loss = 11.968674, acc = 0.285640
--- 216.2301788330078 seconds ---
batch_number = 80, loss = 11.898418, acc = 0.288526
--- 224.0334198474884 seconds ---
batch_number = 90, loss = 11.858170, acc = 0.283565
--- 233.67954325675964 seconds ---
batch_number = 100, loss = 11.816131, acc = 0.287922
--- 241.5081603527069 seconds ---
batch_number = 110, loss = 11.777124, acc = 0.289302
--- 249.71961498260498 seconds ---
batch_number = 120, loss = 11.767757, acc = 0.290353
--- 258.3771822452545 seconds ---
batch_number = 130, loss = 11.714581, acc = 0.291634
--- 267.2318444252014 seconds ---
batch_number = 140, loss = 11.637009, acc = 0.292230
--- 276.05201172828674 seconds ---
batch_number = 150, loss = 11.607399, acc = 0.294751
--- 284.45796728134155 seconds ---
batch_number = 160, loss = 11.600717, acc = 0.297860
[epoch 2]: train_loss = 1.464723, train_acc = 0.301342, validation_loss = 10.344071, validation_acc = 0.435887
--- 301.5593786239624 seconds ---
batch_number = 10, loss = 10.171184, acc = 0.331835
--- 310.2084445953369 seconds ---
batch_number = 20, loss = 10.551574, acc = 0.335167
--- 319.2305386066437 seconds ---
batch_number = 30, loss = 10.713810, acc = 0.341780
--- 329.36861848831177 seconds ---
batch_number = 40, loss = 10.518949, acc = 0.366721
--- 336.3761820793152 seconds ---
batch_number = 50, loss = 10.636139, acc = 0.366159
--- 346.5876519680023 seconds ---
batch_number = 60, loss = 10.520193, acc = 0.375394
--- 354.0367383956909 seconds ---
batch_number = 70, loss = 10.612339, acc = 0.366972
--- 362.29112815856934 seconds ---
batch_number = 80, loss = 10.563202, acc = 0.365688
--- 369.4186499118805 seconds ---
batch_number = 90, loss = 10.483274, acc = 0.366563
--- 378.3124969005585 seconds ---
batch_number = 100, loss = 10.363563, acc = 0.368261
--- 386.64105200767517 seconds ---
batch_number = 110, loss = 10.250438, acc = 0.374820
--- 395.13623237609863 seconds ---
batch_number = 120, loss = 10.162811, acc = 0.378170
--- 402.96241092681885 seconds ---
batch_number = 130, loss = 10.094433, acc = 0.379221
--- 412.63357639312744 seconds ---
batch_number = 140, loss = 10.074432, acc = 0.383416
--- 421.9673762321472 seconds ---
batch_number = 150, loss = 10.055101, acc = 0.382115
--- 430.96098351478577 seconds ---
batch_number = 160, loss = 9.973692, acc = 0.383569
[epoch 3]: train_loss = 1.286915, train_acc = 0.379050, validation_loss = 9.535649, validation_acc = 0.425164
--- 450.2511944770813 seconds ---
batch_number = 10, loss = 9.383180, acc = 0.350802
--- 459.0840449333191 seconds ---
batch_number = 20, loss = 9.587245, acc = 0.369180
--- 467.83699798583984 seconds ---
batch_number = 30, loss = 10.097918, acc = 0.343814
--- 476.82536220550537 seconds ---
batch_number = 40, loss = 9.856194, acc = 0.357673
--- 485.4924759864807 seconds ---
batch_number = 50, loss = 9.769533, acc = 0.366508
--- 494.52689266204834 seconds ---
batch_number = 60, loss = 9.657987, acc = 0.386252
--- 502.817745923996 seconds ---
batch_number = 70, loss = 9.695632, acc = 0.389935
--- 511.27039313316345 seconds ---
batch_number = 80, loss = 9.690823, acc = 0.390708
--- 520.280880689621 seconds ---
batch_number = 90, loss = 9.665523, acc = 0.392197
--- 528.7260782718658 seconds ---
batch_number = 100, loss = 9.651779, acc = 0.392764
--- 537.4993016719818 seconds ---
batch_number = 110, loss = 9.651859, acc = 0.393796
--- 545.658933877945 seconds ---
batch_number = 120, loss = 9.580275, acc = 0.400497
--- 554.3716938495636 seconds ---
batch_number = 130, loss = 9.499077, acc = 0.404407
--- 563.088342666626 seconds ---
batch_number = 140, loss = 9.424430, acc = 0.406253
--- 571.3415906429291 seconds ---
batch_number = 150, loss = 9.360721, acc = 0.407132
--- 579.0265281200409 seconds ---
batch_number = 160, loss = 9.348524, acc = 0.407985
[epoch 4]: train_loss = 1.186783, train_acc = 0.407327, validation_loss = 8.898662, validation_acc = 0.448962
--- 595.3807199001312 seconds ---
batch_number = 10, loss = 8.426183, acc = 0.464922
--- 603.5459034442902 seconds ---
batch_number = 20, loss = 8.793294, acc = 0.449498
--- 612.0832595825195 seconds ---
batch_number = 30, loss = 8.869913, acc = 0.423917
--- 621.5780215263367 seconds ---
batch_number = 40, loss = 8.874289, acc = 0.437516
--- 631.0128712654114 seconds ---
batch_number = 50, loss = 8.793481, acc = 0.448049
--- 639.6732311248779 seconds ---
batch_number = 60, loss = 8.819662, acc = 0.442689
--- 649.3016130924225 seconds ---
batch_number = 70, loss = 8.810466, acc = 0.446248
--- 657.8764843940735 seconds ---
batch_number = 80, loss = 8.744281, acc = 0.449069
--- 665.5366652011871 seconds ---
batch_number = 90, loss = 8.697871, acc = 0.451081
--- 673.9575679302216 seconds ---
batch_number = 100, loss = 8.685838, acc = 0.450783
--- 683.5157468318939 seconds ---
batch_number = 110, loss = 8.584050, acc = 0.463899
--- 692.056990146637 seconds ---
batch_number = 120, loss = 8.542211, acc = 0.468295
--- 699.6826136112213 seconds ---
batch_number = 130, loss = 8.654034, acc = 0.463505
--- 707.2016170024872 seconds ---
batch_number = 140, loss = 8.608006, acc = 0.463737
--- 716.600387096405 seconds ---
batch_number = 150, loss = 8.620919, acc = 0.463846
--- 724.6633458137512 seconds ---
batch_number = 160, loss = 8.642035, acc = 0.464124
[epoch 5]: train_loss = 1.089213, train_acc = 0.464563, validation_loss = 7.701578, validation_acc = 0.563412
--- 741.681633234024 seconds ---
batch_number = 10, loss = 6.727956, acc = 0.544043
--- 750.667959690094 seconds ---
batch_number = 20, loss = 7.133977, acc = 0.524164
--- 759.752140045166 seconds ---
batch_number = 30, loss = 7.490811, acc = 0.506995
--- 768.754403591156 seconds ---
batch_number = 40, loss = 7.351666, acc = 0.526520
--- 775.4076426029205 seconds ---
batch_number = 50, loss = 7.457126, acc = 0.525726
--- 786.2945713996887 seconds ---
batch_number = 60, loss = 7.318888, acc = 0.536321
--- 794.145758152008 seconds ---
batch_number = 70, loss = 7.294818, acc = 0.546036
--- 803.4048128128052 seconds ---
batch_number = 80, loss = 7.253847, acc = 0.547904
--- 811.0259981155396 seconds ---
batch_number = 90, loss = 7.318960, acc = 0.547203
--- 818.4231150150299 seconds ---
batch_number = 100, loss = 7.519872, acc = 0.540824
--- 827.5427708625793 seconds ---
batch_number = 110, loss = 7.550960, acc = 0.541645
--- 835.8869142532349 seconds ---
batch_number = 120, loss = 7.673538, acc = 0.538057
--- 844.4676339626312 seconds ---
batch_number = 130, loss = 7.703505, acc = 0.533120
--- 853.026002407074 seconds ---
batch_number = 140, loss = 7.728161, acc = 0.533056
--- 860.4078600406647 seconds ---
batch_number = 150, loss = 7.773503, acc = 0.530818
--- 869.2704567909241 seconds ---
batch_number = 160, loss = 7.787288, acc = 0.529686
[epoch 6]: train_loss = 0.981495, train_acc = 0.532815, validation_loss = 6.819380, validation_acc = 0.621245
--- 887.0632228851318 seconds ---
batch_number = 10, loss = 6.821979, acc = 0.554085
--- 894.5023159980774 seconds ---
batch_number = 20, loss = 6.978619, acc = 0.561858
--- 901.9623110294342 seconds ---
batch_number = 30, loss = 7.089308, acc = 0.570813
--- 910.1591401100159 seconds ---
batch_number = 40, loss = 7.103425, acc = 0.576159
--- 918.7562665939331 seconds ---
batch_number = 50, loss = 7.046887, acc = 0.575587
--- 928.4200282096863 seconds ---
batch_number = 60, loss = 7.060544, acc = 0.572940
--- 938.4687933921814 seconds ---
batch_number = 70, loss = 6.951190, acc = 0.578463
--- 946.1762700080872 seconds ---
batch_number = 80, loss = 6.969141, acc = 0.578522
--- 953.0613346099854 seconds ---
batch_number = 90, loss = 7.177449, acc = 0.572738
--- 961.9353609085083 seconds ---
batch_number = 100, loss = 7.245223, acc = 0.568904
--- 970.8704364299774 seconds ---
batch_number = 110, loss = 7.255522, acc = 0.569178
--- 980.0938990116119 seconds ---
batch_number = 120, loss = 7.223876, acc = 0.571707
--- 988.3295764923096 seconds ---
batch_number = 130, loss = 7.315747, acc = 0.571045
--- 996.2213697433472 seconds ---
batch_number = 140, loss = 7.385860, acc = 0.568413
--- 1005.6752710342407 seconds ---
batch_number = 150, loss = 7.435642, acc = 0.565748
--- 1014.3934638500214 seconds ---
batch_number = 160, loss = 7.480473, acc = 0.564834
[epoch 7]: train_loss = 0.947470, train_acc = 0.562862, validation_loss = 6.969255, validation_acc = 0.600571
--- 1030.9960670471191 seconds ---
batch_number = 10, loss = 6.355350, acc = 0.586993
--- 1039.227279663086 seconds ---
batch_number = 20, loss = 6.673581, acc = 0.580154
--- 1049.0885965824127 seconds ---
batch_number = 30, loss = 6.701044, acc = 0.597638
--- 1058.011601448059 seconds ---
batch_number = 40, loss = 6.743427, acc = 0.602927
--- 1067.433892250061 seconds ---
batch_number = 50, loss = 6.705045, acc = 0.606306
--- 1077.2486689090729 seconds ---
batch_number = 60, loss = 6.631623, acc = 0.611466
--- 1086.0189170837402 seconds ---
batch_number = 70, loss = 6.828779, acc = 0.599025
--- 1093.4263842105865 seconds ---
batch_number = 80, loss = 6.933494, acc = 0.595789
--- 1101.4966084957123 seconds ---
batch_number = 90, loss = 7.135857, acc = 0.589156
--- 1109.8382415771484 seconds ---
batch_number = 100, loss = 7.137482, acc = 0.589867
--- 1117.7169485092163 seconds ---
batch_number = 110, loss = 7.186297, acc = 0.585410
--- 1127.0466477870941 seconds ---
batch_number = 120, loss = 7.205461, acc = 0.580780
--- 1134.858719110489 seconds ---
batch_number = 130, loss = 7.153732, acc = 0.585035
--- 1143.0384964942932 seconds ---
batch_number = 140, loss = 7.124971, acc = 0.587637
--- 1151.0471444129944 seconds ---
batch_number = 150, loss = 7.069397, acc = 0.591250
--- 1159.9281096458435 seconds ---
batch_number = 160, loss = 7.042189, acc = 0.593110
[epoch 8]: train_loss = 0.886741, train_acc = 0.594662, validation_loss = 6.186022, validation_acc = 0.640835
--- 1177.033987045288 seconds ---
batch_number = 10, loss = 5.447172, acc = 0.672946
--- 1185.4406342506409 seconds ---
batch_number = 20, loss = 5.784284, acc = 0.665029
--- 1193.9308502674103 seconds ---
batch_number = 30, loss = 5.660849, acc = 0.679849
--- 1203.5937299728394 seconds ---
batch_number = 40, loss = 5.721710, acc = 0.680570
--- 1211.9519438743591 seconds ---
batch_number = 50, loss = 5.909652, acc = 0.676230
--- 1220.4715962409973 seconds ---
batch_number = 60, loss = 6.149812, acc = 0.659498
--- 1228.6094055175781 seconds ---
batch_number = 70, loss = 6.166434, acc = 0.659264
--- 1236.710703611374 seconds ---
batch_number = 80, loss = 6.201847, acc = 0.658461
--- 1246.1758959293365 seconds ---
batch_number = 90, loss = 6.256185, acc = 0.652513
--- 1254.70570063591 seconds ---
batch_number = 100, loss = 6.309662, acc = 0.649345
--- 1265.1316885948181 seconds ---
batch_number = 110, loss = 6.267240, acc = 0.653221
--- 1273.7013964653015 seconds ---
batch_number = 120, loss = 6.257088, acc = 0.655025
--- 1281.2877743244171 seconds ---
batch_number = 130, loss = 6.250682, acc = 0.656281
--- 1288.9221670627594 seconds ---
batch_number = 140, loss = 6.225290, acc = 0.657035
--- 1297.3229765892029 seconds ---
batch_number = 150, loss = 6.222004, acc = 0.657022
--- 1304.720281124115 seconds ---
batch_number = 160, loss = 6.247073, acc = 0.653304
[epoch 9]: train_loss = 0.791472, train_acc = 0.651402, validation_loss = 5.973649, validation_acc = 0.643554
--- 1322.6340816020966 seconds ---
batch_number = 10, loss = 5.332496, acc = 0.684580
--- 1331.0670924186707 seconds ---
batch_number = 20, loss = 6.131217, acc = 0.648578
--- 1340.3877885341644 seconds ---
batch_number = 30, loss = 6.309343, acc = 0.651769
--- 1347.7890920639038 seconds ---
batch_number = 40, loss = 6.332402, acc = 0.643041
--- 1355.8917047977448 seconds ---
batch_number = 50, loss = 6.236406, acc = 0.648448
--- 1364.3254978656769 seconds ---
batch_number = 60, loss = 6.435675, acc = 0.647300
--- 1372.8958430290222 seconds ---
batch_number = 70, loss = 6.720775, acc = 0.635633
--- 1380.3163709640503 seconds ---
batch_number = 80, loss = 6.740224, acc = 0.636998
--- 1388.4328916072845 seconds ---
batch_number = 90, loss = 6.725794, acc = 0.638997
--- 1397.558687210083 seconds ---
batch_number = 100, loss = 6.755242, acc = 0.641804
--- 1406.7681102752686 seconds ---
batch_number = 110, loss = 6.775878, acc = 0.640327
--- 1413.6981310844421 seconds ---
batch_number = 120, loss = 6.793324, acc = 0.640761
--- 1424.7498486042023 seconds ---
batch_number = 130, loss = 6.765807, acc = 0.643464
--- 1434.013967037201 seconds ---
batch_number = 140, loss = 6.699004, acc = 0.648009
--- 1441.0497965812683 seconds ---
batch_number = 150, loss = 6.660688, acc = 0.650102
--- 1450.9786989688873 seconds ---
batch_number = 160, loss = 6.660586, acc = 0.651065
[epoch 10]: train_loss = 0.841732, train_acc = 0.651414, validation_loss = 5.973301, validation_acc = 0.673662
--- 1468.3482749462128 seconds ---
batch_number = 10, loss = 6.136045, acc = 0.637584
--- 1476.2547421455383 seconds ---
batch_number = 20, loss = 6.519081, acc = 0.637491
--- 1485.1061675548553 seconds ---
batch_number = 30, loss = 6.825870, acc = 0.624964
--- 1494.563658952713 seconds ---
batch_number = 40, loss = 6.641240, acc = 0.634804
--- 1505.0040633678436 seconds ---
batch_number = 50, loss = 6.594215, acc = 0.639149
--- 1513.0128037929535 seconds ---
batch_number = 60, loss = 6.827207, acc = 0.627602
--- 1522.8531296253204 seconds ---
batch_number = 70, loss = 6.758904, acc = 0.637803
--- 1529.5667045116425 seconds ---
batch_number = 80, loss = 6.672457, acc = 0.640802
--- 1538.518094778061 seconds ---
batch_number = 90, loss = 6.584659, acc = 0.645305
--- 1548.629071712494 seconds ---
batch_number = 100, loss = 6.420548, acc = 0.654723
--- 1556.9733064174652 seconds ---
batch_number = 110, loss = 6.343181, acc = 0.657311
--- 1564.9810223579407 seconds ---
batch_number = 120, loss = 6.312919, acc = 0.657384
--- 1572.0452373027802 seconds ---
batch_number = 130, loss = 6.343120, acc = 0.655148
--- 1580.692477941513 seconds ---
batch_number = 140, loss = 6.352060, acc = 0.657425
--- 1590.6486341953278 seconds ---
batch_number = 150, loss = 6.348896, acc = 0.659179
--- 1597.943969488144 seconds ---
batch_number = 160, loss = 6.334200, acc = 0.659660
[epoch 11]: train_loss = 0.799130, train_acc = 0.661336, validation_loss = 5.584291, validation_acc = 0.695893
--- 1614.3755884170532 seconds ---
batch_number = 10, loss = 4.380053, acc = 0.759829
--- 1622.4010601043701 seconds ---
batch_number = 20, loss = 4.980372, acc = 0.726736
--- 1632.5113554000854 seconds ---
batch_number = 30, loss = 4.940001, acc = 0.736904
--- 1640.4919052124023 seconds ---
batch_number = 40, loss = 5.273575, acc = 0.727994
--- 1647.4621765613556 seconds ---
batch_number = 50, loss = 5.425430, acc = 0.712809
--- 1655.9780898094177 seconds ---
batch_number = 60, loss = 5.467125, acc = 0.711762
--- 1663.8848061561584 seconds ---
batch_number = 70, loss = 5.524135, acc = 0.707886
--- 1673.347591161728 seconds ---
batch_number = 80, loss = 5.491296, acc = 0.708780
--- 1682.7155904769897 seconds ---
batch_number = 90, loss = 5.512508, acc = 0.706922
--- 1692.311295747757 seconds ---
batch_number = 100, loss = 5.499320, acc = 0.707838
--- 1701.075275182724 seconds ---
batch_number = 110, loss = 5.506727, acc = 0.706512
--- 1708.098828792572 seconds ---
batch_number = 120, loss = 5.502085, acc = 0.707132
--- 1716.3208649158478 seconds ---
batch_number = 130, loss = 5.447371, acc = 0.711320
--- 1725.450148820877 seconds ---
batch_number = 140, loss = 5.459344, acc = 0.712120
--- 1735.1192507743835 seconds ---
batch_number = 150, loss = 5.426953, acc = 0.716112
--- 1741.897143125534 seconds ---
batch_number = 160, loss = 5.511865, acc = 0.710582
[epoch 12]: train_loss = 0.700969, train_acc = 0.709085, validation_loss = 5.068005, validation_acc = 0.699358
--- 1757.5872523784637 seconds ---
batch_number = 10, loss = 4.910032, acc = 0.686315
--- 1766.7395832538605 seconds ---
batch_number = 20, loss = 4.944975, acc = 0.726736
--- 1774.7359759807587 seconds ---
batch_number = 30, loss = 4.915443, acc = 0.736715
--- 1783.677143573761 seconds ---
batch_number = 40, loss = 4.865814, acc = 0.745460
--- 1795.0778250694275 seconds ---
batch_number = 50, loss = 4.843353, acc = 0.749195
--- 1802.4287447929382 seconds ---
batch_number = 60, loss = 4.850090, acc = 0.753056
--- 1810.6033582687378 seconds ---
batch_number = 70, loss = 4.844407, acc = 0.752588
--- 1819.5702407360077 seconds ---
batch_number = 80, loss = 4.869395, acc = 0.753291
--- 1828.3560361862183 seconds ---
batch_number = 90, loss = 4.890841, acc = 0.752911
--- 1837.4519460201263 seconds ---
batch_number = 100, loss = 4.938439, acc = 0.750878
--- 1846.48557138443 seconds ---
batch_number = 110, loss = 4.901542, acc = 0.753325
--- 1856.3382546901703 seconds ---
batch_number = 120, loss = 4.872847, acc = 0.754632
--- 1865.0854578018188 seconds ---
batch_number = 130, loss = 4.829772, acc = 0.757313
--- 1872.7206707000732 seconds ---
batch_number = 140, loss = 4.834916, acc = 0.756903
--- 1880.97327876091 seconds ---
batch_number = 150, loss = 4.817789, acc = 0.757502
--- 1890.6359612941742 seconds ---
batch_number = 160, loss = 4.781218, acc = 0.759676
[epoch 13]: train_loss = 0.609108, train_acc = 0.759967, validation_loss = 9.030828, validation_acc = 0.635111
--- 1908.1668758392334 seconds ---
batch_number = 10, loss = 5.604958, acc = 0.719017
--- 1916.087325811386 seconds ---
batch_number = 20, loss = 5.797192, acc = 0.707538
--- 1925.3749947547913 seconds ---
batch_number = 30, loss = 6.021812, acc = 0.695148
--- 1934.1617369651794 seconds ---
batch_number = 40, loss = 5.979260, acc = 0.705493
--- 1941.8041198253632 seconds ---
batch_number = 50, loss = 6.158565, acc = 0.696708
--- 1950.2592532634735 seconds ---
batch_number = 60, loss = 6.053114, acc = 0.703727
--- 1957.2706756591797 seconds ---
batch_number = 70, loss = 6.028830, acc = 0.705572
--- 1966.2892444133759 seconds ---
batch_number = 80, loss = 5.915287, acc = 0.711063
--- 1974.6822936534882 seconds ---
batch_number = 90, loss = 5.973240, acc = 0.709882
--- 1982.6987063884735 seconds ---
batch_number = 100, loss = 6.015369, acc = 0.709561
--- 1991.6961846351624 seconds ---
batch_number = 110, loss = 5.993639, acc = 0.710312
--- 2000.6331667900085 seconds ---
batch_number = 120, loss = 5.963586, acc = 0.711512
--- 2010.3285884857178 seconds ---
batch_number = 130, loss = 5.876641, acc = 0.715272
--- 2018.5092768669128 seconds ---
batch_number = 140, loss = 5.794160, acc = 0.719576
--- 2027.4097354412079 seconds ---
batch_number = 150, loss = 5.736503, acc = 0.722987
--- 2036.3281247615814 seconds ---
batch_number = 160, loss = 5.668059, acc = 0.726847
[epoch 14]: train_loss = 0.710844, train_acc = 0.728398, validation_loss = 5.007095, validation_acc = 0.745458
--- 2054.1008625030518 seconds ---
batch_number = 10, loss = 4.218449, acc = 0.792631
--- 2061.0436639785767 seconds ---
batch_number = 20, loss = 4.670131, acc = 0.769683
--- 2070.1026742458344 seconds ---
batch_number = 30, loss = 4.756893, acc = 0.768391
--- 2078.773610830307 seconds ---
batch_number = 40, loss = 4.817038, acc = 0.761252
--- 2088.7671132087708 seconds ---
batch_number = 50, loss = 4.767347, acc = 0.770031
--- 2097.869768381119 seconds ---
batch_number = 60, loss = 4.675912, acc = 0.777672
--- 2106.406455039978 seconds ---
batch_number = 70, loss = 4.674833, acc = 0.778700
--- 2113.132227897644 seconds ---
batch_number = 80, loss = 4.674712, acc = 0.779912
--- 2123.2198462486267 seconds ---
batch_number = 90, loss = 4.666900, acc = 0.779826
--- 2133.920635700226 seconds ---
batch_number = 100, loss = 4.648725, acc = 0.781611
--- 2142.247959136963 seconds ---
batch_number = 110, loss = 4.808900, acc = 0.774625
--- 2148.9116353988647 seconds ---
batch_number = 120, loss = 4.952335, acc = 0.766747
--- 2158.255598306656 seconds ---
batch_number = 130, loss = 4.950991, acc = 0.767533
--- 2167.1461403369904 seconds ---
batch_number = 140, loss = 4.921480, acc = 0.767861
--- 2175.4375863075256 seconds ---
batch_number = 150, loss = 4.893015, acc = 0.769544
--- 2184.4904215335846 seconds ---
batch_number = 160, loss = 4.882627, acc = 0.769543
[epoch 15]: train_loss = 0.621597, train_acc = 0.767753, validation_loss = 4.704169, validation_acc = 0.766621
--- 2200.8021483421326 seconds ---
batch_number = 10, loss = 4.129975, acc = 0.795162
--- 2209.2020993232727 seconds ---
batch_number = 20, loss = 5.881992, acc = 0.723883
--- 2217.786737203598 seconds ---
batch_number = 30, loss = 6.213246, acc = 0.704678
--- 2226.499094247818 seconds ---
batch_number = 40, loss = 6.078645, acc = 0.713250
--- 2234.949810028076 seconds ---
batch_number = 50, loss = 5.812144, acc = 0.723323
--- 2244.2623784542084 seconds ---
batch_number = 60, loss = 5.678963, acc = 0.733102
--- 2251.7197349071503 seconds ---
batch_number = 70, loss = 5.510652, acc = 0.740878
--- 2261.0726799964905 seconds ---
batch_number = 80, loss = 5.383926, acc = 0.749838
--- 2267.389842271805 seconds ---
batch_number = 90, loss = 5.299392, acc = 0.754531
--- 2275.915603160858 seconds ---
batch_number = 100, loss = 5.266382, acc = 0.756528
--- 2285.9477570056915 seconds ---
batch_number = 110, loss = 5.186116, acc = 0.761149
--- 2294.7332108020782 seconds ---
batch_number = 120, loss = 5.103973, acc = 0.764305
--- 2303.661021232605 seconds ---
batch_number = 130, loss = 5.022300, acc = 0.769293
--- 2313.5391523838043 seconds ---
batch_number = 140, loss = 4.932709, acc = 0.774910
--- 2321.8008828163147 seconds ---
batch_number = 150, loss = 4.914423, acc = 0.774759
--- 2330.854420185089 seconds ---
batch_number = 160, loss = 4.861782, acc = 0.777862
[epoch 16]: train_loss = 0.611015, train_acc = 0.778942, validation_loss = 4.338307, validation_acc = 0.780894
--- 2347.202629327774 seconds ---
batch_number = 10, loss = 3.802332, acc = 0.837094
--- 2354.458309650421 seconds ---
batch_number = 20, loss = 4.097350, acc = 0.819818
--- 2362.7081096172333 seconds ---
batch_number = 30, loss = 4.299805, acc = 0.807968
--- 2371.1937940120697 seconds ---
batch_number = 40, loss = 4.494649, acc = 0.797356
--- 2380.4581422805786 seconds ---
batch_number = 50, loss = 4.849832, acc = 0.776480
--- 2390.0763609409332 seconds ---
batch_number = 60, loss = 4.952349, acc = 0.765426
--- 2399.256801366806 seconds ---
batch_number = 70, loss = 5.036225, acc = 0.755898
--- 2406.1811079978943 seconds ---
batch_number = 80, loss = 5.004838, acc = 0.759074
--- 2414.2918031215668 seconds ---
batch_number = 90, loss = 4.962791, acc = 0.760259
--- 2423.386774301529 seconds ---
batch_number = 100, loss = 4.919797, acc = 0.763692
--- 2431.452019929886 seconds ---
batch_number = 110, loss = 4.869064, acc = 0.767721
--- 2439.9549112319946 seconds ---
batch_number = 120, loss = 4.832993, acc = 0.771979
--- 2447.585943222046 seconds ---
batch_number = 130, loss = 4.802497, acc = 0.774290
--- 2456.5792622566223 seconds ---
batch_number = 140, loss = 4.747819, acc = 0.777449
--- 2466.7679493427277 seconds ---
batch_number = 150, loss = 4.705171, acc = 0.781413
--- 2475.5118494033813 seconds ---
batch_number = 160, loss = 4.665030, acc = 0.785285
[epoch 17]: train_loss = 0.586707, train_acc = 0.786622, validation_loss = 4.158015, validation_acc = 0.788172
--- 2491.83208155632 seconds ---
batch_number = 10, loss = 3.234470, acc = 0.853802
--- 2500.8509328365326 seconds ---
batch_number = 20, loss = 3.457669, acc = 0.850234
--- 2508.7888491153717 seconds ---
batch_number = 30, loss = 3.683118, acc = 0.842356
--- 2518.4820387363434 seconds ---
batch_number = 40, loss = 3.646588, acc = 0.845166
--- 2525.5975761413574 seconds ---
batch_number = 50, loss = 3.703673, acc = 0.843565
--- 2534.831257581711 seconds ---
batch_number = 60, loss = 3.762070, acc = 0.841333
--- 2543.80171585083 seconds ---
batch_number = 70, loss = 3.802592, acc = 0.838260
--- 2552.4524426460266 seconds ---
batch_number = 80, loss = 3.774058, acc = 0.842220
--- 2560.562824487686 seconds ---
batch_number = 90, loss = 3.802541, acc = 0.840412
--- 2569.1068000793457 seconds ---
batch_number = 100, loss = 3.833289, acc = 0.838207
--- 2577.215748310089 seconds ---
batch_number = 110, loss = 3.851674, acc = 0.837708
--- 2586.7568821907043 seconds ---
batch_number = 120, loss = 3.849470, acc = 0.838281
--- 2595.45432305336 seconds ---
batch_number = 130, loss = 3.834837, acc = 0.838921
--- 2604.114548444748 seconds ---
batch_number = 140, loss = 3.861134, acc = 0.837717
--- 2611.714462995529 seconds ---
batch_number = 150, loss = 3.933137, acc = 0.835349
--- 2619.952621459961 seconds ---
batch_number = 160, loss = 3.976431, acc = 0.832765
[epoch 18]: train_loss = 0.504272, train_acc = 0.832737, validation_loss = 4.602469, validation_acc = 0.778217
--- 2636.2661838531494 seconds ---
batch_number = 10, loss = 3.706644, acc = 0.815097
--- 2645.490310192108 seconds ---
batch_number = 20, loss = 3.801163, acc = 0.825383
--- 2654.2571523189545 seconds ---
batch_number = 30, loss = 3.865715, acc = 0.829944
--- 2662.0707738399506 seconds ---
batch_number = 40, loss = 3.905452, acc = 0.829908
--- 2671.091776609421 seconds ---
batch_number = 50, loss = 3.884202, acc = 0.828729
--- 2679.7582578659058 seconds ---
batch_number = 60, loss = 3.855302, acc = 0.833300
--- 2687.4504039287567 seconds ---
batch_number = 70, loss = 3.818676, acc = 0.836387
--- 2695.0071086883545 seconds ---
batch_number = 80, loss = 3.873501, acc = 0.835242
--- 2702.033695936203 seconds ---
batch_number = 90, loss = 3.919651, acc = 0.833889
--- 2710.940459251404 seconds ---
batch_number = 100, loss = 3.933137, acc = 0.833907
--- 2719.3523349761963 seconds ---
batch_number = 110, loss = 3.949781, acc = 0.833416
--- 2728.561832666397 seconds ---
batch_number = 120, loss = 3.957179, acc = 0.831273
--- 2737.232288837433 seconds ---
batch_number = 130, loss = 3.948078, acc = 0.831784
--- 2745.894950389862 seconds ---
batch_number = 140, loss = 3.942463, acc = 0.833452
--- 2755.176604986191 seconds ---
batch_number = 150, loss = 3.932493, acc = 0.834622
--- 2764.1571118831635 seconds ---
batch_number = 160, loss = 3.948289, acc = 0.834235
[epoch 19]: train_loss = 0.500939, train_acc = 0.834360, validation_loss = 3.958616, validation_acc = 0.808029
--- 2780.7509405612946 seconds ---
batch_number = 10, loss = 3.559361, acc = 0.842230
--- 2789.6348593235016 seconds ---
batch_number = 20, loss = 3.758357, acc = 0.828401
--- 2796.9875333309174 seconds ---
batch_number = 30, loss = 3.838866, acc = 0.833385
--- 2804.8464550971985 seconds ---
batch_number = 40, loss = 3.812267, acc = 0.836703
--- 2813.492746591568 seconds ---
batch_number = 50, loss = 3.731294, acc = 0.842752
--- 2821.8498969078064 seconds ---
batch_number = 60, loss = 3.704162, acc = 0.847036
--- 2830.25453042984 seconds ---
batch_number = 70, loss = 3.673337, acc = 0.848161
--- 2840.629860162735 seconds ---
batch_number = 80, loss = 3.642975, acc = 0.851323
--- 2849.3850207328796 seconds ---
batch_number = 90, loss = 3.609838, acc = 0.852385
--- 2857.8970849514008 seconds ---
batch_number = 100, loss = 3.618352, acc = 0.851942
--- 2866.947422981262 seconds ---
batch_number = 110, loss = 3.584757, acc = 0.853934
--- 2875.579219341278 seconds ---
batch_number = 120, loss = 3.554193, acc = 0.855613
--- 2883.364858865738 seconds ---
batch_number = 130, loss = 3.573317, acc = 0.854926
--- 2892.4659645557404 seconds ---
batch_number = 140, loss = 3.571757, acc = 0.855086
--- 2900.946628332138 seconds ---
batch_number = 150, loss = 3.584905, acc = 0.855137
--- 2910.304494857788 seconds ---
batch_number = 160, loss = 3.586654, acc = 0.854972
[epoch 20]: train_loss = 0.452056, train_acc = 0.855592, validation_loss = 4.055948, validation_acc = 0.807746
--- 2926.2079207897186 seconds ---
batch_number = 10, loss = 3.350289, acc = 0.863058
--- 2934.8573610782623 seconds ---
batch_number = 20, loss = 3.320225, acc = 0.870846
--- 2943.1669251918793 seconds ---
batch_number = 30, loss = 3.470649, acc = 0.857247
--- 2952.517141342163 seconds ---
batch_number = 40, loss = 3.595086, acc = 0.849412
--- 2960.0661838054657 seconds ---
batch_number = 50, loss = 3.617739, acc = 0.849968
--- 2968.0974564552307 seconds ---
batch_number = 60, loss = 3.714514, acc = 0.846396
--- 2976.229873418808 seconds ---
batch_number = 70, loss = 3.728716, acc = 0.844388
--- 2984.523205757141 seconds ---
batch_number = 80, loss = 3.705662, acc = 0.846669
--- 2991.930353164673 seconds ---
batch_number = 90, loss = 3.729688, acc = 0.848683
--- 3000.9511437416077 seconds ---
batch_number = 100, loss = 3.671893, acc = 0.852572
--- 3009.903427362442 seconds ---
batch_number = 110, loss = 3.611070, acc = 0.855771
--- 3018.6060268878937 seconds ---
batch_number = 120, loss = 3.590037, acc = 0.858117
--- 3027.723653316498 seconds ---
batch_number = 130, loss = 3.570757, acc = 0.858359
--- 3036.367354154587 seconds ---
batch_number = 140, loss = 3.559357, acc = 0.859168
--- 3045.971741437912 seconds ---
batch_number = 150, loss = 3.533687, acc = 0.860993
--- 3054.9810938835144 seconds ---
batch_number = 160, loss = 3.546916, acc = 0.860037
[epoch 21]: train_loss = 0.448788, train_acc = 0.859828, validation_loss = 4.146000, validation_acc = 0.817632
--- 3072.9951436519623 seconds ---
batch_number = 10, loss = 3.120986, acc = 0.838963
--- 3080.476007461548 seconds ---
batch_number = 20, loss = 3.308297, acc = 0.852275
--- 3089.2044372558594 seconds ---
batch_number = 30, loss = 3.343095, acc = 0.860253
--- 3097.577806711197 seconds ---
batch_number = 40, loss = 3.350246, acc = 0.863506
--- 3107.31312584877 seconds ---
batch_number = 50, loss = 3.352278, acc = 0.865207
--- 3115.2793493270874 seconds ---
batch_number = 60, loss = 3.392657, acc = 0.865613
--- 3124.1255581378937 seconds ---
batch_number = 70, loss = 3.496626, acc = 0.862255
--- 3132.892904996872 seconds ---
batch_number = 80, loss = 3.513144, acc = 0.859619
--- 3140.3640084266663 seconds ---
batch_number = 90, loss = 3.559624, acc = 0.857415
--- 3147.406068086624 seconds ---
batch_number = 100, loss = 3.699520, acc = 0.849668
--- 3155.6870172023773 seconds ---
batch_number = 110, loss = 3.746762, acc = 0.847483
--- 3163.7632772922516 seconds ---
batch_number = 120, loss = 3.974442, acc = 0.836371
--- 3172.841708421707 seconds ---
batch_number = 130, loss = 4.285217, acc = 0.819052
--- 3181.310827732086 seconds ---
batch_number = 140, loss = 4.465841, acc = 0.805768
--- 3189.0032365322113 seconds ---
batch_number = 150, loss = 4.547501, acc = 0.800823
--- 3197.8968603610992 seconds ---
batch_number = 160, loss = 4.542918, acc = 0.801347
[epoch 22]: train_loss = 0.583383, train_acc = 0.802233, validation_loss = 5.335238, validation_acc = 0.724933
--- 3214.7924089431763 seconds ---
batch_number = 10, loss = 6.238411, acc = 0.673007
--- 3222.569881439209 seconds ---
batch_number = 20, loss = 6.169670, acc = 0.699640
--- 3231.905211210251 seconds ---
batch_number = 30, loss = 5.832055, acc = 0.722094
--- 3241.0159270763397 seconds ---
batch_number = 40, loss = 5.437155, acc = 0.746281
--- 3248.1425766944885 seconds ---
batch_number = 50, loss = 5.350439, acc = 0.751658
--- 3257.4278705120087 seconds ---
batch_number = 60, loss = 5.174908, acc = 0.771488
--- 3264.939513206482 seconds ---
batch_number = 70, loss = 5.242544, acc = 0.769118
--- 3274.6075944900513 seconds ---
batch_number = 80, loss = 5.130718, acc = 0.774701
--- 3282.775239467621 seconds ---
batch_number = 90, loss = 5.095561, acc = 0.776445
--- 3290.9761328697205 seconds ---
batch_number = 100, loss = 5.064058, acc = 0.778514
--- 3299.67716050148 seconds ---
batch_number = 110, loss = 5.020251, acc = 0.779604
--- 3306.817892074585 seconds ---
batch_number = 120, loss = 5.052404, acc = 0.778888
--- 3315.976348876953 seconds ---
batch_number = 130, loss = 4.989505, acc = 0.782726
--- 3324.045159816742 seconds ---
batch_number = 140, loss = 4.967938, acc = 0.783887
--- 3335.047785282135 seconds ---
batch_number = 150, loss = 4.879036, acc = 0.790289
--- 3343.136556625366 seconds ---
batch_number = 160, loss = 4.826586, acc = 0.793933
[epoch 23]: train_loss = 0.605520, train_acc = 0.796342, validation_loss = 4.055405, validation_acc = 0.807733
--- 3359.5736021995544 seconds ---
batch_number = 10, loss = 3.161736, acc = 0.858469
--- 3367.493542432785 seconds ---
batch_number = 20, loss = 3.427720, acc = 0.852419
--- 3376.6263439655304 seconds ---
batch_number = 30, loss = 3.589183, acc = 0.853741
--- 3384.1527116298676 seconds ---
batch_number = 40, loss = 3.590391, acc = 0.855191
--- 3393.5131227970123 seconds ---
batch_number = 50, loss = 3.520707, acc = 0.861655
--- 3403.4210629463196 seconds ---
batch_number = 60, loss = 3.458679, acc = 0.865820
--- 3411.4368119239807 seconds ---
batch_number = 70, loss = 3.429513, acc = 0.868786
--- 3420.464993238449 seconds ---
batch_number = 80, loss = 3.421876, acc = 0.872207
--- 3428.9390501976013 seconds ---
batch_number = 90, loss = 3.475418, acc = 0.871054
--- 3438.0999660491943 seconds ---
batch_number = 100, loss = 3.488483, acc = 0.870440
--- 3447.0245168209076 seconds ---
batch_number = 110, loss = 3.538462, acc = 0.868654
--- 3456.3939394950867 seconds ---
batch_number = 120, loss = 3.531133, acc = 0.869233
--- 3465.70441365242 seconds ---
batch_number = 130, loss = 3.509816, acc = 0.870569
--- 3474.2642736434937 seconds ---
batch_number = 140, loss = 3.484235, acc = 0.871724
--- 3481.350956439972 seconds ---
batch_number = 150, loss = 3.476479, acc = 0.872461
--- 3489.493484735489 seconds ---
batch_number = 160, loss = 3.462593, acc = 0.872861
[epoch 24]: train_loss = 0.439624, train_acc = 0.872601, validation_loss = 3.875207, validation_acc = 0.822503
--- 3505.2608642578125 seconds ---
batch_number = 10, loss = 2.891265, acc = 0.892354
--- 3511.3498256206512 seconds ---
batch_number = 20, loss = 3.205263, acc = 0.880001
--- 3519.902039051056 seconds ---
batch_number = 30, loss = 3.143731, acc = 0.887360
--- 3529.5739257335663 seconds ---
batch_number = 40, loss = 3.111237, acc = 0.889461
--- 3538.0412685871124 seconds ---
batch_number = 50, loss = 3.073256, acc = 0.892519
--- 3545.997232437134 seconds ---
batch_number = 60, loss = 3.062448, acc = 0.893375
--- 3553.731653690338 seconds ---
batch_number = 70, loss = 3.052812, acc = 0.893747
--- 3562.8815915584564 seconds ---
batch_number = 80, loss = 3.056743, acc = 0.894560
--- 3571.8066380023956 seconds ---
batch_number = 90, loss = 3.050409, acc = 0.895431
--- 3581.1080968379974 seconds ---
batch_number = 100, loss = 3.047058, acc = 0.896274
--- 3590.0751852989197 seconds ---
batch_number = 110, loss = 3.051652, acc = 0.895795
--- 3599.175570011139 seconds ---
batch_number = 120, loss = 3.035258, acc = 0.895826
--- 3607.919060945511 seconds ---
batch_number = 130, loss = 3.019155, acc = 0.896908
--- 3616.482578277588 seconds ---
batch_number = 140, loss = 3.047199, acc = 0.895192
--- 3623.9246146678925 seconds ---
batch_number = 150, loss = 3.082092, acc = 0.893111
--- 3631.7874097824097 seconds ---
batch_number = 160, loss = 3.154503, acc = 0.889888
[epoch 25]: train_loss = 0.406756, train_acc = 0.885955, validation_loss = 4.688697, validation_acc = 0.772574
--- 3649.0140676498413 seconds ---
batch_number = 10, loss = 3.312429, acc = 0.846952
--- 3658.1644039154053 seconds ---
batch_number = 20, loss = 3.409412, acc = 0.853349
--- 3666.199548482895 seconds ---
batch_number = 30, loss = 3.410198, acc = 0.861886
--- 3674.2386586666107 seconds ---
batch_number = 40, loss = 3.364188, acc = 0.866311
--- 3681.802808046341 seconds ---
batch_number = 50, loss = 3.367220, acc = 0.865900
--- 3690.360553741455 seconds ---
batch_number = 60, loss = 3.358436, acc = 0.868882
--- 3699.2489578723907 seconds ---
batch_number = 70, loss = 3.263844, acc = 0.877295
--- 3708.0405008792877 seconds ---
batch_number = 80, loss = 3.229167, acc = 0.881215
--- 3716.6565506458282 seconds ---
batch_number = 90, loss = 3.217951, acc = 0.883002
--- 3725.3181252479553 seconds ---
batch_number = 100, loss = 3.204229, acc = 0.884238
--- 3735.057184457779 seconds ---
batch_number = 110, loss = 3.162949, acc = 0.886285
--- 3743.2581894397736 seconds ---
batch_number = 120, loss = 3.140695, acc = 0.887360
--- 3752.259031057358 seconds ---
batch_number = 130, loss = 3.115099, acc = 0.889429
--- 3762.10773563385 seconds ---
batch_number = 140, loss = 3.099697, acc = 0.890285
--- 3769.9621102809906 seconds ---
batch_number = 150, loss = 3.120699, acc = 0.889700
--- 3777.6236333847046 seconds ---
batch_number = 160, loss = 3.136485, acc = 0.889035
[epoch 26]: train_loss = 0.394772, train_acc = 0.889341, validation_loss = 3.697844, validation_acc = 0.834018
--- 3797.228546142578 seconds ---
batch_number = 10, loss = 2.447766, acc = 0.915119
--- 3807.9168186187744 seconds ---
batch_number = 20, loss = 2.553423, acc = 0.910923
--- 3814.749993801117 seconds ---
batch_number = 30, loss = 2.645875, acc = 0.910650
--- 3822.5326285362244 seconds ---
batch_number = 40, loss = 2.752229, acc = 0.905696
--- 3832.6391315460205 seconds ---
batch_number = 50, loss = 2.902514, acc = 0.898909
--- 3840.805906057358 seconds ---
batch_number = 60, loss = 3.043490, acc = 0.890143
--- 3849.1729950904846 seconds ---
batch_number = 70, loss = 3.124364, acc = 0.888842
--- 3857.565664291382 seconds ---
batch_number = 80, loss = 3.175909, acc = 0.885433
--- 3864.9635376930237 seconds ---
batch_number = 90, loss = 3.249294, acc = 0.881177
--- 3873.635423183441 seconds ---
batch_number = 100, loss = 3.550444, acc = 0.866301
--- 3880.7540419101715 seconds ---
batch_number = 110, loss = 3.821405, acc = 0.853831
--- 3890.1598455905914 seconds ---
batch_number = 120, loss = 3.958688, acc = 0.842913
--- 3899.3210315704346 seconds ---
batch_number = 130, loss = 4.059845, acc = 0.836659
--- 3906.613886833191 seconds ---
batch_number = 140, loss = 4.135375, acc = 0.833498
--- 3914.2513682842255 seconds ---
batch_number = 150, loss = 4.164555, acc = 0.831950
--- 3922.7234518527985 seconds ---
batch_number = 160, loss = 4.182782, acc = 0.832602
[epoch 27]: train_loss = 0.532995, train_acc = 0.831177, validation_loss = 7.750644, validation_acc = 0.698720
--- 3941.5917360782623 seconds ---
batch_number = 10, loss = 8.111841, acc = 0.660957
--- 3950.1907908916473 seconds ---
batch_number = 20, loss = 8.457503, acc = 0.643501
--- 3956.504964828491 seconds ---
batch_number = 30, loss = 8.167108, acc = 0.639750
--- 3965.593898296356 seconds ---
batch_number = 40, loss = 7.491776, acc = 0.663776
--- 3975.028566837311 seconds ---
batch_number = 50, loss = 6.942148, acc = 0.699396
--- 3983.9333531856537 seconds ---
batch_number = 60, loss = 6.652039, acc = 0.714896
--- 3990.727334499359 seconds ---
batch_number = 70, loss = 6.294328, acc = 0.728156
--- 4000.01650762558 seconds ---
batch_number = 80, loss = 6.062153, acc = 0.739143
--- 4008.4851830005646 seconds ---
batch_number = 90, loss = 5.876446, acc = 0.749850
--- 4016.558868408203 seconds ---
batch_number = 100, loss = 5.678747, acc = 0.761976
--- 4025.497337579727 seconds ---
batch_number = 110, loss = 5.582946, acc = 0.768707
--- 4034.383913040161 seconds ---
batch_number = 120, loss = 5.478367, acc = 0.773650
--- 4044.2434601783752 seconds ---
batch_number = 130, loss = 5.337536, acc = 0.781889
--- 4053.134938955307 seconds ---
batch_number = 140, loss = 5.307747, acc = 0.782476
--- 4062.3368213176727 seconds ---
batch_number = 150, loss = 5.239164, acc = 0.786235
--- 4070.805267095566 seconds ---
batch_number = 160, loss = 5.166307, acc = 0.789133
[epoch 28]: train_loss = 0.645797, train_acc = 0.792123, validation_loss = 4.038302, validation_acc = 0.816841
--- 4090.77232670784 seconds ---
batch_number = 10, loss = 2.993361, acc = 0.887035
--- 4099.945289611816 seconds ---
batch_number = 20, loss = 3.114626, acc = 0.881075
--- 4109.693108797073 seconds ---
batch_number = 30, loss = 3.162404, acc = 0.889432
--- 4118.899250507355 seconds ---
batch_number = 40, loss = 3.127936, acc = 0.894070
--- 4127.249396085739 seconds ---
batch_number = 50, loss = 3.129687, acc = 0.894298
--- 4134.97785115242 seconds ---
batch_number = 60, loss = 3.154155, acc = 0.892334
--- 4143.250311136246 seconds ---
batch_number = 70, loss = 3.182114, acc = 0.889751
--- 4152.061136007309 seconds ---
batch_number = 80, loss = 3.173083, acc = 0.889115
--- 4161.113948106766 seconds ---
batch_number = 90, loss = 3.178437, acc = 0.888619
--- 4169.815646409988 seconds ---
batch_number = 100, loss = 3.305979, acc = 0.883906
--- 4179.056153297424 seconds ---
batch_number = 110, loss = 3.366266, acc = 0.877329
--- 4187.762511968613 seconds ---
batch_number = 120, loss = 3.406362, acc = 0.875292
--- 4196.009142637253 seconds ---
batch_number = 130, loss = 3.410005, acc = 0.875537
--- 4204.586001157761 seconds ---
batch_number = 140, loss = 3.397760, acc = 0.876142
--- 4213.076827287674 seconds ---
batch_number = 150, loss = 3.410389, acc = 0.876274
--- 4221.453413486481 seconds ---
batch_number = 160, loss = 3.384898, acc = 0.877792
[epoch 29]: train_loss = 0.428674, train_acc = 0.877738, validation_loss = 3.749426, validation_acc = 0.838720
--- 4239.890046596527 seconds ---
batch_number = 10, loss = 2.650043, acc = 0.899858
--- 4248.205590009689 seconds ---
batch_number = 20, loss = 2.906532, acc = 0.895072
--- 4256.803024530411 seconds ---
batch_number = 30, loss = 2.969669, acc = 0.897386
--- 4264.610246181488 seconds ---
batch_number = 40, loss = 3.041373, acc = 0.896382
--- 4274.27617764473 seconds ---
batch_number = 50, loss = 3.002868, acc = 0.899862
--- 4284.034287452698 seconds ---
batch_number = 60, loss = 2.963510, acc = 0.901255
--- 4291.2923011779785 seconds ---
batch_number = 70, loss = 2.980498, acc = 0.900224
--- 4299.061309337616 seconds ---
batch_number = 80, loss = 2.979838, acc = 0.899222
--- 4307.180435419083 seconds ---
batch_number = 90, loss = 2.995321, acc = 0.900028
--- 4316.677601099014 seconds ---
batch_number = 100, loss = 2.955832, acc = 0.902078
--- 4324.264564037323 seconds ---
batch_number = 110, loss = 2.984897, acc = 0.900251
--- 4333.376477479935 seconds ---
batch_number = 120, loss = 2.965824, acc = 0.902182
--- 4341.457112073898 seconds ---
batch_number = 130, loss = 2.943822, acc = 0.903888
--- 4349.520864009857 seconds ---
batch_number = 140, loss = 2.938557, acc = 0.904995
--- 4358.442746400833 seconds ---
batch_number = 150, loss = 2.931279, acc = 0.905052
--- 4367.73423075676 seconds ---
batch_number = 160, loss = 2.911961, acc = 0.905835
[epoch 30]: train_loss = 0.368238, train_acc = 0.905431, validation_loss = 3.474797, validation_acc = 0.842543
--- 4385.567213058472 seconds ---
batch_number = 10, loss = 2.451224, acc = 0.923571
--- 4393.741324663162 seconds ---
batch_number = 20, loss = 2.546223, acc = 0.922153
--- 4403.027307033539 seconds ---
batch_number = 30, loss = 2.570847, acc = 0.924907
--- 4410.964492321014 seconds ---
batch_number = 40, loss = 2.576835, acc = 0.924719
--- 4420.392509937286 seconds ---
batch_number = 50, loss = 2.563128, acc = 0.923801
--- 4430.111829519272 seconds ---
batch_number = 60, loss = 2.520866, acc = 0.924787
--- 4440.9736914634705 seconds ---
batch_number = 70, loss = 2.512833, acc = 0.925471
--- 4450.533937692642 seconds ---
batch_number = 80, loss = 2.504228, acc = 0.926157
--- 4458.618798971176 seconds ---
batch_number = 90, loss = 2.529197, acc = 0.924964
--- 4467.044852018356 seconds ---
batch_number = 100, loss = 2.546326, acc = 0.924735
--- 4474.916837930679 seconds ---
batch_number = 110, loss = 2.569363, acc = 0.923672
--- 4482.811725616455 seconds ---
batch_number = 120, loss = 2.574931, acc = 0.923274
--- 4490.974880218506 seconds ---
batch_number = 130, loss = 2.575453, acc = 0.922580
--- 4498.8764934539795 seconds ---
batch_number = 140, loss = 2.579719, acc = 0.922311
--- 4506.523391485214 seconds ---
batch_number = 150, loss = 2.577195, acc = 0.922433
--- 4515.73632979393 seconds ---
batch_number = 160, loss = 2.577629, acc = 0.922447
[epoch 31]: train_loss = 0.325907, train_acc = 0.922448, validation_loss = 3.531130, validation_acc = 0.848157
--- 4531.561065196991 seconds ---
batch_number = 10, loss = 2.333901, acc = 0.926528
--- 4541.082209587097 seconds ---
batch_number = 20, loss = 2.339754, acc = 0.938874
--- 4549.998809337616 seconds ---
batch_number = 30, loss = 2.343266, acc = 0.935985
--- 4558.962404727936 seconds ---
batch_number = 40, loss = 2.269524, acc = 0.938099
--- 4567.179972171783 seconds ---
batch_number = 50, loss = 2.313428, acc = 0.936400
--- 4575.949089050293 seconds ---
batch_number = 60, loss = 2.355348, acc = 0.934610
--- 4584.454788684845 seconds ---
batch_number = 70, loss = 2.367144, acc = 0.933219
--- 4593.230545043945 seconds ---
batch_number = 80, loss = 2.366023, acc = 0.933309
--- 4603.990139007568 seconds ---
batch_number = 90, loss = 2.348767, acc = 0.934153
--- 4611.313100099564 seconds ---
batch_number = 100, loss = 2.367094, acc = 0.933737
--- 4619.913503885269 seconds ---
batch_number = 110, loss = 2.392549, acc = 0.933269
--- 4626.7038362026215 seconds ---
batch_number = 120, loss = 2.422128, acc = 0.931617
--- 4636.636858463287 seconds ---
batch_number = 130, loss = 2.435919, acc = 0.930837
--- 4644.568385839462 seconds ---
batch_number = 140, loss = 2.446416, acc = 0.930217
--- 4652.880753278732 seconds ---
batch_number = 150, loss = 2.456112, acc = 0.929386
--- 4660.638730764389 seconds ---
batch_number = 160, loss = 2.475661, acc = 0.928775
[epoch 32]: train_loss = 0.313805, train_acc = 0.928542, validation_loss = 3.407021, validation_acc = 0.847388
--- 4676.483279705048 seconds ---
batch_number = 10, loss = 2.061057, acc = 0.941154
--- 4685.736273527145 seconds ---
batch_number = 20, loss = 2.149302, acc = 0.938952
--- 4694.513483762741 seconds ---
batch_number = 30, loss = 2.249664, acc = 0.936712
--- 4703.768665313721 seconds ---
batch_number = 40, loss = 2.306580, acc = 0.935310
--- 4712.75430560112 seconds ---
batch_number = 50, loss = 2.310456, acc = 0.934433
--- 4720.606430053711 seconds ---
batch_number = 60, loss = 2.348210, acc = 0.932863
--- 4728.477729320526 seconds ---
batch_number = 70, loss = 2.368406, acc = 0.931149
--- 4736.646517753601 seconds ---
batch_number = 80, loss = 2.393556, acc = 0.931408
--- 4745.13890004158 seconds ---
batch_number = 90, loss = 2.401465, acc = 0.931135
--- 4754.4607882499695 seconds ---
batch_number = 100, loss = 2.403748, acc = 0.930610
--- 4762.919438123703 seconds ---
batch_number = 110, loss = 2.402058, acc = 0.930530
--- 4771.689431190491 seconds ---
batch_number = 120, loss = 2.383257, acc = 0.931112
--- 4780.443103313446 seconds ---
batch_number = 130, loss = 2.384220, acc = 0.930941
--- 4789.194216012955 seconds ---
batch_number = 140, loss = 2.382385, acc = 0.930999
--- 4797.335946559906 seconds ---
batch_number = 150, loss = 2.388190, acc = 0.930470
--- 4806.050744771957 seconds ---
batch_number = 160, loss = 2.379220, acc = 0.931132
[epoch 33]: train_loss = 0.302580, train_acc = 0.931146, validation_loss = 3.610809, validation_acc = 0.848828
--- 4823.526942253113 seconds ---
batch_number = 10, loss = 2.958261, acc = 0.900093
--- 4833.276272773743 seconds ---
batch_number = 20, loss = 3.014260, acc = 0.899798
--- 4841.455706119537 seconds ---
batch_number = 30, loss = 3.103922, acc = 0.895525
--- 4849.895133495331 seconds ---
batch_number = 40, loss = 3.130044, acc = 0.890160
--- 4857.965245246887 seconds ---
batch_number = 50, loss = 3.052155, acc = 0.894328
--- 4867.105381011963 seconds ---
batch_number = 60, loss = 3.013416, acc = 0.895842
--- 4876.398852586746 seconds ---
batch_number = 70, loss = 2.964391, acc = 0.898700
--- 4885.80589556694 seconds ---
batch_number = 80, loss = 2.913567, acc = 0.902113
--- 4893.904120206833 seconds ---
batch_number = 90, loss = 2.867593, acc = 0.904452
--- 4902.408565998077 seconds ---
batch_number = 100, loss = 2.829898, acc = 0.905876
--- 4911.534693956375 seconds ---
batch_number = 110, loss = 2.785982, acc = 0.908867
--- 4919.491038560867 seconds ---
batch_number = 120, loss = 2.780090, acc = 0.909443
--- 4928.017474651337 seconds ---
batch_number = 130, loss = 2.758462, acc = 0.910947
--- 4937.603103637695 seconds ---
batch_number = 140, loss = 2.796603, acc = 0.910807
--- 4944.796288013458 seconds ---
batch_number = 150, loss = 2.893549, acc = 0.905994
--- 4952.032316207886 seconds ---
batch_number = 160, loss = 2.938038, acc = 0.903277
[epoch 34]: train_loss = 0.377062, train_acc = 0.901831, validation_loss = 4.983261, validation_acc = 0.774052
--- 4968.03527879715 seconds ---
batch_number = 10, loss = 7.679659, acc = 0.710226
--- 4977.935927391052 seconds ---
batch_number = 20, loss = 7.823248, acc = 0.672246
--- 4985.474271297455 seconds ---
batch_number = 30, loss = 7.549234, acc = 0.683277
--- 4993.275531768799 seconds ---
batch_number = 40, loss = 7.281334, acc = 0.687288
--- 5002.932970285416 seconds ---
batch_number = 50, loss = 6.757418, acc = 0.710331
--- 5011.857313632965 seconds ---
batch_number = 60, loss = 6.325535, acc = 0.731042
--- 5020.136047840118 seconds ---
batch_number = 70, loss = 6.016181, acc = 0.740641
--- 5029.097688674927 seconds ---
batch_number = 80, loss = 5.778408, acc = 0.751502
--- 5036.991878986359 seconds ---
batch_number = 90, loss = 5.534405, acc = 0.764476
--- 5046.227762937546 seconds ---
batch_number = 100, loss = 5.305345, acc = 0.776178
--- 5053.419898986816 seconds ---
batch_number = 110, loss = 5.123597, acc = 0.784477
--- 5061.095783948898 seconds ---
batch_number = 120, loss = 4.986165, acc = 0.790663
--- 5069.092641830444 seconds ---
batch_number = 130, loss = 4.832565, acc = 0.799347
--- 5077.766806602478 seconds ---
batch_number = 140, loss = 4.710936, acc = 0.806547
--- 5086.021782398224 seconds ---
batch_number = 150, loss = 4.625916, acc = 0.811787
--- 5095.074954032898 seconds ---
batch_number = 160, loss = 4.550798, acc = 0.815116
[epoch 35]: train_loss = 0.566568, train_acc = 0.818753, validation_loss = 3.867784, validation_acc = 0.833591
--- 5113.111723184586 seconds ---
batch_number = 10, loss = 2.443222, acc = 0.918580
--- 5122.702330350876 seconds ---
batch_number = 20, loss = 2.504755, acc = 0.918513
--- 5132.329069375992 seconds ---
batch_number = 30, loss = 2.517505, acc = 0.922454
--- 5139.72878742218 seconds ---
batch_number = 40, loss = 2.594467, acc = 0.920352
--- 5148.018656015396 seconds ---
batch_number = 50, loss = 2.594353, acc = 0.920716
--- 5156.197024345398 seconds ---
batch_number = 60, loss = 2.599052, acc = 0.921628
--- 5165.368882417679 seconds ---
batch_number = 70, loss = 2.589446, acc = 0.922826
--- 5172.131835222244 seconds ---
batch_number = 80, loss = 2.620279, acc = 0.921833
--- 5180.17147731781 seconds ---
batch_number = 90, loss = 2.635957, acc = 0.921380
--- 5188.602510213852 seconds ---
batch_number = 100, loss = 2.638618, acc = 0.922245
--- 5196.342665195465 seconds ---
batch_number = 110, loss = 2.650399, acc = 0.921343
--- 5205.268968820572 seconds ---
batch_number = 120, loss = 2.639532, acc = 0.922318
--- 5215.227520465851 seconds ---
batch_number = 130, loss = 2.624153, acc = 0.922806
--- 5223.253374099731 seconds ---
batch_number = 140, loss = 2.627456, acc = 0.922606
--- 5231.728448867798 seconds ---
batch_number = 150, loss = 2.622913, acc = 0.922834
--- 5241.280173540115 seconds ---
batch_number = 160, loss = 2.616499, acc = 0.922856
[epoch 36]: train_loss = 0.332290, train_acc = 0.922339, validation_loss = 3.610409, validation_acc = 0.853927
--- 5259.377922534943 seconds ---
batch_number = 10, loss = 2.117193, acc = 0.928022
--- 5268.707877635956 seconds ---
batch_number = 20, loss = 2.424648, acc = 0.926469
--- 5277.763065576553 seconds ---
batch_number = 30, loss = 2.457449, acc = 0.924344
--- 5286.902646064758 seconds ---
batch_number = 40, loss = 2.452742, acc = 0.926358
--- 5294.998817682266 seconds ---
batch_number = 50, loss = 2.528804, acc = 0.925327
--- 5302.472101926804 seconds ---
batch_number = 60, loss = 2.536281, acc = 0.926110
--- 5310.121551036835 seconds ---
batch_number = 70, loss = 2.525147, acc = 0.927181
--- 5318.609904766083 seconds ---
batch_number = 80, loss = 2.514732, acc = 0.927351
--- 5325.803515911102 seconds ---
batch_number = 90, loss = 2.505439, acc = 0.926963
--- 5334.364633321762 seconds ---
batch_number = 100, loss = 2.496076, acc = 0.927730
--- 5342.235976219177 seconds ---
batch_number = 110, loss = 2.480707, acc = 0.928325
--- 5350.594431638718 seconds ---
batch_number = 120, loss = 2.491842, acc = 0.927916
--- 5360.366398334503 seconds ---
batch_number = 130, loss = 2.546296, acc = 0.924756
--- 5368.927854537964 seconds ---
batch_number = 140, loss = 2.594597, acc = 0.922038
--- 5378.531731843948 seconds ---
batch_number = 150, loss = 2.628313, acc = 0.920196
--- 5386.393778562546 seconds ---
batch_number = 160, loss = 2.651778, acc = 0.918733
[epoch 37]: train_loss = 0.335927, train_acc = 0.918639, validation_loss = 3.805429, validation_acc = 0.846437
--- 5403.638395309448 seconds ---
batch_number = 10, loss = 2.268534, acc = 0.926568
--- 5413.229647636414 seconds ---
batch_number = 20, loss = 2.363477, acc = 0.925907
--- 5421.52216053009 seconds ---
batch_number = 30, loss = 2.440904, acc = 0.928098
--- 5429.434813499451 seconds ---
batch_number = 40, loss = 2.447748, acc = 0.928549
--- 5439.019230604172 seconds ---
batch_number = 50, loss = 2.372066, acc = 0.931974
--- 5449.232059955597 seconds ---
batch_number = 60, loss = 2.345981, acc = 0.934791
--- 5457.558182954788 seconds ---
batch_number = 70, loss = 2.322396, acc = 0.935749
--- 5465.879909992218 seconds ---
batch_number = 80, loss = 2.320350, acc = 0.936040
--- 5474.711627244949 seconds ---
batch_number = 90, loss = 2.308428, acc = 0.936147
--- 5483.834547519684 seconds ---
batch_number = 100, loss = 2.307339, acc = 0.936321
--- 5491.887261390686 seconds ---
batch_number = 110, loss = 2.306739, acc = 0.936447
--- 5500.7319531440735 seconds ---
batch_number = 120, loss = 2.306443, acc = 0.936214
--- 5509.444718837738 seconds ---
batch_number = 130, loss = 2.314025, acc = 0.935046
--- 5517.688407421112 seconds ---
batch_number = 140, loss = 2.329191, acc = 0.933497
--- 5525.027943372726 seconds ---
batch_number = 150, loss = 2.336884, acc = 0.933306
--- 5534.118287801743 seconds ---
batch_number = 160, loss = 2.347854, acc = 0.933007
[epoch 38]: train_loss = 0.298312, train_acc = 0.933224, validation_loss = 4.252300, validation_acc = 0.809712
--- 5550.351883649826 seconds ---
batch_number = 10, loss = 2.047625, acc = 0.936731
--- 5557.486936807632 seconds ---
batch_number = 20, loss = 2.246896, acc = 0.933527
--- 5565.692977905273 seconds ---
batch_number = 30, loss = 2.294620, acc = 0.931931
--- 5573.855289697647 seconds ---
batch_number = 40, loss = 2.269808, acc = 0.932543
--- 5582.702922105789 seconds ---
batch_number = 50, loss = 2.297332, acc = 0.930804
--- 5592.68021440506 seconds ---
batch_number = 60, loss = 2.286555, acc = 0.933861
--- 5601.746295213699 seconds ---
batch_number = 70, loss = 2.289112, acc = 0.935286
--- 5610.516359806061 seconds ---
batch_number = 80, loss = 2.298124, acc = 0.935697
--- 5618.9552166461945 seconds ---
batch_number = 90, loss = 2.299032, acc = 0.936435
--- 5626.07737660408 seconds ---
batch_number = 100, loss = 2.298923, acc = 0.937608
--- 5634.318950176239 seconds ---
batch_number = 110, loss = 2.284777, acc = 0.937898
--- 5643.440550804138 seconds ---
batch_number = 120, loss = 2.278126, acc = 0.939061
--- 5651.3291182518005 seconds ---
batch_number = 130, loss = 2.259091, acc = 0.939297
--- 5660.06151676178 seconds ---
batch_number = 140, loss = 2.249475, acc = 0.939866
--- 5669.64023399353 seconds ---
batch_number = 150, loss = 2.246157, acc = 0.940312
--- 5678.300632715225 seconds ---
batch_number = 160, loss = 2.238764, acc = 0.940615
[epoch 39]: train_loss = 0.282418, train_acc = 0.941178, validation_loss = 3.324466, validation_acc = 0.854308
--- 5694.535227537155 seconds ---
batch_number = 10, loss = 1.814150, acc = 0.948840
--- 5703.826995134354 seconds ---
batch_number = 20, loss = 1.853667, acc = 0.949184
--- 5711.844956636429 seconds ---
batch_number = 30, loss = 1.902220, acc = 0.949461
--- 5720.644134759903 seconds ---
batch_number = 40, loss = 1.945520, acc = 0.949773
--- 5728.233124732971 seconds ---
batch_number = 50, loss = 2.012838, acc = 0.948025
--- 5735.939247131348 seconds ---
batch_number = 60, loss = 2.044474, acc = 0.947236
--- 5745.268105745316 seconds ---
batch_number = 70, loss = 2.038231, acc = 0.947414
--- 5753.100646734238 seconds ---
batch_number = 80, loss = 2.058000, acc = 0.946688
--- 5762.397930383682 seconds ---
batch_number = 90, loss = 2.040442, acc = 0.947489
--- 5770.340220451355 seconds ---
batch_number = 100, loss = 2.047691, acc = 0.947361
--- 5779.0913071632385 seconds ---
batch_number = 110, loss = 2.044880, acc = 0.947792
--- 5788.828963518143 seconds ---
batch_number = 120, loss = 2.034636, acc = 0.948015
--- 5796.862778902054 seconds ---
batch_number = 130, loss = 2.047612, acc = 0.947783
--- 5804.166242837906 seconds ---
batch_number = 140, loss = 2.060023, acc = 0.947491
--- 5814.495616197586 seconds ---
batch_number = 150, loss = 2.046601, acc = 0.948344
--- 5824.4584703445435 seconds ---
batch_number = 160, loss = 2.046940, acc = 0.948475
[epoch 40]: train_loss = 0.257770, train_acc = 0.948552, validation_loss = 3.483798, validation_acc = 0.840257
--- 5842.589007616043 seconds ---
batch_number = 10, loss = 1.707180, acc = 0.953965
--- 5850.5353944301605 seconds ---
batch_number = 20, loss = 1.816689, acc = 0.954396
--- 5859.687188625336 seconds ---
batch_number = 30, loss = 1.831817, acc = 0.954651
--- 5868.458329439163 seconds ---
batch_number = 40, loss = 1.880251, acc = 0.954156
--- 5876.214852571487 seconds ---
batch_number = 50, loss = 1.916453, acc = 0.953675
--- 5884.354324579239 seconds ---
batch_number = 60, loss = 1.930802, acc = 0.952874
--- 5892.592335224152 seconds ---
batch_number = 70, loss = 1.944964, acc = 0.952400
--- 5900.17173743248 seconds ---
batch_number = 80, loss = 1.959007, acc = 0.952301
--- 5908.08487200737 seconds ---
batch_number = 90, loss = 1.971682, acc = 0.952211
--- 5918.544032096863 seconds ---
batch_number = 100, loss = 1.970159, acc = 0.951907
--- 5927.5314564704895 seconds ---
batch_number = 110, loss = 1.965958, acc = 0.951746
--- 5936.495859146118 seconds ---
batch_number = 120, loss = 1.958105, acc = 0.952069
--- 5945.381352186203 seconds ---
batch_number = 130, loss = 1.957660, acc = 0.952991
--- 5952.994225502014 seconds ---
batch_number = 140, loss = 1.966296, acc = 0.952947
--- 5961.125392913818 seconds ---
batch_number = 150, loss = 1.977460, acc = 0.952591
--- 5970.63197851181 seconds ---
batch_number = 160, loss = 1.968890, acc = 0.952545
[epoch 41]: train_loss = 0.248896, train_acc = 0.952391, validation_loss = 3.126042, validation_acc = 0.860883
--- 5988.360094547272 seconds ---
batch_number = 10, loss = 1.818761, acc = 0.947249
--- 5996.912041187286 seconds ---
batch_number = 20, loss = 1.940235, acc = 0.948388
--- 6005.484857797623 seconds ---
batch_number = 30, loss = 1.948460, acc = 0.949780
--- 6013.327791452408 seconds ---
batch_number = 40, loss = 1.961774, acc = 0.950313
--- 6020.95779299736 seconds ---
batch_number = 50, loss = 1.985540, acc = 0.949610
--- 6029.447438001633 seconds ---
batch_number = 60, loss = 1.979186, acc = 0.950334
--- 6037.691092014313 seconds ---
batch_number = 70, loss = 1.988433, acc = 0.950687
--- 6046.975158929825 seconds ---
batch_number = 80, loss = 1.970954, acc = 0.952075
--- 6056.458028078079 seconds ---
batch_number = 90, loss = 1.964283, acc = 0.952300
--- 6065.283150196075 seconds ---
batch_number = 100, loss = 1.951275, acc = 0.951746
--- 6074.3866946697235 seconds ---
batch_number = 110, loss = 1.994414, acc = 0.949204
--- 6082.5927765369415 seconds ---
batch_number = 120, loss = 2.004093, acc = 0.948810
--- 6092.4258279800415 seconds ---
batch_number = 130, loss = 2.008353, acc = 0.947503
--- 6100.198625802994 seconds ---
batch_number = 140, loss = 2.024507, acc = 0.947271
--- 6109.354971408844 seconds ---
batch_number = 150, loss = 2.017271, acc = 0.947311
--- 6117.447473287582 seconds ---
batch_number = 160, loss = 2.027289, acc = 0.947054
[epoch 42]: train_loss = 0.257031, train_acc = 0.947032, validation_loss = 3.201501, validation_acc = 0.861794
--- 6133.536037683487 seconds ---
batch_number = 10, loss = 1.666988, acc = 0.966070
--- 6143.073638677597 seconds ---
batch_number = 20, loss = 1.768381, acc = 0.958234
--- 6152.0175993442535 seconds ---
batch_number = 30, loss = 1.784290, acc = 0.957426
--- 6160.759564161301 seconds ---
batch_number = 40, loss = 2.000033, acc = 0.945868
--- 6168.2182586193085 seconds ---
batch_number = 50, loss = 2.298338, acc = 0.933695
--- 6176.584734201431 seconds ---
batch_number = 60, loss = 2.589010, acc = 0.917021
--- 6185.651602506638 seconds ---
batch_number = 70, loss = 2.685222, acc = 0.908776
--- 6193.248919010162 seconds ---
batch_number = 80, loss = 2.744086, acc = 0.903284
--- 6201.8220093250275 seconds ---
batch_number = 90, loss = 2.786469, acc = 0.900747
--- 6212.205794095993 seconds ---
batch_number = 100, loss = 2.754378, acc = 0.902268
--- 6220.1650676727295 seconds ---
batch_number = 110, loss = 2.748023, acc = 0.903865
--- 6228.175074338913 seconds ---
batch_number = 120, loss = 2.739467, acc = 0.905107
--- 6236.511180400848 seconds ---
batch_number = 130, loss = 2.719067, acc = 0.905990
--- 6245.911123037338 seconds ---
batch_number = 140, loss = 2.683620, acc = 0.908227
--- 6254.302274227142 seconds ---
batch_number = 150, loss = 2.652338, acc = 0.909965
--- 6262.240815162659 seconds ---
batch_number = 160, loss = 2.645465, acc = 0.910652
[epoch 43]: train_loss = 0.334021, train_acc = 0.910915, validation_loss = 4.069305, validation_acc = 0.820510
--- 6278.468259572983 seconds ---
batch_number = 10, loss = 2.026333, acc = 0.934041
--- 6287.121543645859 seconds ---
batch_number = 20, loss = 2.090613, acc = 0.938764
--- 6296.544988632202 seconds ---
batch_number = 30, loss = 2.047133, acc = 0.941890
--- 6305.465856075287 seconds ---
batch_number = 40, loss = 2.090537, acc = 0.942577
--- 6314.004499673843 seconds ---
batch_number = 50, loss = 2.099932, acc = 0.943042
--- 6321.630819559097 seconds ---
batch_number = 60, loss = 2.134919, acc = 0.941675
--- 6330.969601631165 seconds ---
batch_number = 70, loss = 2.129183, acc = 0.941589
--- 6339.806231021881 seconds ---
batch_number = 80, loss = 2.112684, acc = 0.941834
--- 6348.487893104553 seconds ---
batch_number = 90, loss = 2.104471, acc = 0.942194
--- 6357.815203666687 seconds ---
batch_number = 100, loss = 2.090530, acc = 0.942586
--- 6366.824319601059 seconds ---
batch_number = 110, loss = 2.079931, acc = 0.943908
--- 6375.888962030411 seconds ---
batch_number = 120, loss = 2.077665, acc = 0.944805
--- 6384.141979217529 seconds ---
batch_number = 130, loss = 2.077405, acc = 0.945039
--- 6393.2073097229 seconds ---
batch_number = 140, loss = 2.083162, acc = 0.944381
--- 6402.541077613831 seconds ---
batch_number = 150, loss = 2.098793, acc = 0.943247
--- 6410.160980939865 seconds ---
batch_number = 160, loss = 2.119773, acc = 0.942553
[epoch 44]: train_loss = 0.279416, train_acc = 0.939552, validation_loss = 4.632247, validation_acc = 0.782532
--- 6427.294709444046 seconds ---
batch_number = 10, loss = 7.062098, acc = 0.671765
--- 6436.586790323257 seconds ---
batch_number = 20, loss = 8.246302, acc = 0.580030
--- 6445.39147901535 seconds ---
batch_number = 30, loss = 7.678533, acc = 0.604901
--- 6453.783518791199 seconds ---
batch_number = 40, loss = 7.624039, acc = 0.596561
--- 6461.162576913834 seconds ---
batch_number = 50, loss = 7.610997, acc = 0.596003
--- 6469.80592417717 seconds ---
batch_number = 60, loss = 7.286146, acc = 0.619410
--- 6479.2162165641785 seconds ---
batch_number = 70, loss = 7.183484, acc = 0.626325
--- 6488.083243846893 seconds ---
batch_number = 80, loss = 6.961697, acc = 0.639461
--- 6495.926399946213 seconds ---
batch_number = 90, loss = 6.678600, acc = 0.659974
--- 6503.727098703384 seconds ---
batch_number = 100, loss = 6.405295, acc = 0.679273
--- 6512.887118577957 seconds ---
batch_number = 110, loss = 6.197810, acc = 0.697608
--- 6521.356773614883 seconds ---
batch_number = 120, loss = 5.984699, acc = 0.710681
--- 6529.319178819656 seconds ---
batch_number = 130, loss = 5.841638, acc = 0.721877
--- 6537.908541917801 seconds ---
batch_number = 140, loss = 5.736201, acc = 0.730079
--- 6546.341735124588 seconds ---
batch_number = 150, loss = 5.626609, acc = 0.737904
--- 6555.3176057338715 seconds ---
batch_number = 160, loss = 5.483881, acc = 0.749209
[epoch 45]: train_loss = 0.684384, train_acc = 0.753980, validation_loss = 4.064397, validation_acc = 0.824763
--- 6574.286766529083 seconds ---
batch_number = 10, loss = 2.900153, acc = 0.902042
--- 6582.298335313797 seconds ---
batch_number = 20, loss = 3.018479, acc = 0.902051
--- 6589.327720165253 seconds ---
batch_number = 30, loss = 2.955848, acc = 0.909463
--- 6597.064684391022 seconds ---
batch_number = 40, loss = 2.934117, acc = 0.911506
--- 6605.880527973175 seconds ---
batch_number = 50, loss = 2.906298, acc = 0.912052
--- 6616.2512311935425 seconds ---
batch_number = 60, loss = 2.869196, acc = 0.913558
--- 6626.003192424774 seconds ---
batch_number = 70, loss = 2.837923, acc = 0.914348
--- 6634.686863660812 seconds ---
batch_number = 80, loss = 2.849552, acc = 0.913257
--- 6642.819066286087 seconds ---
batch_number = 90, loss = 2.853884, acc = 0.913081
--- 6651.3704380989075 seconds ---
batch_number = 100, loss = 2.864056, acc = 0.913502
--- 6659.585809469223 seconds ---
batch_number = 110, loss = 2.845330, acc = 0.914024
--- 6667.102140665054 seconds ---
batch_number = 120, loss = 2.908889, acc = 0.911039
--- 6675.261541366577 seconds ---
batch_number = 130, loss = 2.936016, acc = 0.910458
--- 6684.437789916992 seconds ---
batch_number = 140, loss = 3.103432, acc = 0.900561
--- 6693.646711349487 seconds ---
batch_number = 150, loss = 3.162350, acc = 0.897424
--- 6700.34779047966 seconds ---
batch_number = 160, loss = 3.281113, acc = 0.892393
[epoch 46]: train_loss = 0.420283, train_acc = 0.890924, validation_loss = 4.507877, validation_acc = 0.806775
--- 6716.147101163864 seconds ---
batch_number = 10, loss = 3.077877, acc = 0.862840
--- 6724.6659417152405 seconds ---
batch_number = 20, loss = 3.319033, acc = 0.870977
--- 6733.047798395157 seconds ---
batch_number = 30, loss = 3.225104, acc = 0.880037
--- 6741.106512069702 seconds ---
batch_number = 40, loss = 3.207879, acc = 0.887656
--- 6749.526113510132 seconds ---
batch_number = 50, loss = 3.095109, acc = 0.893066
--- 6758.879789829254 seconds ---
batch_number = 60, loss = 3.057061, acc = 0.897066
--- 6769.130003929138 seconds ---
batch_number = 70, loss = 2.968826, acc = 0.902406
--- 6777.928782939911 seconds ---
batch_number = 80, loss = 2.971467, acc = 0.902040
--- 6787.563692331314 seconds ---
batch_number = 90, loss = 2.998990, acc = 0.900500
--- 6796.056019067764 seconds ---
batch_number = 100, loss = 3.000585, acc = 0.899555
--- 6804.797069311142 seconds ---
batch_number = 110, loss = 2.974022, acc = 0.900499
--- 6813.729717731476 seconds ---
batch_number = 120, loss = 2.939755, acc = 0.902914
--- 6821.410230398178 seconds ---
batch_number = 130, loss = 2.902883, acc = 0.905757
--- 6830.4367027282715 seconds ---
batch_number = 140, loss = 2.861832, acc = 0.908138
--- 6838.77845788002 seconds ---
batch_number = 150, loss = 2.837532, acc = 0.909269
--- 6848.036366701126 seconds ---
batch_number = 160, loss = 2.814411, acc = 0.910744
[epoch 47]: train_loss = 0.355578, train_acc = 0.910887, validation_loss = 5.047582, validation_acc = 0.822754
--- 6865.507962703705 seconds ---
batch_number = 10, loss = 2.601309, acc = 0.916998
--- 6873.505661249161 seconds ---
batch_number = 20, loss = 2.631537, acc = 0.921015
--- 6882.231797456741 seconds ---
batch_number = 30, loss = 2.555635, acc = 0.924898
--- 6891.9265348911285 seconds ---
batch_number = 40, loss = 2.486832, acc = 0.929535
--- 6900.404547452927 seconds ---
batch_number = 50, loss = 2.489018, acc = 0.928646
--- 6907.237933397293 seconds ---
batch_number = 60, loss = 2.481844, acc = 0.930539
--- 6916.187650680542 seconds ---
batch_number = 70, loss = 2.437286, acc = 0.934387
--- 6924.556759595871 seconds ---
batch_number = 80, loss = 2.433508, acc = 0.935148
--- 6934.257790803909 seconds ---
batch_number = 90, loss = 2.386250, acc = 0.937109
--- 6943.576516628265 seconds ---
batch_number = 100, loss = 2.355410, acc = 0.938562
--- 6953.174120426178 seconds ---
batch_number = 110, loss = 2.336806, acc = 0.940098
--- 6962.846990585327 seconds ---
batch_number = 120, loss = 2.312657, acc = 0.941066
--- 6972.069026708603 seconds ---
batch_number = 130, loss = 2.296373, acc = 0.941618
--- 6980.41215467453 seconds ---
batch_number = 140, loss = 2.291388, acc = 0.941970
--- 6988.402576684952 seconds ---
batch_number = 150, loss = 2.294706, acc = 0.942055
--- 6995.684449911118 seconds ---
batch_number = 160, loss = 2.298527, acc = 0.941654
[epoch 48]: train_loss = 0.291948, train_acc = 0.941561, validation_loss = 3.860497, validation_acc = 0.850544
--- 7011.772516489029 seconds ---
batch_number = 10, loss = 2.006105, acc = 0.945767
--- 7021.469696521759 seconds ---
batch_number = 20, loss = 2.081238, acc = 0.944675
--- 7030.874960660934 seconds ---
batch_number = 30, loss = 2.123982, acc = 0.943420
--- 7039.7775666713715 seconds ---
batch_number = 40, loss = 2.141692, acc = 0.943249
--- 7049.311123132706 seconds ---
batch_number = 50, loss = 2.131957, acc = 0.944632
--- 7057.31396484375 seconds ---
batch_number = 60, loss = 2.146087, acc = 0.945059
--- 7064.960028409958 seconds ---
batch_number = 70, loss = 2.151167, acc = 0.945882
--- 7071.962791919708 seconds ---
batch_number = 80, loss = 2.158455, acc = 0.946086
--- 7080.692108154297 seconds ---
batch_number = 90, loss = 2.136239, acc = 0.947867
--- 7090.086469888687 seconds ---
batch_number = 100, loss = 2.114839, acc = 0.948407
--- 7098.131117105484 seconds ---
batch_number = 110, loss = 2.109950, acc = 0.948762
--- 7106.295196771622 seconds ---
batch_number = 120, loss = 2.109109, acc = 0.950089
--- 7114.228875398636 seconds ---
batch_number = 130, loss = 2.103843, acc = 0.950158
--- 7123.332082748413 seconds ---
batch_number = 140, loss = 2.080042, acc = 0.950943
--- 7132.501239299774 seconds ---
batch_number = 150, loss = 2.065798, acc = 0.951317
--- 7141.53275513649 seconds ---
batch_number = 160, loss = 2.053091, acc = 0.952050
[epoch 49]: train_loss = 0.260138, train_acc = 0.952007, validation_loss = 2.999532, validation_acc = 0.877324
--- 7157.646668434143 seconds ---
batch_number = 10, loss = 1.709020, acc = 0.956756
--- 7166.753365755081 seconds ---
batch_number = 20, loss = 1.803798, acc = 0.958288
--- 7175.19250369072 seconds ---
batch_number = 30, loss = 1.845082, acc = 0.959187
--- 7183.145473480225 seconds ---
batch_number = 40, loss = 1.839843, acc = 0.960323
--- 7192.117259502411 seconds ---
batch_number = 50, loss = 1.835411, acc = 0.959975
--- 7202.129040718079 seconds ---
batch_number = 60, loss = 1.835470, acc = 0.961072
--- 7212.36608171463 seconds ---
batch_number = 70, loss = 1.827367, acc = 0.961060
--- 7220.149573326111 seconds ---
batch_number = 80, loss = 1.849496, acc = 0.960369
--- 7228.366941452026 seconds ---
batch_number = 90, loss = 1.842309, acc = 0.961066
--- 7237.009936571121 seconds ---
batch_number = 100, loss = 1.839025, acc = 0.961487
--- 7245.274648666382 seconds ---
batch_number = 110, loss = 1.852898, acc = 0.960689
--- 7253.287109136581 seconds ---
batch_number = 120, loss = 1.851157, acc = 0.960516
--- 7261.690849542618 seconds ---
batch_number = 130, loss = 1.852722, acc = 0.960579
--- 7270.488745927811 seconds ---
batch_number = 140, loss = 1.843982, acc = 0.960832
--- 7278.901588916779 seconds ---
batch_number = 150, loss = 1.842834, acc = 0.961075
--- 7287.576821088791 seconds ---
batch_number = 160, loss = 1.842443, acc = 0.961001
[epoch 50]: train_loss = 0.233236, train_acc = 0.960781, validation_loss = 2.992113, validation_acc = 0.874181
--- 7304.5795378685 seconds ---
batch_number = 10, loss = 1.513016, acc = 0.962328
--- 7313.203229188919 seconds ---
batch_number = 20, loss = 1.677582, acc = 0.961527
--- 7321.39128947258 seconds ---
batch_number = 30, loss = 1.730439, acc = 0.962040
--- 7328.885666847229 seconds ---
batch_number = 40, loss = 1.779094, acc = 0.961546
--- 7338.2404799461365 seconds ---
batch_number = 50, loss = 1.769016, acc = 0.962258
--- 7345.91241312027 seconds ---
batch_number = 60, loss = 1.761383, acc = 0.962489
--- 7353.969246149063 seconds ---
batch_number = 70, loss = 1.766701, acc = 0.961968
--- 7364.442294597626 seconds ---
batch_number = 80, loss = 1.754244, acc = 0.963239
--- 7375.116430521011 seconds ---
batch_number = 90, loss = 1.731541, acc = 0.963760
--- 7383.805698871613 seconds ---
batch_number = 100, loss = 1.727059, acc = 0.964045
--- 7392.0544312000275 seconds ---
batch_number = 110, loss = 1.728924, acc = 0.964002
--- 7400.212670087814 seconds ---
batch_number = 120, loss = 1.739482, acc = 0.963961
--- 7407.695435523987 seconds ---
batch_number = 130, loss = 1.759278, acc = 0.963559
--- 7416.8108253479 seconds ---
batch_number = 140, loss = 1.754097, acc = 0.963173
--- 7427.094926118851 seconds ---
batch_number = 150, loss = 1.745456, acc = 0.963318
--- 7434.394903182983 seconds ---
batch_number = 160, loss = 1.760030, acc = 0.963236
[epoch 51]: train_loss = 0.222434, train_acc = 0.963291, validation_loss = 3.008918, validation_acc = 0.874494
--- 7452.367757558823 seconds ---
batch_number = 10, loss = 1.536058, acc = 0.969589
--- 7460.917382955551 seconds ---
batch_number = 20, loss = 1.650218, acc = 0.965445
--- 7469.613435506821 seconds ---
batch_number = 30, loss = 1.665231, acc = 0.965787
--- 7478.127676010132 seconds ---
batch_number = 40, loss = 1.669020, acc = 0.966994
--- 7486.14895772934 seconds ---
batch_number = 50, loss = 1.690643, acc = 0.965886
--- 7493.7338399887085 seconds ---
batch_number = 60, loss = 1.706667, acc = 0.964601
--- 7502.474382400513 seconds ---
batch_number = 70, loss = 1.692930, acc = 0.964320
--- 7512.716243028641 seconds ---
batch_number = 80, loss = 1.681784, acc = 0.964658
--- 7521.420017004013 seconds ---
batch_number = 90, loss = 1.687536, acc = 0.964555
--- 7529.415209770203 seconds ---
batch_number = 100, loss = 1.697359, acc = 0.964799
--- 7537.346365451813 seconds ---
batch_number = 110, loss = 1.715761, acc = 0.964720
--- 7546.318428993225 seconds ---
batch_number = 120, loss = 1.721406, acc = 0.964291
--- 7553.743239402771 seconds ---
batch_number = 130, loss = 1.724816, acc = 0.964031
--- 7562.835842370987 seconds ---
batch_number = 140, loss = 1.725188, acc = 0.964031
--- 7572.275879144669 seconds ---
batch_number = 150, loss = 1.719024, acc = 0.963965
--- 7580.142216682434 seconds ---
batch_number = 160, loss = 1.719290, acc = 0.964161
[epoch 52]: train_loss = 0.217874, train_acc = 0.964158, validation_loss = 3.040952, validation_acc = 0.870245
--- 7596.310461521149 seconds ---
batch_number = 10, loss = 1.458821, acc = 0.971050
--- 7604.664703369141 seconds ---
batch_number = 20, loss = 1.574302, acc = 0.965511
--- 7613.703459978104 seconds ---
batch_number = 30, loss = 1.576038, acc = 0.967839
--- 7622.036893367767 seconds ---
batch_number = 40, loss = 1.613342, acc = 0.967382
--- 7629.255649805069 seconds ---
batch_number = 50, loss = 1.649305, acc = 0.966293
--- 7638.269361972809 seconds ---
batch_number = 60, loss = 1.654134, acc = 0.966386
--- 7646.051887512207 seconds ---
batch_number = 70, loss = 1.665274, acc = 0.965513
--- 7655.042717456818 seconds ---
batch_number = 80, loss = 1.654340, acc = 0.965726
--- 7664.709228277206 seconds ---
batch_number = 90, loss = 1.633320, acc = 0.966180
--- 7673.414427518845 seconds ---
batch_number = 100, loss = 1.634718, acc = 0.966449
--- 7682.517645597458 seconds ---
batch_number = 110, loss = 1.635950, acc = 0.966624
--- 7689.789553165436 seconds ---
batch_number = 120, loss = 1.641123, acc = 0.966719
--- 7698.85395359993 seconds ---
batch_number = 130, loss = 1.646985, acc = 0.966498
--- 7708.1313762664795 seconds ---
batch_number = 140, loss = 1.637487, acc = 0.967107
--- 7717.836182832718 seconds ---
batch_number = 150, loss = 1.639019, acc = 0.967114
--- 7724.822659730911 seconds ---
batch_number = 160, loss = 1.649189, acc = 0.966958
[epoch 53]: train_loss = 0.208261, train_acc = 0.966993, validation_loss = 3.126578, validation_acc = 0.873325
--- 7742.763871669769 seconds ---
batch_number = 10, loss = 1.449996, acc = 0.966181
--- 7750.164093255997 seconds ---
batch_number = 20, loss = 1.525619, acc = 0.966063
--- 7757.776783704758 seconds ---
batch_number = 30, loss = 1.590087, acc = 0.964316
--- 7766.17147397995 seconds ---
batch_number = 40, loss = 1.589032, acc = 0.965007
--- 7774.822387218475 seconds ---
batch_number = 50, loss = 1.601628, acc = 0.964954
--- 7783.941204071045 seconds ---
batch_number = 60, loss = 1.597812, acc = 0.964811
--- 7793.588604211807 seconds ---
batch_number = 70, loss = 1.583066, acc = 0.966116
--- 7803.183832883835 seconds ---
batch_number = 80, loss = 1.582910, acc = 0.966655
--- 7813.10573720932 seconds ---
batch_number = 90, loss = 1.573798, acc = 0.966586
--- 7822.038493156433 seconds ---
batch_number = 100, loss = 1.572868, acc = 0.966243
--- 7830.677553892136 seconds ---
batch_number = 110, loss = 1.590322, acc = 0.966400
--- 7838.804474830627 seconds ---
batch_number = 120, loss = 1.596425, acc = 0.966716
--- 7846.580593347549 seconds ---
batch_number = 130, loss = 1.597117, acc = 0.966668
--- 7854.924307584763 seconds ---
batch_number = 140, loss = 1.618257, acc = 0.965795
--- 7863.360759019852 seconds ---
batch_number = 150, loss = 1.670291, acc = 0.963257
--- 7873.122374296188 seconds ---
batch_number = 160, loss = 1.764114, acc = 0.956896
[epoch 54]: train_loss = 0.230838, train_acc = 0.953075, validation_loss = 4.953517, validation_acc = 0.755338
--- 7890.209567070007 seconds ---
batch_number = 10, loss = 3.453732, acc = 0.836836
--- 7898.424116373062 seconds ---
batch_number = 20, loss = 3.414663, acc = 0.855351
--- 7906.325816869736 seconds ---
batch_number = 30, loss = 3.256828, acc = 0.869835
--- 7914.691176652908 seconds ---
batch_number = 40, loss = 3.264860, acc = 0.866474
--- 7922.6319189071655 seconds ---
batch_number = 50, loss = 3.321027, acc = 0.866297
--- 7931.608731269836 seconds ---
batch_number = 60, loss = 3.301457, acc = 0.870305
--- 7939.714134931564 seconds ---
batch_number = 70, loss = 3.296266, acc = 0.871262
--- 7948.104220867157 seconds ---
batch_number = 80, loss = 3.195744, acc = 0.876102
--- 7958.309982538223 seconds ---
batch_number = 90, loss = 3.132618, acc = 0.880699
--- 7966.668917179108 seconds ---
batch_number = 100, loss = 3.100724, acc = 0.883123
--- 7975.668949365616 seconds ---
batch_number = 110, loss = 3.057293, acc = 0.885184
--- 7983.506005525589 seconds ---
batch_number = 120, loss = 3.106427, acc = 0.885147
--- 7992.41570687294 seconds ---
batch_number = 130, loss = 3.123122, acc = 0.883246
--- 8000.375668287277 seconds ---
batch_number = 140, loss = 3.116804, acc = 0.884699
--- 8009.524955511093 seconds ---
batch_number = 150, loss = 3.073388, acc = 0.888008
--- 8017.595460653305 seconds ---
batch_number = 160, loss = 3.052100, acc = 0.889239
[epoch 55]: train_loss = 0.383425, train_acc = 0.889881, validation_loss = 4.090121, validation_acc = 0.819374
--- 8034.802692651749 seconds ---
batch_number = 10, loss = 3.566378, acc = 0.863274
--- 8044.123627662659 seconds ---
batch_number = 20, loss = 5.213094, acc = 0.786666
--- 8053.691412687302 seconds ---
batch_number = 30, loss = 4.856072, acc = 0.782501
--- 8063.116708040237 seconds ---
batch_number = 40, loss = 4.508661, acc = 0.810329
--- 8069.587304115295 seconds ---
batch_number = 50, loss = 4.244481, acc = 0.823950
--- 8077.570680618286 seconds ---
batch_number = 60, loss = 4.035102, acc = 0.839457
--- 8088.875967979431 seconds ---
batch_number = 70, loss = 3.864823, acc = 0.848436
--- 8096.482925653458 seconds ---
batch_number = 80, loss = 3.772340, acc = 0.853671
--- 8104.69918346405 seconds ---
batch_number = 90, loss = 3.686812, acc = 0.858732
--- 8113.398721218109 seconds ---
batch_number = 100, loss = 3.625174, acc = 0.860509
--- 8121.511087656021 seconds ---
batch_number = 110, loss = 3.567088, acc = 0.864848
--- 8130.773391246796 seconds ---
batch_number = 120, loss = 3.496101, acc = 0.869805
--- 8138.4689128398895 seconds ---
batch_number = 130, loss = 3.444184, acc = 0.873578
--- 8147.457454919815 seconds ---
batch_number = 140, loss = 3.413047, acc = 0.876078
--- 8154.5948138237 seconds ---
batch_number = 150, loss = 3.493607, acc = 0.873679
--- 8162.325346708298 seconds ---
batch_number = 160, loss = 3.482579, acc = 0.873450
[epoch 56]: train_loss = 0.437912, train_acc = 0.874129, validation_loss = 4.155246, validation_acc = 0.816215
--- 8180.915168046951 seconds ---
batch_number = 10, loss = 2.449678, acc = 0.906873
--- 8188.896404266357 seconds ---
batch_number = 20, loss = 2.481659, acc = 0.915484
--- 8198.41348695755 seconds ---
batch_number = 30, loss = 2.370925, acc = 0.924667
--- 8206.197459459305 seconds ---
batch_number = 40, loss = 2.342429, acc = 0.930527
--- 8213.542380332947 seconds ---
batch_number = 50, loss = 2.333783, acc = 0.932840
--- 8221.354210615158 seconds ---
batch_number = 60, loss = 2.326049, acc = 0.935348
--- 8229.625210285187 seconds ---
batch_number = 70, loss = 2.291287, acc = 0.936629
--- 8238.383229017258 seconds ---
batch_number = 80, loss = 2.260389, acc = 0.939199
--- 8246.969529867172 seconds ---
batch_number = 90, loss = 2.223426, acc = 0.942120
--- 8255.663279294968 seconds ---
batch_number = 100, loss = 2.197418, acc = 0.943359
--- 8264.937499523163 seconds ---
batch_number = 110, loss = 2.172236, acc = 0.944504
--- 8273.284911870956 seconds ---
batch_number = 120, loss = 2.153612, acc = 0.945470
--- 8283.452035427094 seconds ---
batch_number = 130, loss = 2.141021, acc = 0.946352
--- 8292.516330003738 seconds ---
batch_number = 140, loss = 2.138650, acc = 0.946797
--- 8302.638235092163 seconds ---
batch_number = 150, loss = 2.119542, acc = 0.947935
--- 8310.031420707703 seconds ---
batch_number = 160, loss = 2.105892, acc = 0.948478
[epoch 57]: train_loss = 0.265880, train_acc = 0.948921, validation_loss = 3.048078, validation_acc = 0.871397
--- 8325.973732948303 seconds ---
batch_number = 10, loss = 1.683351, acc = 0.957636
--- 8334.151236057281 seconds ---
batch_number = 20, loss = 1.664632, acc = 0.960973
--- 8343.402123451233 seconds ---
batch_number = 30, loss = 1.679797, acc = 0.963722
--- 8351.130578041077 seconds ---
batch_number = 40, loss = 1.705556, acc = 0.963717
--- 8360.582837343216 seconds ---
batch_number = 50, loss = 1.702034, acc = 0.965084
--- 8369.880997896194 seconds ---
batch_number = 60, loss = 1.710265, acc = 0.966145
--- 8379.1829559803 seconds ---
batch_number = 70, loss = 1.702265, acc = 0.965827
--- 8387.334121227264 seconds ---
batch_number = 80, loss = 1.715215, acc = 0.965152
--- 8398.07469367981 seconds ---
batch_number = 90, loss = 1.726375, acc = 0.964456
--- 8407.53527879715 seconds ---
batch_number = 100, loss = 1.715075, acc = 0.964650
--- 8417.124722003937 seconds ---
batch_number = 110, loss = 1.717719, acc = 0.964476
--- 8425.359974384308 seconds ---
batch_number = 120, loss = 1.720598, acc = 0.964737
--- 8432.175193548203 seconds ---
batch_number = 130, loss = 1.734477, acc = 0.964632
--- 8440.951090812683 seconds ---
batch_number = 140, loss = 1.734587, acc = 0.964957
--- 8447.799099206924 seconds ---
batch_number = 150, loss = 1.736334, acc = 0.964894
--- 8456.441539525986 seconds ---
batch_number = 160, loss = 1.726413, acc = 0.964778
[epoch 58]: train_loss = 0.218774, train_acc = 0.964994, validation_loss = 3.195566, validation_acc = 0.867509
--- 8472.806275367737 seconds ---
batch_number = 10, loss = 1.499725, acc = 0.965204
--- 8482.264972925186 seconds ---
batch_number = 20, loss = 1.505916, acc = 0.968782
--- 8490.822607755661 seconds ---
batch_number = 30, loss = 1.562720, acc = 0.968901
--- 8500.199362039566 seconds ---
batch_number = 40, loss = 1.568855, acc = 0.970428
--- 8507.824035406113 seconds ---
batch_number = 50, loss = 1.601553, acc = 0.969495
--- 8515.325231075287 seconds ---
batch_number = 60, loss = 1.638811, acc = 0.968599
--- 8523.827434062958 seconds ---
batch_number = 70, loss = 1.636869, acc = 0.969435
--- 8532.581705331802 seconds ---
batch_number = 80, loss = 1.625869, acc = 0.969667
--- 8541.187788009644 seconds ---
batch_number = 90, loss = 1.631867, acc = 0.970185
--- 8550.082471609116 seconds ---
batch_number = 100, loss = 1.633224, acc = 0.969896
--- 8558.09972691536 seconds ---
batch_number = 110, loss = 1.635925, acc = 0.970026
--- 8566.88176035881 seconds ---
batch_number = 120, loss = 1.628557, acc = 0.970090
--- 8576.061091184616 seconds ---
batch_number = 130, loss = 1.627248, acc = 0.970028
--- 8584.68444776535 seconds ---
batch_number = 140, loss = 1.621614, acc = 0.970176
--- 8593.794573545456 seconds ---
batch_number = 150, loss = 1.617462, acc = 0.970248
--- 8601.74598145485 seconds ---
batch_number = 160, loss = 1.620315, acc = 0.969899
[epoch 59]: train_loss = 0.205297, train_acc = 0.969772, validation_loss = 3.179423, validation_acc = 0.874133
--- 8619.740718841553 seconds ---
batch_number = 10, loss = 1.393223, acc = 0.972466
--- 8627.652999162674 seconds ---
batch_number = 20, loss = 1.578423, acc = 0.970965
--- 8636.977357625961 seconds ---
batch_number = 30, loss = 1.571222, acc = 0.969628
--- 8644.315820932388 seconds ---
batch_number = 40, loss = 1.588711, acc = 0.969569
--- 8652.218612909317 seconds ---
batch_number = 50, loss = 1.589081, acc = 0.969056
--- 8661.573450088501 seconds ---
batch_number = 60, loss = 1.587531, acc = 0.969133
--- 8670.7572016716 seconds ---
batch_number = 70, loss = 1.588111, acc = 0.969520
--- 8680.698182106018 seconds ---
batch_number = 80, loss = 1.572254, acc = 0.970231
--- 8688.90934252739 seconds ---
batch_number = 90, loss = 1.576743, acc = 0.970457
--- 8697.505656003952 seconds ---
batch_number = 100, loss = 1.576450, acc = 0.970820
--- 8705.692748069763 seconds ---
batch_number = 110, loss = 1.578499, acc = 0.970818
--- 8713.016657114029 seconds ---
batch_number = 120, loss = 1.589570, acc = 0.970812
--- 8720.804860591888 seconds ---
batch_number = 130, loss = 1.583094, acc = 0.970865
--- 8728.797395467758 seconds ---
batch_number = 140, loss = 1.575531, acc = 0.970889
--- 8738.097472906113 seconds ---
batch_number = 150, loss = 1.571009, acc = 0.970842
--- 8746.680452108383 seconds ---
batch_number = 160, loss = 1.573064, acc = 0.970781
[epoch 60]: train_loss = 0.199691, train_acc = 0.970744, validation_loss = 3.180100, validation_acc = 0.872579
--- 8763.89920926094 seconds ---
batch_number = 10, loss = 1.354601, acc = 0.971573
--- 8772.467248678207 seconds ---
batch_number = 20, loss = 1.395080, acc = 0.972653
--- 8781.167960643768 seconds ---
batch_number = 30, loss = 1.421274, acc = 0.972669
--- 8789.81636762619 seconds ---
batch_number = 40, loss = 1.422713, acc = 0.973908
--- 8798.13462805748 seconds ---
batch_number = 50, loss = 1.441535, acc = 0.973385
--- 8807.40875697136 seconds ---
batch_number = 60, loss = 1.446670, acc = 0.973540
--- 8815.620875120163 seconds ---
batch_number = 70, loss = 1.458458, acc = 0.973863
--- 8823.75740814209 seconds ---
batch_number = 80, loss = 1.458341, acc = 0.973767
--- 8832.860227584839 seconds ---
batch_number = 90, loss = 1.456268, acc = 0.973678
--- 8842.742931604385 seconds ---
batch_number = 100, loss = 1.453982, acc = 0.973767
--- 8851.039101839066 seconds ---
batch_number = 110, loss = 1.457570, acc = 0.973582
--- 8859.121838331223 seconds ---
batch_number = 120, loss = 1.465313, acc = 0.973170
--- 8868.733473300934 seconds ---
batch_number = 130, loss = 1.464844, acc = 0.973120
--- 8878.153504371643 seconds ---
batch_number = 140, loss = 1.460992, acc = 0.973074
--- 8886.344145298004 seconds ---
batch_number = 150, loss = 1.466242, acc = 0.973056
--- 8894.341251373291 seconds ---
batch_number = 160, loss = 1.471815, acc = 0.972802
[epoch 61]: train_loss = 0.186381, train_acc = 0.972712, validation_loss = 3.083098, validation_acc = 0.874458
--- 8910.845772981644 seconds ---
batch_number = 10, loss = 1.387832, acc = 0.968622
--- 8919.57695388794 seconds ---
batch_number = 20, loss = 1.447881, acc = 0.969695
--- 8928.499608516693 seconds ---
batch_number = 30, loss = 1.468633, acc = 0.969170
--- 8936.68068742752 seconds ---
batch_number = 40, loss = 1.497603, acc = 0.968812
--- 8945.245567798615 seconds ---
batch_number = 50, loss = 1.499361, acc = 0.969544
--- 8954.808705806732 seconds ---
batch_number = 60, loss = 1.488722, acc = 0.970304
--- 8963.917458057404 seconds ---
batch_number = 70, loss = 1.485776, acc = 0.970860
--- 8972.505380153656 seconds ---
batch_number = 80, loss = 1.494792, acc = 0.970679
--- 8979.63221859932 seconds ---
batch_number = 90, loss = 1.515175, acc = 0.969761
--- 8988.190274238586 seconds ---
batch_number = 100, loss = 1.525167, acc = 0.969375
--- 8997.436237335205 seconds ---
batch_number = 110, loss = 1.527017, acc = 0.969035
--- 9005.813316583633 seconds ---
batch_number = 120, loss = 1.533081, acc = 0.968653
--- 9014.816809654236 seconds ---
batch_number = 130, loss = 1.542369, acc = 0.968388
--- 9023.642765760422 seconds ---
batch_number = 140, loss = 1.540485, acc = 0.967812
--- 9031.852045297623 seconds ---
batch_number = 150, loss = 1.559004, acc = 0.966667
--- 9040.920487165451 seconds ---
batch_number = 160, loss = 1.563868, acc = 0.966471
[epoch 62]: train_loss = 0.198538, train_acc = 0.966469, validation_loss = 3.392518, validation_acc = 0.865380
--- 9056.903284788132 seconds ---
batch_number = 10, loss = 1.434677, acc = 0.964426
--- 9064.720866203308 seconds ---
batch_number = 20, loss = 1.482844, acc = 0.968180
--- 9073.948072195053 seconds ---
batch_number = 30, loss = 1.465951, acc = 0.970053
--- 9082.252219676971 seconds ---
batch_number = 40, loss = 1.492631, acc = 0.970125
--- 9091.96297287941 seconds ---
batch_number = 50, loss = 1.507780, acc = 0.969079
--- 9100.269164085388 seconds ---
batch_number = 60, loss = 1.522609, acc = 0.968359
--- 9108.713553667068 seconds ---
batch_number = 70, loss = 1.533105, acc = 0.967964
--- 9116.934910058975 seconds ---
batch_number = 80, loss = 1.544330, acc = 0.967476
--- 9126.357956647873 seconds ---
batch_number = 90, loss = 1.523612, acc = 0.967895
--- 9135.15100812912 seconds ---
batch_number = 100, loss = 1.531754, acc = 0.968037
--- 9143.15875864029 seconds ---
batch_number = 110, loss = 1.532769, acc = 0.967971
--- 9152.728471040726 seconds ---
batch_number = 120, loss = 1.529197, acc = 0.968118
--- 9160.835668087006 seconds ---
batch_number = 130, loss = 1.533982, acc = 0.967896
--- 9168.205609083176 seconds ---
batch_number = 140, loss = 1.543088, acc = 0.967666
--- 9177.127451658249 seconds ---
batch_number = 150, loss = 1.542903, acc = 0.967550
--- 9185.546490907669 seconds ---
batch_number = 160, loss = 1.544435, acc = 0.967585
[epoch 63]: train_loss = 0.196686, train_acc = 0.967074, validation_loss = 3.294189, validation_acc = 0.856708
--- 9200.481985330582 seconds ---
batch_number = 10, loss = 1.444199, acc = 0.961921
--- 9209.370989561081 seconds ---
batch_number = 20, loss = 1.441275, acc = 0.961144
--- 9218.680673837662 seconds ---
batch_number = 30, loss = 1.474188, acc = 0.962592
--- 9227.191546440125 seconds ---
batch_number = 40, loss = 1.485694, acc = 0.963734
--- 9235.589873552322 seconds ---
batch_number = 50, loss = 1.477718, acc = 0.965220
--- 9244.410700559616 seconds ---
batch_number = 60, loss = 1.469209, acc = 0.966299
--- 9254.123826026917 seconds ---
batch_number = 70, loss = 1.476597, acc = 0.967674
--- 9263.58901309967 seconds ---
batch_number = 80, loss = 1.479956, acc = 0.968226
--- 9273.036529779434 seconds ---
batch_number = 90, loss = 1.480467, acc = 0.968221
--- 9281.602042913437 seconds ---
batch_number = 100, loss = 1.477572, acc = 0.968757
--- 9290.654996156693 seconds ---
batch_number = 110, loss = 1.478109, acc = 0.969036
--- 9298.070482254028 seconds ---
batch_number = 120, loss = 1.485762, acc = 0.969099
--- 9307.763648748398 seconds ---
batch_number = 130, loss = 1.478012, acc = 0.969657
--- 9314.885452270508 seconds ---
batch_number = 140, loss = 1.483822, acc = 0.969447
--- 9324.398989915848 seconds ---
batch_number = 150, loss = 1.475333, acc = 0.969494
--- 9331.776918888092 seconds ---
batch_number = 160, loss = 1.487263, acc = 0.969508
[epoch 64]: train_loss = 0.187711, train_acc = 0.969451, validation_loss = 3.351455, validation_acc = 0.862700
--- 9349.55933022499 seconds ---
batch_number = 10, loss = 1.304796, acc = 0.970957
--- 9357.612737417221 seconds ---
batch_number = 20, loss = 1.353496, acc = 0.971310
--- 9366.240046262741 seconds ---
batch_number = 30, loss = 1.396300, acc = 0.971969
--- 9375.552443265915 seconds ---
batch_number = 40, loss = 1.394570, acc = 0.972133
--- 9383.786487340927 seconds ---
batch_number = 50, loss = 1.426777, acc = 0.972194
--- 9392.197870731354 seconds ---
batch_number = 60, loss = 1.434709, acc = 0.972123
--- 9401.082715511322 seconds ---
batch_number = 70, loss = 1.420838, acc = 0.972717
--- 9409.016059875488 seconds ---
batch_number = 80, loss = 1.421400, acc = 0.972810
--- 9417.62678861618 seconds ---
batch_number = 90, loss = 1.423889, acc = 0.972710
--- 9426.494836568832 seconds ---
batch_number = 100, loss = 1.419088, acc = 0.972434
--- 9434.787963628769 seconds ---
batch_number = 110, loss = 1.415025, acc = 0.972312
--- 9443.350738286972 seconds ---
batch_number = 120, loss = 1.426460, acc = 0.972064
--- 9452.70621085167 seconds ---
batch_number = 130, loss = 1.419443, acc = 0.972453
--- 9461.602015972137 seconds ---
batch_number = 140, loss = 1.412582, acc = 0.972745
--- 9471.484319448471 seconds ---
batch_number = 150, loss = 1.416895, acc = 0.972771
--- 9479.798860788345 seconds ---
batch_number = 160, loss = 1.417722, acc = 0.972812
[epoch 65]: train_loss = 0.180136, train_acc = 0.972635, validation_loss = 3.334827, validation_acc = 0.861703
--- 9496.643851041794 seconds ---
batch_number = 10, loss = 1.223040, acc = 0.972301
--- 9505.609221458435 seconds ---
batch_number = 20, loss = 1.303432, acc = 0.971454
--- 9513.80479669571 seconds ---
batch_number = 30, loss = 1.373704, acc = 0.972451
--- 9523.424113035202 seconds ---
batch_number = 40, loss = 1.375649, acc = 0.971892
--- 9533.006311655045 seconds ---
batch_number = 50, loss = 1.367339, acc = 0.972303
--- 9541.985806941986 seconds ---
batch_number = 60, loss = 1.375615, acc = 0.972849
--- 9551.80949831009 seconds ---
batch_number = 70, loss = 1.354762, acc = 0.973468
--- 9560.113066196442 seconds ---
batch_number = 80, loss = 1.352732, acc = 0.973703
--- 9568.758649110794 seconds ---
batch_number = 90, loss = 1.355079, acc = 0.973443
--- 9577.870770931244 seconds ---
batch_number = 100, loss = 1.348114, acc = 0.973859
--- 9585.33808350563 seconds ---
batch_number = 110, loss = 1.354090, acc = 0.974087
--- 9592.385459423065 seconds ---
batch_number = 120, loss = 1.362169, acc = 0.973837
--- 9600.896714925766 seconds ---
batch_number = 130, loss = 1.364925, acc = 0.973669
--- 9608.726532697678 seconds ---
batch_number = 140, loss = 1.372184, acc = 0.973601
--- 9617.473598718643 seconds ---
batch_number = 150, loss = 1.378831, acc = 0.973365
--- 9626.082416534424 seconds ---
batch_number = 160, loss = 1.379277, acc = 0.973248
[epoch 66]: train_loss = 0.175320, train_acc = 0.973221, validation_loss = 3.405556, validation_acc = 0.856613
--- 9641.746483325958 seconds ---
batch_number = 10, loss = 1.288271, acc = 0.973215
--- 9651.166889190674 seconds ---
batch_number = 20, loss = 1.298823, acc = 0.974832
--- 9660.037200689316 seconds ---
batch_number = 30, loss = 1.303156, acc = 0.974864
--- 9667.879983901978 seconds ---
batch_number = 40, loss = 1.329803, acc = 0.974382
--- 9676.573390483856 seconds ---
batch_number = 50, loss = 1.342009, acc = 0.973599
--- 9685.946115732193 seconds ---
batch_number = 60, loss = 1.346949, acc = 0.973528
--- 9693.139773845673 seconds ---
batch_number = 70, loss = 1.366155, acc = 0.973284
--- 9702.033508300781 seconds ---
batch_number = 80, loss = 1.370972, acc = 0.973428
--- 9711.109659433365 seconds ---
batch_number = 90, loss = 1.391886, acc = 0.971993
--- 9720.724546909332 seconds ---
batch_number = 100, loss = 1.411816, acc = 0.969874
--- 9728.914030790329 seconds ---
batch_number = 110, loss = 1.494509, acc = 0.965723
--- 9737.838906288147 seconds ---
batch_number = 120, loss = 1.560895, acc = 0.961905
--- 9746.742130756378 seconds ---
batch_number = 130, loss = 1.679399, acc = 0.953429
--- 9754.213300228119 seconds ---
batch_number = 140, loss = 1.852985, acc = 0.944841
--- 9763.27537226677 seconds ---
batch_number = 150, loss = 1.976504, acc = 0.938114
--- 9770.565675020218 seconds ---
batch_number = 160, loss = 2.111331, acc = 0.931527
[epoch 67]: train_loss = 0.294266, train_acc = 0.921273, validation_loss = 11.810158, validation_acc = 0.567486
--- 9787.110608577728 seconds ---
batch_number = 10, loss = 9.003597, acc = 0.573679
--- 9796.95866727829 seconds ---
batch_number = 20, loss = 8.546146, acc = 0.550049
--- 9804.113353967667 seconds ---
batch_number = 30, loss = 7.781802, acc = 0.610607
--- 9811.626105546951 seconds ---
batch_number = 40, loss = 7.592155, acc = 0.634221
--- 9820.264286994934 seconds ---
batch_number = 50, loss = 7.250375, acc = 0.655503
--- 9828.564865112305 seconds ---
batch_number = 60, loss = 6.911528, acc = 0.672613
--- 9837.85012125969 seconds ---
batch_number = 70, loss = 6.628859, acc = 0.684918
--- 9845.52099108696 seconds ---
batch_number = 80, loss = 6.298783, acc = 0.700987
--- 9853.640766382217 seconds ---
batch_number = 90, loss = 6.026219, acc = 0.718174
--- 9863.100105047226 seconds ---
batch_number = 100, loss = 5.791330, acc = 0.733578
--- 9871.414768695831 seconds ---
batch_number = 110, loss = 5.655447, acc = 0.745103
--- 9879.893282175064 seconds ---
batch_number = 120, loss = 5.542408, acc = 0.752260
--- 9888.430310249329 seconds ---
batch_number = 130, loss = 5.468028, acc = 0.754172
--- 9896.98564338684 seconds ---
batch_number = 140, loss = 5.426797, acc = 0.755117
--- 9906.087244987488 seconds ---
batch_number = 150, loss = 5.328313, acc = 0.761342
--- 9915.663642406464 seconds ---
batch_number = 160, loss = 5.210545, acc = 0.769639
[epoch 68]: train_loss = 0.648460, train_acc = 0.773194, validation_loss = 3.903628, validation_acc = 0.825323
--- 9931.906220912933 seconds ---
batch_number = 10, loss = 2.757445, acc = 0.915087
--- 9940.24900650978 seconds ---
batch_number = 20, loss = 2.753741, acc = 0.916614
--- 9949.018616437912 seconds ---
batch_number = 30, loss = 2.767688, acc = 0.920121
--- 9957.75126838684 seconds ---
batch_number = 40, loss = 2.756715, acc = 0.920414
--- 9968.442065238953 seconds ---
batch_number = 50, loss = 2.678329, acc = 0.921951
--- 9977.574543476105 seconds ---
batch_number = 60, loss = 2.869615, acc = 0.908262
--- 9985.629484653473 seconds ---
batch_number = 70, loss = 2.854915, acc = 0.909015
--- 9993.50911784172 seconds ---
batch_number = 80, loss = 2.818920, acc = 0.910980
--- 10003.797593593597 seconds ---
batch_number = 90, loss = 2.750637, acc = 0.914834
--- 10011.23323059082 seconds ---
batch_number = 100, loss = 2.708166, acc = 0.917301
--- 10020.168355464935 seconds ---
batch_number = 110, loss = 2.657511, acc = 0.919863
--- 10027.728474140167 seconds ---
batch_number = 120, loss = 2.623362, acc = 0.921868
--- 10036.839664936066 seconds ---
batch_number = 130, loss = 2.568380, acc = 0.924549
--- 10044.615615606308 seconds ---
batch_number = 140, loss = 2.542473, acc = 0.927028
--- 10053.343270778656 seconds ---
batch_number = 150, loss = 2.503695, acc = 0.928956
--- 10060.990114688873 seconds ---
batch_number = 160, loss = 2.476767, acc = 0.930370
[epoch 69]: train_loss = 0.310864, train_acc = 0.931278, validation_loss = 3.235638, validation_acc = 0.860723
--- 10078.637650728226 seconds ---
batch_number = 10, loss = 1.502409, acc = 0.962764
--- 10085.745102405548 seconds ---
batch_number = 20, loss = 1.796421, acc = 0.958256
--- 10094.077296733856 seconds ---
batch_number = 30, loss = 1.807872, acc = 0.959790
--- 10102.713622570038 seconds ---
batch_number = 40, loss = 1.777266, acc = 0.962016
--- 10111.768969774246 seconds ---
batch_number = 50, loss = 1.765092, acc = 0.963561
--- 10120.626688480377 seconds ---
batch_number = 60, loss = 1.749032, acc = 0.963372
--- 10130.6998128891 seconds ---
batch_number = 70, loss = 1.732503, acc = 0.964317
--- 10139.127035617828 seconds ---
batch_number = 80, loss = 1.724684, acc = 0.964624
--- 10146.727476596832 seconds ---
batch_number = 90, loss = 1.717759, acc = 0.964991
--- 10154.384692192078 seconds ---
batch_number = 100, loss = 1.732140, acc = 0.965109
--- 10163.336220502853 seconds ---
batch_number = 110, loss = 1.728237, acc = 0.964934
--- 10172.40700674057 seconds ---
batch_number = 120, loss = 1.721905, acc = 0.964963
--- 10182.220644950867 seconds ---
batch_number = 130, loss = 1.714620, acc = 0.965387
--- 10191.18871831894 seconds ---
batch_number = 140, loss = 1.716727, acc = 0.965257
--- 10199.624023914337 seconds ---
batch_number = 150, loss = 1.708863, acc = 0.965413
--- 10206.761722803116 seconds ---
batch_number = 160, loss = 1.713565, acc = 0.965765
[epoch 70]: train_loss = 0.217199, train_acc = 0.965914, validation_loss = 2.909741, validation_acc = 0.878281
--- 10224.059350013733 seconds ---
batch_number = 10, loss = 1.648904, acc = 0.965827
--- 10233.163923740387 seconds ---
batch_number = 20, loss = 1.582783, acc = 0.966612
--- 10240.851685523987 seconds ---
batch_number = 30, loss = 1.626906, acc = 0.966577
--- 10249.596084356308 seconds ---
batch_number = 40, loss = 1.617274, acc = 0.968313
--- 10257.320034265518 seconds ---
batch_number = 50, loss = 1.619428, acc = 0.968372
--- 10266.248499393463 seconds ---
batch_number = 60, loss = 1.596188, acc = 0.968874
--- 10274.645097494125 seconds ---
batch_number = 70, loss = 1.598339, acc = 0.969519
--- 10283.199482440948 seconds ---
batch_number = 80, loss = 1.579287, acc = 0.969798
--- 10292.421653747559 seconds ---
batch_number = 90, loss = 1.580419, acc = 0.970572
--- 10300.247970819473 seconds ---
batch_number = 100, loss = 1.579870, acc = 0.970665
--- 10308.043196439743 seconds ---
batch_number = 110, loss = 1.572447, acc = 0.970824
--- 10316.828830003738 seconds ---
batch_number = 120, loss = 1.572840, acc = 0.970699
--- 10328.267886161804 seconds ---
batch_number = 130, loss = 1.555051, acc = 0.971276
--- 10336.99096441269 seconds ---
batch_number = 140, loss = 1.547034, acc = 0.971489
--- 10344.009427547455 seconds ---
batch_number = 150, loss = 1.552460, acc = 0.971539
--- 10352.526142597198 seconds ---
batch_number = 160, loss = 1.552591, acc = 0.971777
[epoch 71]: train_loss = 0.196599, train_acc = 0.971837, validation_loss = 2.771756, validation_acc = 0.886611
--- 10369.049570560455 seconds ---
batch_number = 10, loss = 1.791141, acc = 0.943521
--- 10378.34183549881 seconds ---
batch_number = 20, loss = 1.912121, acc = 0.944222
--- 10387.479684591293 seconds ---
batch_number = 30, loss = 1.823858, acc = 0.948443
--- 10396.618288755417 seconds ---
batch_number = 40, loss = 1.783201, acc = 0.953135
--- 10404.197288751602 seconds ---
batch_number = 50, loss = 1.819766, acc = 0.953135
--- 10411.735748052597 seconds ---
batch_number = 60, loss = 1.822267, acc = 0.955147
--- 10420.19651889801 seconds ---
batch_number = 70, loss = 1.781349, acc = 0.957012
--- 10427.841454267502 seconds ---
batch_number = 80, loss = 1.752042, acc = 0.958441
--- 10438.024260997772 seconds ---
batch_number = 90, loss = 1.728892, acc = 0.960093
--- 10446.5760679245 seconds ---
batch_number = 100, loss = 1.716253, acc = 0.961405
--- 10455.198688030243 seconds ---
batch_number = 110, loss = 1.711635, acc = 0.961835
--- 10463.84194946289 seconds ---
batch_number = 120, loss = 1.690112, acc = 0.962607
--- 10472.115670919418 seconds ---
batch_number = 130, loss = 1.689466, acc = 0.962936
--- 10480.337114334106 seconds ---
batch_number = 140, loss = 1.678980, acc = 0.963347
--- 10488.040531396866 seconds ---
batch_number = 150, loss = 1.677235, acc = 0.963864
--- 10496.54334115982 seconds ---
batch_number = 160, loss = 1.663939, acc = 0.964580
[epoch 72]: train_loss = 0.209849, train_acc = 0.965028, validation_loss = 3.059047, validation_acc = 0.867421
--- 10516.10327243805 seconds ---
batch_number = 10, loss = 1.274078, acc = 0.974414
--- 10523.757458209991 seconds ---
batch_number = 20, loss = 1.412752, acc = 0.972755
--- 10531.375080347061 seconds ---
batch_number = 30, loss = 1.460799, acc = 0.972891
--- 10540.028013944626 seconds ---
batch_number = 40, loss = 1.483162, acc = 0.972850
--- 10548.8258228302 seconds ---
batch_number = 50, loss = 1.474755, acc = 0.973480
--- 10556.52797293663 seconds ---
batch_number = 60, loss = 1.491039, acc = 0.973028
--- 10565.080676555634 seconds ---
batch_number = 70, loss = 1.501446, acc = 0.972749
--- 10573.78451347351 seconds ---
batch_number = 80, loss = 1.493502, acc = 0.973368
--- 10582.9792470932 seconds ---
batch_number = 90, loss = 1.490293, acc = 0.973233
--- 10591.656927347183 seconds ---
batch_number = 100, loss = 1.475379, acc = 0.973461
--- 10599.957697868347 seconds ---
batch_number = 110, loss = 1.471122, acc = 0.973694
--- 10608.08382153511 seconds ---
batch_number = 120, loss = 1.472784, acc = 0.973716
--- 10615.554189920425 seconds ---
batch_number = 130, loss = 1.474305, acc = 0.973739
--- 10624.894429683685 seconds ---
batch_number = 140, loss = 1.472851, acc = 0.973495
--- 10633.363025188446 seconds ---
batch_number = 150, loss = 1.477923, acc = 0.973715
--- 10641.189410686493 seconds ---
batch_number = 160, loss = 1.473231, acc = 0.973815
[epoch 73]: train_loss = 0.185410, train_acc = 0.974008, validation_loss = 3.041185, validation_acc = 0.874546
--- 10659.23320031166 seconds ---
batch_number = 10, loss = 1.286244, acc = 0.975365
--- 10667.366936683655 seconds ---
batch_number = 20, loss = 1.365703, acc = 0.976082
--- 10675.10331773758 seconds ---
batch_number = 30, loss = 1.386386, acc = 0.975771
--- 10682.582934856415 seconds ---
batch_number = 40, loss = 1.362266, acc = 0.976611
--- 10691.791923999786 seconds ---
batch_number = 50, loss = 1.356634, acc = 0.977301
--- 10700.923598527908 seconds ---
batch_number = 60, loss = 1.362889, acc = 0.976848
--- 10708.813169956207 seconds ---
batch_number = 70, loss = 1.372781, acc = 0.976903
--- 10717.739995241165 seconds ---
batch_number = 80, loss = 1.387726, acc = 0.975963
--- 10726.882521152496 seconds ---
batch_number = 90, loss = 1.387528, acc = 0.975740
--- 10736.658740520477 seconds ---
batch_number = 100, loss = 1.380742, acc = 0.975873
--- 10745.146904706955 seconds ---
batch_number = 110, loss = 1.384659, acc = 0.975698
--- 10753.379173517227 seconds ---
batch_number = 120, loss = 1.385446, acc = 0.975648
--- 10762.688997745514 seconds ---
batch_number = 130, loss = 1.373864, acc = 0.975832
--- 10772.119700670242 seconds ---
batch_number = 140, loss = 1.366783, acc = 0.975969
--- 10780.839283704758 seconds ---
batch_number = 150, loss = 1.363591, acc = 0.976270
--- 10789.284331798553 seconds ---
batch_number = 160, loss = 1.365525, acc = 0.976475
[epoch 74]: train_loss = 0.172840, train_acc = 0.976439, validation_loss = 2.879048, validation_acc = 0.885768
--- 10806.148930072784 seconds ---
batch_number = 10, loss = 1.141455, acc = 0.975845
--- 10814.722876310349 seconds ---
batch_number = 20, loss = 1.193030, acc = 0.977609
--- 10823.321328401566 seconds ---
batch_number = 30, loss = 1.237526, acc = 0.978223
--- 10831.487220048904 seconds ---
batch_number = 40, loss = 1.263057, acc = 0.978115
--- 10841.641531705856 seconds ---
batch_number = 50, loss = 1.246502, acc = 0.978788
--- 10850.829048395157 seconds ---
batch_number = 60, loss = 1.261065, acc = 0.978945
--- 10860.035496473312 seconds ---
batch_number = 70, loss = 1.261625, acc = 0.978856
--- 10868.216327667236 seconds ---
batch_number = 80, loss = 1.282542, acc = 0.978036
--- 10874.863993644714 seconds ---
batch_number = 90, loss = 1.298390, acc = 0.977992
--- 10882.350250720978 seconds ---
batch_number = 100, loss = 1.316195, acc = 0.977868
--- 10890.433371782303 seconds ---
batch_number = 110, loss = 1.318365, acc = 0.977871
--- 10901.369181632996 seconds ---
batch_number = 120, loss = 1.308664, acc = 0.978044
--- 10909.977434158325 seconds ---
batch_number = 130, loss = 1.310654, acc = 0.978085
--- 10919.608702421188 seconds ---
batch_number = 140, loss = 1.306292, acc = 0.978025
--- 10927.437985897064 seconds ---
batch_number = 150, loss = 1.305948, acc = 0.978072
--- 10936.738476991653 seconds ---
batch_number = 160, loss = 1.304908, acc = 0.977891
[epoch 75]: train_loss = 0.165721, train_acc = 0.977770, validation_loss = 3.185745, validation_acc = 0.863107
--- 10953.782304525375 seconds ---
batch_number = 10, loss = 1.117521, acc = 0.979782
--- 10962.333531141281 seconds ---
batch_number = 20, loss = 1.215742, acc = 0.978377
--- 10969.697291851044 seconds ---
batch_number = 30, loss = 1.262268, acc = 0.978525
--- 10977.45736670494 seconds ---
batch_number = 40, loss = 1.279831, acc = 0.978944
--- 10986.54036641121 seconds ---
batch_number = 50, loss = 1.271617, acc = 0.979456
--- 10996.309893131256 seconds ---
batch_number = 60, loss = 1.269780, acc = 0.979215
--- 11003.383817434311 seconds ---
batch_number = 70, loss = 1.279221, acc = 0.979042
--- 11012.282553195953 seconds ---
batch_number = 80, loss = 1.288088, acc = 0.978634
--- 11021.326301813126 seconds ---
batch_number = 90, loss = 1.275044, acc = 0.978627
--- 11027.885388612747 seconds ---
batch_number = 100, loss = 1.296155, acc = 0.978309
--- 11036.356242895126 seconds ---
batch_number = 110, loss = 1.296289, acc = 0.978242
--- 11046.99369597435 seconds ---
batch_number = 120, loss = 1.291616, acc = 0.978600
--- 11055.379393815994 seconds ---
batch_number = 130, loss = 1.288625, acc = 0.978490
--- 11064.086406707764 seconds ---
batch_number = 140, loss = 1.289102, acc = 0.978176
--- 11073.232941150665 seconds ---
batch_number = 150, loss = 1.288882, acc = 0.977854
--- 11081.034456014633 seconds ---
batch_number = 160, loss = 1.293779, acc = 0.977563
[epoch 76]: train_loss = 0.163207, train_acc = 0.977493, validation_loss = 3.282339, validation_acc = 0.869010
--- 11098.402822256088 seconds ---
batch_number = 10, loss = 1.240405, acc = 0.968308
--- 11107.33969426155 seconds ---
batch_number = 20, loss = 1.248266, acc = 0.970941
--- 11116.901103973389 seconds ---
batch_number = 30, loss = 1.274555, acc = 0.972978
--- 11125.510608911514 seconds ---
batch_number = 40, loss = 1.269912, acc = 0.975082
--- 11133.712105989456 seconds ---
batch_number = 50, loss = 1.275135, acc = 0.975830
--- 11142.45939040184 seconds ---
batch_number = 60, loss = 1.273150, acc = 0.976535
--- 11150.787713050842 seconds ---
batch_number = 70, loss = 1.275376, acc = 0.976838
--- 11159.203255414963 seconds ---
batch_number = 80, loss = 1.273425, acc = 0.977033
--- 11167.371700286865 seconds ---
batch_number = 90, loss = 1.284844, acc = 0.976883
--- 11175.58991098404 seconds ---
batch_number = 100, loss = 1.278692, acc = 0.977071
--- 11183.654705762863 seconds ---
batch_number = 110, loss = 1.283244, acc = 0.977097
--- 11192.583484649658 seconds ---
batch_number = 120, loss = 1.295994, acc = 0.976773
--- 11200.01352763176 seconds ---
batch_number = 130, loss = 1.346548, acc = 0.974237
--- 11208.654163122177 seconds ---
batch_number = 140, loss = 1.379418, acc = 0.972076
--- 11217.258529424667 seconds ---
batch_number = 150, loss = 1.404306, acc = 0.971132
--- 11226.426455497742 seconds ---
batch_number = 160, loss = 1.429011, acc = 0.969284
[epoch 77]: train_loss = 0.182003, train_acc = 0.968904, validation_loss = 3.575468, validation_acc = 0.857971
--- 11243.794903755188 seconds ---
batch_number = 10, loss = 1.540630, acc = 0.951195
--- 11251.917197465897 seconds ---
batch_number = 20, loss = 1.713256, acc = 0.949421
--- 11260.497797966003 seconds ---
batch_number = 30, loss = 1.993623, acc = 0.933872
--- 11269.928827762604 seconds ---
batch_number = 40, loss = 2.009814, acc = 0.932048
--- 11277.50732588768 seconds ---
batch_number = 50, loss = 2.023088, acc = 0.929883
--- 11286.050878286362 seconds ---
batch_number = 60, loss = 2.021538, acc = 0.930984
--- 11294.675429582596 seconds ---
batch_number = 70, loss = 1.989446, acc = 0.935311
--- 11303.753926038742 seconds ---
batch_number = 80, loss = 1.974699, acc = 0.935976
--- 11311.153399705887 seconds ---
batch_number = 90, loss = 1.993240, acc = 0.936228
--- 11318.220655202866 seconds ---
batch_number = 100, loss = 2.017949, acc = 0.936000
--- 11327.254923343658 seconds ---
batch_number = 110, loss = 2.007757, acc = 0.936821
--- 11336.87924027443 seconds ---
batch_number = 120, loss = 1.987438, acc = 0.938820
--- 11346.2738571167 seconds ---
batch_number = 130, loss = 1.979484, acc = 0.939495
--- 11354.087757825851 seconds ---
batch_number = 140, loss = 1.990550, acc = 0.939023
--- 11363.365919828415 seconds ---
batch_number = 150, loss = 1.993366, acc = 0.938394
--- 11370.629130125046 seconds ---
batch_number = 160, loss = 1.995759, acc = 0.938334
[epoch 78]: train_loss = 0.250236, train_acc = 0.938915, validation_loss = 3.587650, validation_acc = 0.855155
--- 11389.063903093338 seconds ---
batch_number = 10, loss = 1.457363, acc = 0.959456
--- 11395.333136320114 seconds ---
batch_number = 20, loss = 1.755442, acc = 0.953108
--- 11405.780598402023 seconds ---
batch_number = 30, loss = 1.846798, acc = 0.945091
--- 11414.1256275177 seconds ---
batch_number = 40, loss = 2.112253, acc = 0.935276
--- 11423.827497720718 seconds ---
batch_number = 50, loss = 2.427085, acc = 0.920518
--- 11431.814574480057 seconds ---
batch_number = 60, loss = 2.562630, acc = 0.912775
--- 11438.999290943146 seconds ---
batch_number = 70, loss = 3.037170, acc = 0.896151
--- 11447.17721581459 seconds ---
batch_number = 80, loss = 3.863038, acc = 0.853173
--- 11455.23396897316 seconds ---
batch_number = 90, loss = 4.111927, acc = 0.839212
--- 11463.347569465637 seconds ---
batch_number = 100, loss = 4.336203, acc = 0.825884
--- 11471.967275619507 seconds ---
batch_number = 110, loss = 4.465760, acc = 0.815271
--- 11481.266124248505 seconds ---
batch_number = 120, loss = 4.508214, acc = 0.815126
--- 11489.809849977493 seconds ---
batch_number = 130, loss = 4.476183, acc = 0.817532
--- 11498.38038277626 seconds ---
batch_number = 140, loss = 4.491593, acc = 0.818797
--- 11507.128906488419 seconds ---
batch_number = 150, loss = 4.450894, acc = 0.819608
--- 11515.253131866455 seconds ---
batch_number = 160, loss = 4.403024, acc = 0.823054
[epoch 79]: train_loss = 0.550479, train_acc = 0.826062, validation_loss = 4.357675, validation_acc = 0.825988
--- 11532.014623880386 seconds ---
batch_number = 10, loss = 2.643077, acc = 0.915796
--- 11540.89649105072 seconds ---
batch_number = 20, loss = 2.704434, acc = 0.920252
--- 11550.417226076126 seconds ---
batch_number = 30, loss = 2.590366, acc = 0.925690
--- 11558.620485305786 seconds ---
batch_number = 40, loss = 2.537415, acc = 0.928019
--- 11566.226766824722 seconds ---
batch_number = 50, loss = 2.512793, acc = 0.930838
--- 11573.820979118347 seconds ---
batch_number = 60, loss = 2.472734, acc = 0.933045
--- 11583.31586098671 seconds ---
batch_number = 70, loss = 2.414745, acc = 0.937811
--- 11591.125274658203 seconds ---
batch_number = 80, loss = 2.402994, acc = 0.939005
--- 11600.720736980438 seconds ---
batch_number = 90, loss = 2.338367, acc = 0.941054
--- 11608.278500556946 seconds ---
batch_number = 100, loss = 2.334839, acc = 0.941142
--- 11616.071052789688 seconds ---
batch_number = 110, loss = 2.309678, acc = 0.942053
--- 11625.443578243256 seconds ---
batch_number = 120, loss = 2.275069, acc = 0.943308
--- 11633.318895578384 seconds ---
batch_number = 130, loss = 2.261327, acc = 0.943596
--- 11642.490902662277 seconds ---
batch_number = 140, loss = 2.230729, acc = 0.944724
--- 11651.024606704712 seconds ---
batch_number = 150, loss = 2.208810, acc = 0.945523
--- 11659.486690282822 seconds ---
batch_number = 160, loss = 2.188127, acc = 0.946449
[epoch 80]: train_loss = 0.275156, train_acc = 0.946687, validation_loss = 3.501692, validation_acc = 0.842211
--- 11678.794072628021 seconds ---
batch_number = 10, loss = 1.603172, acc = 0.968835
--- 11687.48840379715 seconds ---
batch_number = 20, loss = 1.678303, acc = 0.967955
--- 11696.312340259552 seconds ---
batch_number = 30, loss = 1.691320, acc = 0.968172
--- 11704.363369226456 seconds ---
batch_number = 40, loss = 1.673223, acc = 0.967931
--- 11713.059433698654 seconds ---
batch_number = 50, loss = 1.656786, acc = 0.969006
--- 11720.920927762985 seconds ---
batch_number = 60, loss = 1.648018, acc = 0.968714
--- 11729.167189836502 seconds ---
batch_number = 70, loss = 1.647374, acc = 0.969388
--- 11737.67059803009 seconds ---
batch_number = 80, loss = 1.637215, acc = 0.970015
--- 11746.787322759628 seconds ---
batch_number = 90, loss = 1.628947, acc = 0.969853
--- 11756.380947589874 seconds ---
batch_number = 100, loss = 1.625487, acc = 0.969889
--- 11765.346931695938 seconds ---
batch_number = 110, loss = 1.610785, acc = 0.969928
--- 11773.01068353653 seconds ---
batch_number = 120, loss = 1.610298, acc = 0.970153
--- 11781.67722272873 seconds ---
batch_number = 130, loss = 1.603096, acc = 0.970347
--- 11789.756305217743 seconds ---
batch_number = 140, loss = 1.607105, acc = 0.970160
--- 11799.099110364914 seconds ---
batch_number = 150, loss = 1.598695, acc = 0.970265
--- 11807.08058810234 seconds ---
batch_number = 160, loss = 1.601729, acc = 0.969935
[epoch 81]: train_loss = 0.202524, train_acc = 0.969798, validation_loss = 3.376873, validation_acc = 0.859114
--- 11823.625599622726 seconds ---
batch_number = 10, loss = 1.495787, acc = 0.969084
--- 11832.344567775726 seconds ---
batch_number = 20, loss = 1.619279, acc = 0.965878
--- 11841.238265037537 seconds ---
batch_number = 30, loss = 1.571603, acc = 0.966737
--- 11851.133753538132 seconds ---
batch_number = 40, loss = 1.528941, acc = 0.968183
--- 11860.223425865173 seconds ---
batch_number = 50, loss = 1.530666, acc = 0.969420
--- 11867.446983098984 seconds ---
batch_number = 60, loss = 1.514845, acc = 0.970576
--- 11875.75437426567 seconds ---
batch_number = 70, loss = 1.500646, acc = 0.971580
--- 11883.830891370773 seconds ---
batch_number = 80, loss = 1.492620, acc = 0.972047
--- 11892.433621644974 seconds ---
batch_number = 90, loss = 1.487463, acc = 0.972194
--- 11900.336625814438 seconds ---
batch_number = 100, loss = 1.495933, acc = 0.972498
--- 11907.79051232338 seconds ---
batch_number = 110, loss = 1.495909, acc = 0.972444
--- 11915.859215021133 seconds ---
batch_number = 120, loss = 1.494811, acc = 0.972920
--- 11924.706199407578 seconds ---
batch_number = 130, loss = 1.485580, acc = 0.973322
--- 11933.005997180939 seconds ---
batch_number = 140, loss = 1.475909, acc = 0.973721
--- 11941.172131061554 seconds ---
batch_number = 150, loss = 1.478148, acc = 0.973883
--- 11950.218168020248 seconds ---
batch_number = 160, loss = 1.475039, acc = 0.974022
[epoch 82]: train_loss = 0.185753, train_acc = 0.974137, validation_loss = 3.216936, validation_acc = 0.872820
--- 11969.745087862015 seconds ---
batch_number = 10, loss = 1.214168, acc = 0.981676
--- 11977.792824983597 seconds ---
batch_number = 20, loss = 1.307993, acc = 0.980366
--- 11985.762047290802 seconds ---
batch_number = 30, loss = 1.314291, acc = 0.979948
--- 11993.945927619934 seconds ---
batch_number = 40, loss = 1.332803, acc = 0.979733
--- 12001.554152488708 seconds ---
batch_number = 50, loss = 1.341083, acc = 0.978964
--- 12010.797929048538 seconds ---
batch_number = 60, loss = 1.334960, acc = 0.979124
--- 12018.807639360428 seconds ---
batch_number = 70, loss = 1.329323, acc = 0.979366
--- 12027.95780467987 seconds ---
batch_number = 80, loss = 1.323306, acc = 0.979577
--- 12037.007731676102 seconds ---
batch_number = 90, loss = 1.324336, acc = 0.979707
--- 12045.149478673935 seconds ---
batch_number = 100, loss = 1.327652, acc = 0.979763
--- 12053.00228691101 seconds ---
batch_number = 110, loss = 1.334633, acc = 0.979386
--- 12061.50488114357 seconds ---
batch_number = 120, loss = 1.340053, acc = 0.979208
--- 12070.397164106369 seconds ---
batch_number = 130, loss = 1.342914, acc = 0.979188
--- 12078.947724819183 seconds ---
batch_number = 140, loss = 1.344654, acc = 0.979089
--- 12088.215203762054 seconds ---
batch_number = 150, loss = 1.332463, acc = 0.979137
--- 12097.331320047379 seconds ---
batch_number = 160, loss = 1.328431, acc = 0.979203
[epoch 83]: train_loss = 0.168380, train_acc = 0.979214, validation_loss = 3.137858, validation_acc = 0.873670
--- 12113.834217786789 seconds ---
batch_number = 10, loss = 1.193562, acc = 0.982524
--- 12122.564963817596 seconds ---
batch_number = 20, loss = 1.245172, acc = 0.981436
--- 12130.472627401352 seconds ---
batch_number = 30, loss = 1.272380, acc = 0.980362
--- 12139.848156452179 seconds ---
batch_number = 40, loss = 1.279255, acc = 0.981778
--- 12147.444314718246 seconds ---
batch_number = 50, loss = 1.288991, acc = 0.981391
--- 12155.980486154556 seconds ---
batch_number = 60, loss = 1.288606, acc = 0.981335
--- 12164.670390367508 seconds ---
batch_number = 70, loss = 1.274070, acc = 0.981112
--- 12174.01196026802 seconds ---
batch_number = 80, loss = 1.275245, acc = 0.981007
--- 12183.75669002533 seconds ---
batch_number = 90, loss = 1.273196, acc = 0.981119
--- 12191.558675050735 seconds ---
batch_number = 100, loss = 1.282693, acc = 0.980989
--- 12200.434669017792 seconds ---
batch_number = 110, loss = 1.282812, acc = 0.981100
--- 12209.478922843933 seconds ---
batch_number = 120, loss = 1.282236, acc = 0.980847
--- 12217.49040055275 seconds ---
batch_number = 130, loss = 1.280861, acc = 0.980834
--- 12226.032263755798 seconds ---
batch_number = 140, loss = 1.279588, acc = 0.980631
--- 12234.843067407608 seconds ---
batch_number = 150, loss = 1.276786, acc = 0.980462
--- 12241.857622861862 seconds ---
batch_number = 160, loss = 1.279167, acc = 0.980430
[epoch 84]: train_loss = 0.161831, train_acc = 0.980562, validation_loss = 3.240624, validation_acc = 0.869854
--- 12259.218026161194 seconds ---
batch_number = 10, loss = 1.077132, acc = 0.980270
--- 12267.327500104904 seconds ---
batch_number = 20, loss = 1.164496, acc = 0.979884
--- 12276.320393323898 seconds ---
batch_number = 30, loss = 1.164554, acc = 0.980334
--- 12285.649510622025 seconds ---
batch_number = 40, loss = 1.160257, acc = 0.980415
--- 12294.118939638138 seconds ---
batch_number = 50, loss = 1.154204, acc = 0.980991
--- 12302.409015893936 seconds ---
batch_number = 60, loss = 1.179752, acc = 0.980963
--- 12310.315371990204 seconds ---
batch_number = 70, loss = 1.195548, acc = 0.980864
--- 12319.476729631424 seconds ---
batch_number = 80, loss = 1.201954, acc = 0.980865
--- 12329.379127264023 seconds ---
batch_number = 90, loss = 1.191935, acc = 0.980943
--- 12337.470568656921 seconds ---
batch_number = 100, loss = 1.198672, acc = 0.980581
--- 12345.944486618042 seconds ---
batch_number = 110, loss = 1.209882, acc = 0.980511
--- 12353.475784778595 seconds ---
batch_number = 120, loss = 1.227897, acc = 0.980019
--- 12363.297918081284 seconds ---
batch_number = 130, loss = 1.227521, acc = 0.979905
--- 12372.128535747528 seconds ---
batch_number = 140, loss = 1.226084, acc = 0.980072
--- 12380.243073940277 seconds ---
batch_number = 150, loss = 1.228967, acc = 0.980170
--- 12389.893543481827 seconds ---
batch_number = 160, loss = 1.223807, acc = 0.980261
[epoch 85]: train_loss = 0.154664, train_acc = 0.980374, validation_loss = 3.223253, validation_acc = 0.866295
--- 12406.359133720398 seconds ---
batch_number = 10, loss = 1.108071, acc = 0.982231
--- 12414.795654535294 seconds ---
batch_number = 20, loss = 1.218376, acc = 0.981471
--- 12423.8655667305 seconds ---
batch_number = 30, loss = 1.191734, acc = 0.981859
--- 12432.561367750168 seconds ---
batch_number = 40, loss = 1.174200, acc = 0.982217
--- 12441.79321527481 seconds ---
batch_number = 50, loss = 1.170211, acc = 0.982581
--- 12449.766805887222 seconds ---
batch_number = 60, loss = 1.180763, acc = 0.982106
--- 12458.846954584122 seconds ---
batch_number = 70, loss = 1.166384, acc = 0.982356
--- 12467.196859836578 seconds ---
batch_number = 80, loss = 1.171407, acc = 0.982312
--- 12475.78256559372 seconds ---
batch_number = 90, loss = 1.176248, acc = 0.982354
--- 12483.942975759506 seconds ---
batch_number = 100, loss = 1.185543, acc = 0.982041
--- 12493.745894670486 seconds ---
batch_number = 110, loss = 1.178101, acc = 0.982257
--- 12503.187454938889 seconds ---
batch_number = 120, loss = 1.180500, acc = 0.982355
--- 12510.703219175339 seconds ---
batch_number = 130, loss = 1.187837, acc = 0.982217
--- 12518.56704902649 seconds ---
batch_number = 140, loss = 1.202106, acc = 0.981707
--- 12528.143060922623 seconds ---
batch_number = 150, loss = 1.203719, acc = 0.981275
--- 12536.860575675964 seconds ---
batch_number = 160, loss = 1.202894, acc = 0.981090
[epoch 86]: train_loss = 0.153071, train_acc = 0.980900, validation_loss = 3.329892, validation_acc = 0.860648
--- 12551.697826385498 seconds ---
batch_number = 10, loss = 1.194908, acc = 0.977067
--- 12559.756638765335 seconds ---
batch_number = 20, loss = 1.259332, acc = 0.980389
--- 12569.103492498398 seconds ---
batch_number = 30, loss = 1.219735, acc = 0.979777
--- 12577.190671682358 seconds ---
batch_number = 40, loss = 1.228442, acc = 0.978856
--- 12585.41541838646 seconds ---
batch_number = 50, loss = 1.221706, acc = 0.978879
--- 12594.245485067368 seconds ---
batch_number = 60, loss = 1.225131, acc = 0.979563
--- 12603.393316984177 seconds ---
batch_number = 70, loss = 1.216928, acc = 0.980055
--- 12610.849878311157 seconds ---
batch_number = 80, loss = 1.231321, acc = 0.980202
--- 12619.866055488586 seconds ---
batch_number = 90, loss = 1.230604, acc = 0.980138
--- 12628.26606798172 seconds ---
batch_number = 100, loss = 1.222906, acc = 0.980203
--- 12636.401639938354 seconds ---
batch_number = 110, loss = 1.214185, acc = 0.980331
--- 12645.357253551483 seconds ---
batch_number = 120, loss = 1.213179, acc = 0.980375
--- 12655.596167564392 seconds ---
batch_number = 130, loss = 1.206948, acc = 0.980485
--- 12663.601204156876 seconds ---
batch_number = 140, loss = 1.210057, acc = 0.980134
--- 12673.000348806381 seconds ---
batch_number = 150, loss = 1.199491, acc = 0.980302
--- 12682.271027565002 seconds ---
batch_number = 160, loss = 1.192913, acc = 0.980249
[epoch 87]: train_loss = 0.152036, train_acc = 0.980208, validation_loss = 3.385955, validation_acc = 0.868274
--- 12698.592051029205 seconds ---
batch_number = 10, loss = 1.027056, acc = 0.979909
--- 12707.13731098175 seconds ---
batch_number = 20, loss = 1.121492, acc = 0.979069
--- 12716.757765054703 seconds ---
batch_number = 30, loss = 1.097667, acc = 0.979555
--- 12723.981095790863 seconds ---
batch_number = 40, loss = 1.140450, acc = 0.979719
--- 12730.742646217346 seconds ---
batch_number = 50, loss = 1.183060, acc = 0.979031
--- 12739.732764720917 seconds ---
batch_number = 60, loss = 1.193895, acc = 0.978448
--- 12748.164001464844 seconds ---
batch_number = 70, loss = 1.203085, acc = 0.977712
--- 12756.309031963348 seconds ---
batch_number = 80, loss = 1.229561, acc = 0.976745
--- 12765.84897017479 seconds ---
batch_number = 90, loss = 1.223392, acc = 0.976768
--- 12774.789796113968 seconds ---
batch_number = 100, loss = 1.226183, acc = 0.976820
--- 12782.594150781631 seconds ---
batch_number = 110, loss = 1.243749, acc = 0.976440
--- 12791.516030788422 seconds ---
batch_number = 120, loss = 1.244841, acc = 0.976564
--- 12800.832540273666 seconds ---
batch_number = 130, loss = 1.241096, acc = 0.976745
--- 12810.401681184769 seconds ---
batch_number = 140, loss = 1.239118, acc = 0.976837
--- 12819.48559308052 seconds ---
batch_number = 150, loss = 1.238273, acc = 0.977076
--- 12827.924850702286 seconds ---
batch_number = 160, loss = 1.246388, acc = 0.977011
[epoch 88]: train_loss = 0.158805, train_acc = 0.976798, validation_loss = 3.233582, validation_acc = 0.862094
--- 12842.089807987213 seconds ---
batch_number = 10, loss = 1.873403, acc = 0.950005
--- 12850.574100732803 seconds ---
batch_number = 20, loss = 1.950395, acc = 0.942713
--- 12858.421399593353 seconds ---
batch_number = 30, loss = 1.904805, acc = 0.947004
--- 12866.745885372162 seconds ---
batch_number = 40, loss = 1.834743, acc = 0.948796
--- 12875.518008708954 seconds ---
batch_number = 50, loss = 1.759586, acc = 0.953309
--- 12885.507502317429 seconds ---
batch_number = 60, loss = 1.699535, acc = 0.955222
--- 12894.37405705452 seconds ---
batch_number = 70, loss = 1.650418, acc = 0.957913
--- 12903.306778907776 seconds ---
batch_number = 80, loss = 1.612398, acc = 0.959919
--- 12913.024808168411 seconds ---
batch_number = 90, loss = 1.570878, acc = 0.961177
--- 12920.905910253525 seconds ---
batch_number = 100, loss = 1.549055, acc = 0.962000
--- 12929.661440610886 seconds ---
batch_number = 110, loss = 1.536558, acc = 0.962851
--- 12938.77421784401 seconds ---
batch_number = 120, loss = 1.511798, acc = 0.963754
--- 12948.445223808289 seconds ---
batch_number = 130, loss = 1.487755, acc = 0.964789
--- 12955.855482578278 seconds ---
batch_number = 140, loss = 1.475200, acc = 0.965040
--- 12963.75024008751 seconds ---
batch_number = 150, loss = 1.465191, acc = 0.965428
--- 12972.49967622757 seconds ---
batch_number = 160, loss = 1.452955, acc = 0.966138
[epoch 89]: train_loss = 0.183037, train_acc = 0.966411, validation_loss = 3.482656, validation_acc = 0.860642
--- 12989.709393024445 seconds ---
batch_number = 10, loss = 1.044367, acc = 0.978179
--- 12997.448485851288 seconds ---
batch_number = 20, loss = 1.231489, acc = 0.972478
--- 13005.337443590164 seconds ---
batch_number = 30, loss = 1.269883, acc = 0.972283
--- 13014.263242959976 seconds ---
batch_number = 40, loss = 1.297236, acc = 0.972378
--- 13022.44757437706 seconds ---
batch_number = 50, loss = 1.331479, acc = 0.972333
--- 13031.085615158081 seconds ---
batch_number = 60, loss = 1.331637, acc = 0.973022
--- 13038.101493120193 seconds ---
batch_number = 70, loss = 1.336143, acc = 0.972842
--- 13047.90982246399 seconds ---
batch_number = 80, loss = 1.326616, acc = 0.973086
--- 13057.110912799835 seconds ---
batch_number = 90, loss = 1.318303, acc = 0.973317
--- 13065.630569696426 seconds ---
batch_number = 100, loss = 1.311552, acc = 0.973381
--- 13074.130821466446 seconds ---
batch_number = 110, loss = 1.301850, acc = 0.973757
--- 13082.500697851181 seconds ---
batch_number = 120, loss = 1.300232, acc = 0.974062
--- 13091.740271091461 seconds ---
batch_number = 130, loss = 1.292401, acc = 0.974463
--- 13100.278704166412 seconds ---
batch_number = 140, loss = 1.289283, acc = 0.974678
--- 13110.437675476074 seconds ---
batch_number = 150, loss = 1.286227, acc = 0.974564
--- 13117.771881341934 seconds ---
batch_number = 160, loss = 1.285949, acc = 0.974572
[epoch 90]: train_loss = 0.163336, train_acc = 0.974613, validation_loss = 3.321885, validation_acc = 0.867275
--- 13136.275846719742 seconds ---
batch_number = 10, loss = 1.150115, acc = 0.975295
--- 13143.439555644989 seconds ---
batch_number = 20, loss = 1.277847, acc = 0.972155
--- 13152.4097738266 seconds ---
batch_number = 30, loss = 1.259188, acc = 0.973970
--- 13159.756865024567 seconds ---
batch_number = 40, loss = 1.256107, acc = 0.975211
--- 13168.182201385498 seconds ---
batch_number = 50, loss = 1.255133, acc = 0.975793
--- 13176.799106121063 seconds ---
batch_number = 60, loss = 1.244785, acc = 0.976478
--- 13185.485711097717 seconds ---
batch_number = 70, loss = 1.248249, acc = 0.976672
--- 13194.298900604248 seconds ---
batch_number = 80, loss = 1.241689, acc = 0.976904
--- 13203.366161108017 seconds ---
batch_number = 90, loss = 1.230822, acc = 0.977381
--- 13212.504375219345 seconds ---
batch_number = 100, loss = 1.220377, acc = 0.978045
--- 13221.160136461258 seconds ---
batch_number = 110, loss = 1.217999, acc = 0.978338
--- 13228.134712696075 seconds ---
batch_number = 120, loss = 1.227010, acc = 0.978371
--- 13236.364282369614 seconds ---
batch_number = 130, loss = 1.226260, acc = 0.978285
--- 13245.258912563324 seconds ---
batch_number = 140, loss = 1.227416, acc = 0.977975
--- 13253.386056423187 seconds ---
batch_number = 150, loss = 1.225954, acc = 0.977927
--- 13261.30888223648 seconds ---
batch_number = 160, loss = 1.227251, acc = 0.977912
[epoch 91]: train_loss = 0.154923, train_acc = 0.977865, validation_loss = 3.263790, validation_acc = 0.868258
--- 13278.150002002716 seconds ---
batch_number = 10, loss = 1.116589, acc = 0.977207
--- 13286.553683519363 seconds ---
batch_number = 20, loss = 1.145623, acc = 0.977893
--- 13295.747097730637 seconds ---
batch_number = 30, loss = 1.146576, acc = 0.978325
--- 13302.686989307404 seconds ---
batch_number = 40, loss = 1.175643, acc = 0.977712
--- 13312.23000717163 seconds ---
batch_number = 50, loss = 1.178151, acc = 0.977525
--- 13321.825476884842 seconds ---
batch_number = 60, loss = 1.178558, acc = 0.978337
--- 13330.83946466446 seconds ---
batch_number = 70, loss = 1.174473, acc = 0.978128
--- 13337.936910152435 seconds ---
batch_number = 80, loss = 1.190887, acc = 0.977680
--- 13347.155420780182 seconds ---
batch_number = 90, loss = 1.197882, acc = 0.977097
--- 13356.938723564148 seconds ---
batch_number = 100, loss = 1.194412, acc = 0.976913
--- 13365.493474960327 seconds ---
batch_number = 110, loss = 1.214918, acc = 0.975708
--- 13373.31500530243 seconds ---
batch_number = 120, loss = 1.243585, acc = 0.974675
--- 13382.149462461472 seconds ---
batch_number = 130, loss = 1.285900, acc = 0.973015
--- 13391.467232704163 seconds ---
batch_number = 140, loss = 1.306359, acc = 0.971420
--- 13400.052716255188 seconds ---
batch_number = 150, loss = 1.313789, acc = 0.970719
--- 13409.216796875 seconds ---
batch_number = 160, loss = 1.326415, acc = 0.970417
[epoch 92]: train_loss = 0.168282, train_acc = 0.970394, validation_loss = 3.403101, validation_acc = 0.868896
--- 13423.397468805313 seconds ---
batch_number = 10, loss = 1.335352, acc = 0.967574
--- 13431.052682638168 seconds ---
batch_number = 20, loss = 1.364051, acc = 0.967240
--- 13440.19915676117 seconds ---
batch_number = 30, loss = 1.431502, acc = 0.963619
--- 13449.601077795029 seconds ---
batch_number = 40, loss = 1.424794, acc = 0.963690
--- 13457.12673163414 seconds ---
batch_number = 50, loss = 1.512071, acc = 0.959934
--- 13464.701721429825 seconds ---
batch_number = 60, loss = 1.582495, acc = 0.958482
--- 13473.358103990555 seconds ---
batch_number = 70, loss = 1.623516, acc = 0.955802
--- 13482.510574817657 seconds ---
batch_number = 80, loss = 1.606619, acc = 0.956458
--- 13490.627264738083 seconds ---
batch_number = 90, loss = 1.596917, acc = 0.957231
--- 13499.59175992012 seconds ---
batch_number = 100, loss = 1.575764, acc = 0.958302
--- 13507.6799659729 seconds ---
batch_number = 110, loss = 1.566508, acc = 0.958532
--- 13516.545396327972 seconds ---
batch_number = 120, loss = 1.559485, acc = 0.959153
--- 13524.863776445389 seconds ---
batch_number = 130, loss = 1.575330, acc = 0.957634
--- 13533.498993873596 seconds ---
batch_number = 140, loss = 1.588112, acc = 0.957427
--- 13543.315008878708 seconds ---
batch_number = 150, loss = 1.583570, acc = 0.957585
--- 13551.34935760498 seconds ---
batch_number = 160, loss = 1.589191, acc = 0.957347
[epoch 93]: train_loss = 0.200283, train_acc = 0.957779, validation_loss = 3.567657, validation_acc = 0.859179
--- 13569.007436275482 seconds ---
batch_number = 10, loss = 1.292715, acc = 0.965660
--- 13579.126945495605 seconds ---
batch_number = 20, loss = 1.536991, acc = 0.958640
--- 13586.954952716827 seconds ---
batch_number = 30, loss = 1.602220, acc = 0.957871
--- 13595.785343408585 seconds ---
batch_number = 40, loss = 1.574927, acc = 0.958149
--- 13605.395963430405 seconds ---
batch_number = 50, loss = 1.525873, acc = 0.959936
--- 13612.4737637043 seconds ---
batch_number = 60, loss = 1.545955, acc = 0.959545
--- 13621.24424123764 seconds ---
batch_number = 70, loss = 1.556032, acc = 0.959601
--- 13629.290718317032 seconds ---
batch_number = 80, loss = 1.564949, acc = 0.959477
--- 13638.559709787369 seconds ---
batch_number = 90, loss = 1.544617, acc = 0.960488
--- 13646.764866828918 seconds ---
batch_number = 100, loss = 1.554357, acc = 0.959954
--- 13655.502497673035 seconds ---
batch_number = 110, loss = 1.575544, acc = 0.958493
--- 13665.28100514412 seconds ---
batch_number = 120, loss = 1.593376, acc = 0.957757
--- 13673.669495105743 seconds ---
batch_number = 130, loss = 1.602678, acc = 0.957147
--- 13681.395280361176 seconds ---
batch_number = 140, loss = 1.637811, acc = 0.955863
--- 13690.51684999466 seconds ---
batch_number = 150, loss = 1.664188, acc = 0.954147
--- 13699.460677862167 seconds ---
batch_number = 160, loss = 1.743688, acc = 0.950326
[epoch 94]: train_loss = 0.236589, train_acc = 0.945871, validation_loss = 7.146102, validation_acc = 0.663841
--- 13716.102083921432 seconds ---
batch_number = 10, loss = 5.914231, acc = 0.721348
--- 13725.353712320328 seconds ---
batch_number = 20, loss = 5.877047, acc = 0.732268
--- 13734.204457521439 seconds ---
batch_number = 30, loss = 5.746373, acc = 0.733282
--- 13743.436134338379 seconds ---
batch_number = 40, loss = 5.409926, acc = 0.759871
--- 13752.36959695816 seconds ---
batch_number = 50, loss = 5.367914, acc = 0.764563
--- 13759.352695703506 seconds ---
batch_number = 60, loss = 5.445086, acc = 0.762612
--- 13767.729599237442 seconds ---
batch_number = 70, loss = 5.336581, acc = 0.766557
--- 13775.402215957642 seconds ---
batch_number = 80, loss = 5.277668, acc = 0.774582
--- 13783.86685538292 seconds ---
batch_number = 90, loss = 5.228207, acc = 0.779603
--- 13793.207378864288 seconds ---
batch_number = 100, loss = 5.338642, acc = 0.775080
--- 13800.692438602448 seconds ---
batch_number = 110, loss = 5.185631, acc = 0.782417
--- 13807.33318066597 seconds ---
batch_number = 120, loss = 5.042710, acc = 0.788014
--- 13815.836595058441 seconds ---
batch_number = 130, loss = 4.902824, acc = 0.796517
--- 13824.290712356567 seconds ---
batch_number = 140, loss = 4.792014, acc = 0.803120
--- 13834.003512859344 seconds ---
batch_number = 150, loss = 4.761406, acc = 0.805525
--- 13843.978932619095 seconds ---
batch_number = 160, loss = 4.666573, acc = 0.810167
[epoch 95]: train_loss = 0.580212, train_acc = 0.813559, validation_loss = 3.885740, validation_acc = 0.818143
--- 13862.628777980804 seconds ---
batch_number = 10, loss = 2.501899, acc = 0.896731
--- 13870.958034992218 seconds ---
batch_number = 20, loss = 2.422951, acc = 0.918856
--- 13880.66923236847 seconds ---
batch_number = 30, loss = 2.381393, acc = 0.925909
--- 13888.848734140396 seconds ---
batch_number = 40, loss = 2.289205, acc = 0.930510
--- 13896.712200641632 seconds ---
batch_number = 50, loss = 2.221853, acc = 0.934389
--- 13904.942448854446 seconds ---
batch_number = 60, loss = 2.183823, acc = 0.938493
--- 13912.86337351799 seconds ---
batch_number = 70, loss = 2.151572, acc = 0.941766
--- 13920.449844360352 seconds ---
batch_number = 80, loss = 2.127733, acc = 0.943938
--- 13928.926095724106 seconds ---
batch_number = 90, loss = 2.093164, acc = 0.945651
--- 13938.78918504715 seconds ---
batch_number = 100, loss = 2.047652, acc = 0.948185
--- 13947.395347595215 seconds ---
batch_number = 110, loss = 2.015651, acc = 0.949921
--- 13955.947581529617 seconds ---
batch_number = 120, loss = 1.986380, acc = 0.951474
--- 13965.4353556633 seconds ---
batch_number = 130, loss = 1.957127, acc = 0.953307
--- 13972.476323366165 seconds ---
batch_number = 140, loss = 1.948711, acc = 0.954484
--- 13980.649783372879 seconds ---
batch_number = 150, loss = 1.921974, acc = 0.955687
--- 13988.945539712906 seconds ---
batch_number = 160, loss = 1.907608, acc = 0.956161
[epoch 96]: train_loss = 0.241292, train_acc = 0.956351, validation_loss = 3.179150, validation_acc = 0.861798
--- 14005.516389846802 seconds ---
batch_number = 10, loss = 1.582754, acc = 0.964256
--- 14014.200223684311 seconds ---
batch_number = 20, loss = 1.559768, acc = 0.969200
--- 14023.072557926178 seconds ---
batch_number = 30, loss = 1.508253, acc = 0.970896
--- 14030.850786447525 seconds ---
batch_number = 40, loss = 1.526463, acc = 0.971340
--- 14038.617606401443 seconds ---
batch_number = 50, loss = 1.523280, acc = 0.972236
--- 14046.243801355362 seconds ---
batch_number = 60, loss = 1.529549, acc = 0.972749
--- 14055.259648561478 seconds ---
batch_number = 70, loss = 1.533908, acc = 0.973317
--- 14064.511109113693 seconds ---
batch_number = 80, loss = 1.511854, acc = 0.973928
--- 14073.973916053772 seconds ---
batch_number = 90, loss = 1.498580, acc = 0.974297
--- 14081.72726893425 seconds ---
batch_number = 100, loss = 1.491873, acc = 0.974592
--- 14090.319432973862 seconds ---
batch_number = 110, loss = 1.482575, acc = 0.974889
--- 14098.743085861206 seconds ---
batch_number = 120, loss = 1.473999, acc = 0.974966
--- 14106.596256017685 seconds ---
batch_number = 130, loss = 1.477260, acc = 0.975015
--- 14114.66821718216 seconds ---
batch_number = 140, loss = 1.472693, acc = 0.975166
--- 14124.251421928406 seconds ---
batch_number = 150, loss = 1.461167, acc = 0.975421
--- 14133.378487825394 seconds ---
batch_number = 160, loss = 1.450317, acc = 0.975660
[epoch 97]: train_loss = 0.183089, train_acc = 0.975706, validation_loss = 2.936937, validation_acc = 0.884117
--- 14151.025770902634 seconds ---
batch_number = 10, loss = 1.176785, acc = 0.981134
--- 14160.528376817703 seconds ---
batch_number = 20, loss = 1.217888, acc = 0.982301
--- 14169.506157636642 seconds ---
batch_number = 30, loss = 1.226600, acc = 0.982011
--- 14177.908483505249 seconds ---
batch_number = 40, loss = 1.260818, acc = 0.982165
--- 14185.8755235672 seconds ---
batch_number = 50, loss = 1.256795, acc = 0.981946
--- 14193.306438684464 seconds ---
batch_number = 60, loss = 1.285535, acc = 0.981054
--- 14201.694583177567 seconds ---
batch_number = 70, loss = 1.292748, acc = 0.980844
--- 14209.752313137054 seconds ---
batch_number = 80, loss = 1.303285, acc = 0.980585
--- 14218.690518379211 seconds ---
batch_number = 90, loss = 1.298016, acc = 0.980749
--- 14227.668636083603 seconds ---
batch_number = 100, loss = 1.291509, acc = 0.981054
--- 14237.177963018417 seconds ---
batch_number = 110, loss = 1.283221, acc = 0.981162
--- 14246.158865213394 seconds ---
batch_number = 120, loss = 1.273856, acc = 0.981193
--- 14254.849186182022 seconds ---
batch_number = 130, loss = 1.270910, acc = 0.981120
--- 14263.680944681168 seconds ---
batch_number = 140, loss = 1.271553, acc = 0.981172
--- 14272.042754411697 seconds ---
batch_number = 150, loss = 1.273156, acc = 0.981281
--- 14279.960901260376 seconds ---
batch_number = 160, loss = 1.272545, acc = 0.981211
[epoch 98]: train_loss = 0.161126, train_acc = 0.981144, validation_loss = 2.922221, validation_acc = 0.888233
--- 14296.046643733978 seconds ---
batch_number = 10, loss = 1.145871, acc = 0.982090
--- 14304.973440885544 seconds ---
batch_number = 20, loss = 1.173465, acc = 0.982889
--- 14312.84858250618 seconds ---
batch_number = 30, loss = 1.208329, acc = 0.982632
--- 14321.494816541672 seconds ---
batch_number = 40, loss = 1.187511, acc = 0.983029
--- 14330.994786024094 seconds ---
batch_number = 50, loss = 1.177766, acc = 0.982876
--- 14340.241087198257 seconds ---
batch_number = 60, loss = 1.180348, acc = 0.982955
--- 14349.30114364624 seconds ---
batch_number = 70, loss = 1.195318, acc = 0.982763
--- 14356.968666553497 seconds ---
batch_number = 80, loss = 1.202138, acc = 0.982793
--- 14365.222709655762 seconds ---
batch_number = 90, loss = 1.198380, acc = 0.982799
--- 14374.559263706207 seconds ---
batch_number = 100, loss = 1.199041, acc = 0.982634
--- 14382.23510813713 seconds ---
batch_number = 110, loss = 1.208941, acc = 0.982452
--- 14391.449095249176 seconds ---
batch_number = 120, loss = 1.219150, acc = 0.982430
--- 14401.424693584442 seconds ---
batch_number = 130, loss = 1.209687, acc = 0.982627
--- 14409.40831208229 seconds ---
batch_number = 140, loss = 1.204932, acc = 0.982620
--- 14417.781960964203 seconds ---
batch_number = 150, loss = 1.206893, acc = 0.982621
--- 14426.454041719437 seconds ---
batch_number = 160, loss = 1.208443, acc = 0.982592
[epoch 99]: train_loss = 0.152993, train_acc = 0.982554, validation_loss = 3.069427, validation_acc = 0.883254
--- 14443.314581871033 seconds ---
batch_number = 10, loss = 1.149734, acc = 0.979446
--- 14452.03832912445 seconds ---
batch_number = 20, loss = 1.149652, acc = 0.982067
--- 14461.542699575424 seconds ---
batch_number = 30, loss = 1.131900, acc = 0.982985
--- 14469.685198545456 seconds ---
batch_number = 40, loss = 1.130293, acc = 0.982713
--- 14478.200632810593 seconds ---
batch_number = 50, loss = 1.157579, acc = 0.981854
--- 14486.833724975586 seconds ---
batch_number = 60, loss = 1.206230, acc = 0.979842
--- 14496.009375572205 seconds ---
batch_number = 70, loss = 1.215126, acc = 0.979555
--- 14503.89630484581 seconds ---
batch_number = 80, loss = 1.223024, acc = 0.979464
--- 14512.221177101135 seconds ---
batch_number = 90, loss = 1.216994, acc = 0.979459
--- 14520.020849704742 seconds ---
batch_number = 100, loss = 1.219371, acc = 0.979593
--- 14531.532562494278 seconds ---
batch_number = 110, loss = 1.204666, acc = 0.980363
--- 14539.159014701843 seconds ---
batch_number = 120, loss = 1.206356, acc = 0.980392
--- 14548.82797050476 seconds ---
batch_number = 130, loss = 1.202803, acc = 0.980746
--- 14556.392680883408 seconds ---
batch_number = 140, loss = 1.200270, acc = 0.980992
--- 14564.185192584991 seconds ---
batch_number = 150, loss = 1.199832, acc = 0.981011
--- 14572.082048654556 seconds ---
batch_number = 160, loss = 1.190250, acc = 0.981155
[epoch 100]: train_loss = 0.150393, train_acc = 0.981201, validation_loss = 3.113591, validation_acc = 0.880622
cuda
BaselineLinear
Finish Load the Training data and labels!!!
Traceback (most recent call last):
  File "main.py", line 207, in <module>
    train()
  File "main.py", line 77, in train
    model.load_state_dict(torch.load(model_folder + "/epoch-%d.model" % start_epoch))
  File "/home/toshal/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py", line 769, in load_state_dict
    self.__class__.__name__, "\n\t".join(error_msgs)))
RuntimeError: Error(s) in loading state_dict for BaselineLinear:
	Missing key(s) in state_dict: "fc1.weight", "fc1.bias", "fc2.weight", "fc2.bias", "fc3.weight", "fc3.bias", "fc4.weight", "fc4.bias". 
	Unexpected key(s) in state_dict: "stage1.conv_in.weight", "stage1.conv_in.bias", "stage1.network.0.conv_in.weight", "stage1.network.0.conv_in.bias", "stage1.network.0.conv_out.weight", "stage1.network.0.conv_out.bias", "stage1.network.1.conv_in.weight", "stage1.network.1.conv_in.bias", "stage1.network.1.conv_out.weight", "stage1.network.1.conv_out.bias", "stage1.network.2.conv_in.weight", "stage1.network.2.conv_in.bias", "stage1.network.2.conv_out.weight", "stage1.network.2.conv_out.bias", "stage1.network.3.conv_in.weight", "stage1.network.3.conv_in.bias", "stage1.network.3.conv_out.weight", "stage1.network.3.conv_out.bias", "stage1.network.4.conv_in.weight", "stage1.network.4.conv_in.bias", "stage1.network.4.conv_out.weight", "stage1.network.4.conv_out.bias", "stage1.network.5.conv_in.weight", "stage1.network.5.conv_in.bias", "stage1.network.5.conv_out.weight", "stage1.network.5.conv_out.bias", "stage1.network.6.conv_in.weight", "stage1.network.6.conv_in.bias", "stage1.network.6.conv_out.weight", "stage1.network.6.conv_out.bias", "stage1.network.7.conv_in.weight", "stage1.network.7.conv_in.bias", "stage1.network.7.conv_out.weight", "stage1.network.7.conv_out.bias", "stage1.network.8.conv_in.weight", "stage1.network.8.conv_in.bias", "stage1.network.8.conv_out.weight", "stage1.network.8.conv_out.bias", "stage1.network.9.conv_in.weight", "stage1.network.9.conv_in.bias", "stage1.network.9.conv_out.weight", "stage1.network.9.conv_out.bias", "stage1.network.10.conv_in.weight", "stage1.network.10.conv_in.bias", "stage1.network.10.conv_out.weight", "stage1.network.10.conv_out.bias", "stage1.network.11.conv_in.weight", "stage1.network.11.conv_in.bias", "stage1.network.11.conv_out.weight", "stage1.network.11.conv_out.bias", "stage1.conv_out.weight", "stage1.conv_out.bias", "stages.0.conv_in.weight", "stages.0.conv_in.bias", "stages.0.network.0.conv_in.weight", "stages.0.network.0.conv_in.bias", "stages.0.network.0.conv_out.weight", "stages.0.network.0.conv_out.bias", "stages.0.network.1.conv_in.weight", "stages.0.network.1.conv_in.bias", "stages.0.network.1.conv_out.weight", "stages.0.network.1.conv_out.bias", "stages.0.network.2.conv_in.weight", "stages.0.network.2.conv_in.bias", "stages.0.network.2.conv_out.weight", "stages.0.network.2.conv_out.bias", "stages.0.network.3.conv_in.weight", "stages.0.network.3.conv_in.bias", "stages.0.network.3.conv_out.weight", "stages.0.network.3.conv_out.bias", "stages.0.network.4.conv_in.weight", "stages.0.network.4.conv_in.bias", "stages.0.network.4.conv_out.weight", "stages.0.network.4.conv_out.bias", "stages.0.network.5.conv_in.weight", "stages.0.network.5.conv_in.bias", "stages.0.network.5.conv_out.weight", "stages.0.network.5.conv_out.bias", "stages.0.network.6.conv_in.weight", "stages.0.network.6.conv_in.bias", "stages.0.network.6.conv_out.weight", "stages.0.network.6.conv_out.bias", "stages.0.network.7.conv_in.weight", "stages.0.network.7.conv_in.bias", "stages.0.network.7.conv_out.weight", "stages.0.network.7.conv_out.bias", "stages.0.network.8.conv_in.weight", "stages.0.network.8.conv_in.bias", "stages.0.network.8.conv_out.weight", "stages.0.network.8.conv_out.bias", "stages.0.network.9.conv_in.weight", "stages.0.network.9.conv_in.bias", "stages.0.network.9.conv_out.weight", "stages.0.network.9.conv_out.bias", "stages.0.network.10.conv_in.weight", "stages.0.network.10.conv_in.bias", "stages.0.network.10.conv_out.weight", "stages.0.network.10.conv_out.bias", "stages.0.network.11.conv_in.weight", "stages.0.network.11.conv_in.bias", "stages.0.network.11.conv_out.weight", "stages.0.network.11.conv_out.bias", "stages.0.conv_out.weight", "stages.0.conv_out.bias", "stages.1.conv_in.weight", "stages.1.conv_in.bias", "stages.1.network.0.conv_in.weight", "stages.1.network.0.conv_in.bias", "stages.1.network.0.conv_out.weight", "stages.1.network.0.conv_out.bias", "stages.1.network.1.conv_in.weight", "stages.1.network.1.conv_in.bias", "stages.1.network.1.conv_out.weight", "stages.1.network.1.conv_out.bias", "stages.1.network.2.conv_in.weight", "stages.1.network.2.conv_in.bias", "stages.1.network.2.conv_out.weight", "stages.1.network.2.conv_out.bias", "stages.1.network.3.conv_in.weight", "stages.1.network.3.conv_in.bias", "stages.1.network.3.conv_out.weight", "stages.1.network.3.conv_out.bias", "stages.1.network.4.conv_in.weight", "stages.1.network.4.conv_in.bias", "stages.1.network.4.conv_out.weight", "stages.1.network.4.conv_out.bias", "stages.1.network.5.conv_in.weight", "stages.1.network.5.conv_in.bias", "stages.1.network.5.conv_out.weight", "stages.1.network.5.conv_out.bias", "stages.1.network.6.conv_in.weight", "stages.1.network.6.conv_in.bias", "stages.1.network.6.conv_out.weight", "stages.1.network.6.conv_out.bias", "stages.1.network.7.conv_in.weight", "stages.1.network.7.conv_in.bias", "stages.1.network.7.conv_out.weight", "stages.1.network.7.conv_out.bias", "stages.1.network.8.conv_in.weight", "stages.1.network.8.conv_in.bias", "stages.1.network.8.conv_out.weight", "stages.1.network.8.conv_out.bias", "stages.1.network.9.conv_in.weight", "stages.1.network.9.conv_in.bias", "stages.1.network.9.conv_out.weight", "stages.1.network.9.conv_out.bias", "stages.1.network.10.conv_in.weight", "stages.1.network.10.conv_in.bias", "stages.1.network.10.conv_out.weight", "stages.1.network.10.conv_out.bias", "stages.1.network.11.conv_in.weight", "stages.1.network.11.conv_in.bias", "stages.1.network.11.conv_out.weight", "stages.1.network.11.conv_out.bias", "stages.1.conv_out.weight", "stages.1.conv_out.bias", "stages.2.conv_in.weight", "stages.2.conv_in.bias", "stages.2.network.0.conv_in.weight", "stages.2.network.0.conv_in.bias", "stages.2.network.0.conv_out.weight", "stages.2.network.0.conv_out.bias", "stages.2.network.1.conv_in.weight", "stages.2.network.1.conv_in.bias", "stages.2.network.1.conv_out.weight", "stages.2.network.1.conv_out.bias", "stages.2.network.2.conv_in.weight", "stages.2.network.2.conv_in.bias", "stages.2.network.2.conv_out.weight", "stages.2.network.2.conv_out.bias", "stages.2.network.3.conv_in.weight", "stages.2.network.3.conv_in.bias", "stages.2.network.3.conv_out.weight", "stages.2.network.3.conv_out.bias", "stages.2.network.4.conv_in.weight", "stages.2.network.4.conv_in.bias", "stages.2.network.4.conv_out.weight", "stages.2.network.4.conv_out.bias", "stages.2.network.5.conv_in.weight", "stages.2.network.5.conv_in.bias", "stages.2.network.5.conv_out.weight", "stages.2.network.5.conv_out.bias", "stages.2.network.6.conv_in.weight", "stages.2.network.6.conv_in.bias", "stages.2.network.6.conv_out.weight", "stages.2.network.6.conv_out.bias", "stages.2.network.7.conv_in.weight", "stages.2.network.7.conv_in.bias", "stages.2.network.7.conv_out.weight", "stages.2.network.7.conv_out.bias", "stages.2.network.8.conv_in.weight", "stages.2.network.8.conv_in.bias", "stages.2.network.8.conv_out.weight", "stages.2.network.8.conv_out.bias", "stages.2.network.9.conv_in.weight", "stages.2.network.9.conv_in.bias", "stages.2.network.9.conv_out.weight", "stages.2.network.9.conv_out.bias", "stages.2.network.10.conv_in.weight", "stages.2.network.10.conv_in.bias", "stages.2.network.10.conv_out.weight", "stages.2.network.10.conv_out.bias", "stages.2.network.11.conv_in.weight", "stages.2.network.11.conv_in.bias", "stages.2.network.11.conv_out.weight", "stages.2.network.11.conv_out.bias", "stages.2.conv_out.weight", "stages.2.conv_out.bias", "stages.3.conv_in.weight", "stages.3.conv_in.bias", "stages.3.network.0.conv_in.weight", "stages.3.network.0.conv_in.bias", "stages.3.network.0.conv_out.weight", "stages.3.network.0.conv_out.bias", "stages.3.network.1.conv_in.weight", "stages.3.network.1.conv_in.bias", "stages.3.network.1.conv_out.weight", "stages.3.network.1.conv_out.bias", "stages.3.network.2.conv_in.weight", "stages.3.network.2.conv_in.bias", "stages.3.network.2.conv_out.weight", "stages.3.network.2.conv_out.bias", "stages.3.network.3.conv_in.weight", "stages.3.network.3.conv_in.bias", "stages.3.network.3.conv_out.weight", "stages.3.network.3.conv_out.bias", "stages.3.network.4.conv_in.weight", "stages.3.network.4.conv_in.bias", "stages.3.network.4.conv_out.weight", "stages.3.network.4.conv_out.bias", "stages.3.network.5.conv_in.weight", "stages.3.network.5.conv_in.bias", "stages.3.network.5.conv_out.weight", "stages.3.network.5.conv_out.bias", "stages.3.network.6.conv_in.weight", "stages.3.network.6.conv_in.bias", "stages.3.network.6.conv_out.weight", "stages.3.network.6.conv_out.bias", "stages.3.network.7.conv_in.weight", "stages.3.network.7.conv_in.bias", "stages.3.network.7.conv_out.weight", "stages.3.network.7.conv_out.bias", "stages.3.network.8.conv_in.weight", "stages.3.network.8.conv_in.bias", "stages.3.network.8.conv_out.weight", "stages.3.network.8.conv_out.bias", "stages.3.network.9.conv_in.weight", "stages.3.network.9.conv_in.bias", "stages.3.network.9.conv_out.weight", "stages.3.network.9.conv_out.bias", "stages.3.network.10.conv_in.weight", "stages.3.network.10.conv_in.bias", "stages.3.network.10.conv_out.weight", "stages.3.network.10.conv_out.bias", "stages.3.network.11.conv_in.weight", "stages.3.network.11.conv_in.bias", "stages.3.network.11.conv_out.weight", "stages.3.network.11.conv_out.bias", "stages.3.conv_out.weight", "stages.3.conv_out.bias". 
cuda
MultiStageTCN
Finish Load the Training data and labels!!!
--- 8.521442413330078 seconds ---
batch_number = 10, loss = 1.119826, acc = 0.982682
--- 16.174577236175537 seconds ---
batch_number = 20, loss = 1.199530, acc = 0.983925
--- 23.667493104934692 seconds ---
batch_number = 30, loss = 1.193010, acc = 0.983531
--- 33.12473440170288 seconds ---
batch_number = 40, loss = 1.168242, acc = 0.984132
--- 42.763837575912476 seconds ---
batch_number = 50, loss = 1.145904, acc = 0.984073
--- 51.016488790512085 seconds ---
batch_number = 60, loss = 1.156463, acc = 0.983821
--- 59.57960319519043 seconds ---
batch_number = 70, loss = 1.141900, acc = 0.983793
--- 67.59487843513489 seconds ---
batch_number = 80, loss = 1.146622, acc = 0.983602
--- 76.6225426197052 seconds ---
batch_number = 90, loss = 1.145660, acc = 0.983458
--- 85.418940782547 seconds ---
batch_number = 100, loss = 1.155419, acc = 0.983437
--- 93.89293003082275 seconds ---
batch_number = 110, loss = 1.151947, acc = 0.983400
--- 101.50922012329102 seconds ---
batch_number = 120, loss = 1.151339, acc = 0.983311
--- 110.66948652267456 seconds ---
batch_number = 130, loss = 1.142461, acc = 0.983424
--- 119.66094183921814 seconds ---
batch_number = 140, loss = 1.139069, acc = 0.983388
--- 128.3587987422943 seconds ---
batch_number = 150, loss = 1.136691, acc = 0.983377
--- 136.74533891677856 seconds ---
batch_number = 160, loss = 1.137102, acc = 0.983428
[epoch 101]: train_loss = 0.143842, train_acc = 0.983520, validation_loss = 3.185225, validation_acc = 0.876712
--- 153.38466477394104 seconds ---
batch_number = 10, loss = 0.983393, acc = 0.983703
--- 161.46864938735962 seconds ---
batch_number = 20, loss = 1.071012, acc = 0.984977
--- 171.13509702682495 seconds ---
batch_number = 30, loss = 1.063846, acc = 0.985496
--- 179.13791823387146 seconds ---
batch_number = 40, loss = 1.070829, acc = 0.985533
--- 187.11333560943604 seconds ---
batch_number = 50, loss = 1.092734, acc = 0.985464
--- 196.43657064437866 seconds ---
batch_number = 60, loss = 1.089233, acc = 0.985228
--- 206.99204540252686 seconds ---
batch_number = 70, loss = 1.084380, acc = 0.985378
--- 215.53520464897156 seconds ---
batch_number = 80, loss = 1.085287, acc = 0.985115
--- 223.4062900543213 seconds ---
batch_number = 90, loss = 1.091553, acc = 0.984782
--- 233.1332790851593 seconds ---
batch_number = 100, loss = 1.086531, acc = 0.984655
--- 240.92454552650452 seconds ---
batch_number = 110, loss = 1.084579, acc = 0.984304
--- 249.17692708969116 seconds ---
batch_number = 120, loss = 1.086099, acc = 0.984163
--- 257.85072803497314 seconds ---
batch_number = 130, loss = 1.086236, acc = 0.984196
--- 266.7304172515869 seconds ---
batch_number = 140, loss = 1.082342, acc = 0.984228
--- 275.72701144218445 seconds ---
batch_number = 150, loss = 1.078860, acc = 0.984245
--- 284.1904740333557 seconds ---
batch_number = 160, loss = 1.079543, acc = 0.984317
[epoch 102]: train_loss = 0.136528, train_acc = 0.984389, validation_loss = 3.165714, validation_acc = 0.878112
--- 301.4419734477997 seconds ---
batch_number = 10, loss = 0.978879, acc = 0.983705
--- 310.1871449947357 seconds ---
batch_number = 20, loss = 1.059898, acc = 0.984700
--- 319.2597668170929 seconds ---
batch_number = 30, loss = 1.068489, acc = 0.984582
--- 329.401664018631 seconds ---
batch_number = 40, loss = 1.055430, acc = 0.984923
--- 336.55288672447205 seconds ---
batch_number = 50, loss = 1.067292, acc = 0.984428
--- 347.0003960132599 seconds ---
batch_number = 60, loss = 1.049790, acc = 0.984559
--- 354.33053755760193 seconds ---
batch_number = 70, loss = 1.059948, acc = 0.984468
--- 362.5802216529846 seconds ---
batch_number = 80, loss = 1.051028, acc = 0.984465
--- 369.75157928466797 seconds ---
batch_number = 90, loss = 1.057456, acc = 0.984396
--- 378.76259684562683 seconds ---
batch_number = 100, loss = 1.054488, acc = 0.984486
--- 387.0723168849945 seconds ---
batch_number = 110, loss = 1.048600, acc = 0.984496
--- 395.5653886795044 seconds ---
batch_number = 120, loss = 1.054186, acc = 0.984618
--- 403.49612951278687 seconds ---
batch_number = 130, loss = 1.056538, acc = 0.984592
--- 413.0035161972046 seconds ---
batch_number = 140, loss = 1.058637, acc = 0.984664
--- 422.06669545173645 seconds ---
batch_number = 150, loss = 1.059210, acc = 0.984816
--- 431.15248441696167 seconds ---
batch_number = 160, loss = 1.052653, acc = 0.984672
[epoch 103]: train_loss = 0.133238, train_acc = 0.984699, validation_loss = 3.272891, validation_acc = 0.874582
--- 450.22272062301636 seconds ---
batch_number = 10, loss = 0.921230, acc = 0.984425
--- 459.019668340683 seconds ---
batch_number = 20, loss = 0.997951, acc = 0.984396
--- 467.7630989551544 seconds ---
batch_number = 30, loss = 1.037341, acc = 0.983697
--- 476.87755608558655 seconds ---
batch_number = 40, loss = 1.031514, acc = 0.984235
--- 485.69216752052307 seconds ---
batch_number = 50, loss = 1.028619, acc = 0.984312
--- 494.65176820755005 seconds ---
batch_number = 60, loss = 1.031212, acc = 0.984648
--- 502.9534296989441 seconds ---
batch_number = 70, loss = 1.023124, acc = 0.984909
--- 510.85457396507263 seconds ---
batch_number = 80, loss = 1.026670, acc = 0.985093
--- 519.6650199890137 seconds ---
batch_number = 90, loss = 1.024168, acc = 0.985278
--- 528.1425664424896 seconds ---
batch_number = 100, loss = 1.032969, acc = 0.985031
--- 536.9751393795013 seconds ---
batch_number = 110, loss = 1.036117, acc = 0.984962
--- 545.0532252788544 seconds ---
batch_number = 120, loss = 1.036561, acc = 0.984936
--- 553.828070640564 seconds ---
batch_number = 130, loss = 1.033750, acc = 0.984923
--- 562.618536233902 seconds ---
batch_number = 140, loss = 1.033750, acc = 0.984770
--- 570.890367269516 seconds ---
batch_number = 150, loss = 1.034550, acc = 0.984788
--- 578.5563955307007 seconds ---
batch_number = 160, loss = 1.036443, acc = 0.984763
[epoch 104]: train_loss = 0.131626, train_acc = 0.984718, validation_loss = 3.142947, validation_acc = 0.877308
--- 595.0942533016205 seconds ---
batch_number = 10, loss = 0.892916, acc = 0.986579
--- 603.3740170001984 seconds ---
batch_number = 20, loss = 0.998013, acc = 0.985680
--- 612.0607886314392 seconds ---
batch_number = 30, loss = 0.986354, acc = 0.985752
--- 621.915682554245 seconds ---
batch_number = 40, loss = 0.978123, acc = 0.985541
--- 631.3348603248596 seconds ---
batch_number = 50, loss = 1.010194, acc = 0.983780
--- 639.9827063083649 seconds ---
batch_number = 60, loss = 1.038821, acc = 0.982697
--- 649.6778938770294 seconds ---
batch_number = 70, loss = 1.104993, acc = 0.979797
--- 658.1887373924255 seconds ---
batch_number = 80, loss = 1.122514, acc = 0.978613
--- 665.7613658905029 seconds ---
batch_number = 90, loss = 1.131761, acc = 0.978422
--- 674.208438873291 seconds ---
batch_number = 100, loss = 1.144563, acc = 0.977620
--- 683.8734774589539 seconds ---
batch_number = 110, loss = 1.143604, acc = 0.977640
--- 692.4961149692535 seconds ---
batch_number = 120, loss = 1.150169, acc = 0.977383
--- 700.1988537311554 seconds ---
batch_number = 130, loss = 1.165074, acc = 0.977244
--- 707.7844927310944 seconds ---
batch_number = 140, loss = 1.176054, acc = 0.976690
--- 717.1416664123535 seconds ---
batch_number = 150, loss = 1.183170, acc = 0.976192
--- 725.2936680316925 seconds ---
batch_number = 160, loss = 1.196233, acc = 0.975682
[epoch 105]: train_loss = 0.152316, train_acc = 0.975326, validation_loss = 3.738894, validation_acc = 0.846519
--- 742.3767907619476 seconds ---
batch_number = 10, loss = 1.314466, acc = 0.959689
--- 751.2806241512299 seconds ---
batch_number = 20, loss = 1.437164, acc = 0.956330
--- 760.4915976524353 seconds ---
batch_number = 30, loss = 1.405461, acc = 0.961067
--- 769.6709187030792 seconds ---
batch_number = 40, loss = 1.370581, acc = 0.963093
--- 776.2917332649231 seconds ---
batch_number = 50, loss = 1.402157, acc = 0.962962
--- 787.1883170604706 seconds ---
batch_number = 60, loss = 1.385301, acc = 0.963187
--- 795.025390625 seconds ---
batch_number = 70, loss = 1.416994, acc = 0.962631
--- 804.3812963962555 seconds ---
batch_number = 80, loss = 1.400409, acc = 0.962893
--- 811.9318692684174 seconds ---
batch_number = 90, loss = 1.435775, acc = 0.960782
--- 819.45720911026 seconds ---
batch_number = 100, loss = 1.460481, acc = 0.959814
--- 828.7169864177704 seconds ---
batch_number = 110, loss = 1.464661, acc = 0.959772
--- 837.362176656723 seconds ---
batch_number = 120, loss = 1.472211, acc = 0.959845
--- 846.2107427120209 seconds ---
batch_number = 130, loss = 1.464865, acc = 0.960558
--- 854.7598886489868 seconds ---
batch_number = 140, loss = 1.464461, acc = 0.960994
--- 862.0561099052429 seconds ---
batch_number = 150, loss = 1.470725, acc = 0.960665
--- 871.0601360797882 seconds ---
batch_number = 160, loss = 1.461042, acc = 0.961320
[epoch 106]: train_loss = 0.184519, train_acc = 0.961782, validation_loss = 3.256590, validation_acc = 0.867307
--- 889.7662289142609 seconds ---
batch_number = 10, loss = 1.132052, acc = 0.970780
--- 897.6101930141449 seconds ---
batch_number = 20, loss = 1.205886, acc = 0.971801
--- 905.2827231884003 seconds ---
batch_number = 30, loss = 1.245976, acc = 0.972919
--- 913.5031566619873 seconds ---
batch_number = 40, loss = 1.245777, acc = 0.974345
--- 922.2751932144165 seconds ---
batch_number = 50, loss = 1.221926, acc = 0.975004
--- 932.189450263977 seconds ---
batch_number = 60, loss = 1.191038, acc = 0.976130
--- 942.4927294254303 seconds ---
batch_number = 70, loss = 1.210197, acc = 0.975701
--- 950.4633057117462 seconds ---
batch_number = 80, loss = 1.257702, acc = 0.973388
--- 957.5119860172272 seconds ---
batch_number = 90, loss = 1.301216, acc = 0.972063
--- 966.5606646537781 seconds ---
batch_number = 100, loss = 1.329284, acc = 0.970418
--- 975.618171453476 seconds ---
batch_number = 110, loss = 1.342830, acc = 0.969919
--- 984.9746990203857 seconds ---
batch_number = 120, loss = 1.340041, acc = 0.970032
--- 993.3523049354553 seconds ---
batch_number = 130, loss = 1.338428, acc = 0.970141
--- 1001.250039100647 seconds ---
batch_number = 140, loss = 1.342155, acc = 0.969958
--- 1010.6825971603394 seconds ---
batch_number = 150, loss = 1.334174, acc = 0.970218
--- 1019.3038392066956 seconds ---
batch_number = 160, loss = 1.326016, acc = 0.970828
[epoch 107]: train_loss = 0.167566, train_acc = 0.970911, validation_loss = 3.201297, validation_acc = 0.871931
--- 1036.3430695533752 seconds ---
batch_number = 10, loss = 1.039582, acc = 0.980591
--- 1044.5519576072693 seconds ---
batch_number = 20, loss = 1.096135, acc = 0.979336
--- 1054.4566860198975 seconds ---
batch_number = 30, loss = 1.102336, acc = 0.977664
--- 1063.3849272727966 seconds ---
batch_number = 40, loss = 1.155714, acc = 0.977024
--- 1072.9840908050537 seconds ---
batch_number = 50, loss = 1.151905, acc = 0.977121
--- 1082.6342413425446 seconds ---
batch_number = 60, loss = 1.143412, acc = 0.977268
--- 1091.5143992900848 seconds ---
batch_number = 70, loss = 1.155481, acc = 0.977572
--- 1098.9870991706848 seconds ---
batch_number = 80, loss = 1.164282, acc = 0.977676
--- 1107.1906416416168 seconds ---
batch_number = 90, loss = 1.163790, acc = 0.977668
--- 1115.9624872207642 seconds ---
batch_number = 100, loss = 1.157273, acc = 0.977757
--- 1124.001240491867 seconds ---
batch_number = 110, loss = 1.155616, acc = 0.977791
--- 1133.5696527957916 seconds ---
batch_number = 120, loss = 1.149896, acc = 0.978046
--- 1141.532508134842 seconds ---
batch_number = 130, loss = 1.147478, acc = 0.978153
--- 1149.9338879585266 seconds ---
batch_number = 140, loss = 1.149799, acc = 0.978079
--- 1158.302001953125 seconds ---
batch_number = 150, loss = 1.166305, acc = 0.977276
--- 1167.2410154342651 seconds ---
batch_number = 160, loss = 1.201697, acc = 0.975428
[epoch 108]: train_loss = 0.158984, train_acc = 0.973490, validation_loss = 5.696970, validation_acc = 0.749421
--- 1184.759155511856 seconds ---
batch_number = 10, loss = 3.883043, acc = 0.843144
--- 1193.3378047943115 seconds ---
batch_number = 20, loss = 4.221071, acc = 0.835543
--- 1201.8902702331543 seconds ---
batch_number = 30, loss = 4.415678, acc = 0.820789
--- 1211.7325339317322 seconds ---
batch_number = 40, loss = 4.457624, acc = 0.811577
--- 1220.320105791092 seconds ---
batch_number = 50, loss = 4.484667, acc = 0.812146
--- 1228.8032977581024 seconds ---
batch_number = 60, loss = 4.863022, acc = 0.791067
--- 1237.2267291545868 seconds ---
batch_number = 70, loss = 4.918517, acc = 0.792891
--- 1245.3265323638916 seconds ---
batch_number = 80, loss = 4.854706, acc = 0.796264
--- 1255.072288274765 seconds ---
batch_number = 90, loss = 4.813131, acc = 0.797585
--- 1263.570030450821 seconds ---
batch_number = 100, loss = 4.744485, acc = 0.799896
--- 1274.0079972743988 seconds ---
batch_number = 110, loss = 4.996197, acc = 0.786976
--- 1282.5494449138641 seconds ---
batch_number = 120, loss = 5.312593, acc = 0.780691
--- 1290.3260667324066 seconds ---
batch_number = 130, loss = 5.508134, acc = 0.773890
--- 1298.0063169002533 seconds ---
batch_number = 140, loss = 5.596148, acc = 0.770696
--- 1306.3972318172455 seconds ---
batch_number = 150, loss = 5.570461, acc = 0.771836
--- 1313.754296541214 seconds ---
batch_number = 160, loss = 5.485724, acc = 0.773237
[epoch 109]: train_loss = 0.684874, train_acc = 0.776908, validation_loss = 4.660509, validation_acc = 0.784840
--- 1331.5758068561554 seconds ---
batch_number = 10, loss = 3.445540, acc = 0.833402
--- 1340.0184421539307 seconds ---
batch_number = 20, loss = 3.548685, acc = 0.848372
--- 1349.3808100223541 seconds ---
batch_number = 30, loss = 3.621652, acc = 0.848832
--- 1356.8152956962585 seconds ---
batch_number = 40, loss = 3.600141, acc = 0.854517
--- 1364.972295999527 seconds ---
batch_number = 50, loss = 3.382705, acc = 0.870513
--- 1373.3653755187988 seconds ---
batch_number = 60, loss = 3.215714, acc = 0.880845
--- 1382.0454638004303 seconds ---
batch_number = 70, loss = 3.089737, acc = 0.891854
--- 1389.641924381256 seconds ---
batch_number = 80, loss = 2.982003, acc = 0.898482
--- 1397.7007677555084 seconds ---
batch_number = 90, loss = 2.871838, acc = 0.904744
--- 1407.0400185585022 seconds ---
batch_number = 100, loss = 2.767638, acc = 0.910962
--- 1416.4381816387177 seconds ---
batch_number = 110, loss = 2.685677, acc = 0.916353
--- 1423.5185704231262 seconds ---
batch_number = 120, loss = 2.688970, acc = 0.917875
--- 1434.7282485961914 seconds ---
batch_number = 130, loss = 2.616126, acc = 0.921435
--- 1444.124636888504 seconds ---
batch_number = 140, loss = 2.559176, acc = 0.924589
--- 1451.2008876800537 seconds ---
batch_number = 150, loss = 2.513256, acc = 0.927037
--- 1461.2716686725616 seconds ---
batch_number = 160, loss = 2.460154, acc = 0.929887
[epoch 110]: train_loss = 0.307925, train_acc = 0.931091, validation_loss = 2.892260, validation_acc = 0.885106
--- 1479.0107531547546 seconds ---
batch_number = 10, loss = 1.386672, acc = 0.974889
--- 1487.0058424472809 seconds ---
batch_number = 20, loss = 1.502656, acc = 0.974079
--- 1495.904326915741 seconds ---
batch_number = 30, loss = 1.504298, acc = 0.974823
--- 1505.0907831192017 seconds ---
batch_number = 40, loss = 1.492749, acc = 0.974792
--- 1515.463487148285 seconds ---
batch_number = 50, loss = 1.475515, acc = 0.975838
--- 1523.7288494110107 seconds ---
batch_number = 60, loss = 1.484728, acc = 0.975718
--- 1533.7760105133057 seconds ---
batch_number = 70, loss = 1.477813, acc = 0.976389
--- 1540.4754943847656 seconds ---
batch_number = 80, loss = 1.493706, acc = 0.975970
--- 1549.60564827919 seconds ---
batch_number = 90, loss = 1.478064, acc = 0.976174
--- 1559.7457597255707 seconds ---
batch_number = 100, loss = 1.454156, acc = 0.976817
--- 1568.3970410823822 seconds ---
batch_number = 110, loss = 1.447900, acc = 0.977013
--- 1576.56694149971 seconds ---
batch_number = 120, loss = 1.447183, acc = 0.976785
--- 1583.8223016262054 seconds ---
batch_number = 130, loss = 1.440950, acc = 0.976737
--- 1592.6836400032043 seconds ---
batch_number = 140, loss = 1.440229, acc = 0.976864
--- 1602.8938426971436 seconds ---
batch_number = 150, loss = 1.431030, acc = 0.977017
--- 1610.2343037128448 seconds ---
batch_number = 160, loss = 1.437994, acc = 0.976830
[epoch 111]: train_loss = 0.181712, train_acc = 0.977102, validation_loss = 2.820255, validation_acc = 0.887047
--- 1627.514093875885 seconds ---
batch_number = 10, loss = 1.141196, acc = 0.981620
--- 1635.716195821762 seconds ---
batch_number = 20, loss = 1.232235, acc = 0.980467
--- 1646.1236867904663 seconds ---
batch_number = 30, loss = 1.197792, acc = 0.982346
--- 1654.0782299041748 seconds ---
batch_number = 40, loss = 1.246611, acc = 0.981492
--- 1661.0984706878662 seconds ---
batch_number = 50, loss = 1.269085, acc = 0.981395
--- 1669.6802022457123 seconds ---
batch_number = 60, loss = 1.276192, acc = 0.981570
--- 1677.607978105545 seconds ---
batch_number = 70, loss = 1.290352, acc = 0.981722
--- 1687.0882115364075 seconds ---
batch_number = 80, loss = 1.280838, acc = 0.981659
--- 1696.4939742088318 seconds ---
batch_number = 90, loss = 1.269244, acc = 0.981782
--- 1706.1864824295044 seconds ---
batch_number = 100, loss = 1.265712, acc = 0.981953
--- 1715.0066139698029 seconds ---
batch_number = 110, loss = 1.266849, acc = 0.982017
--- 1722.0738265514374 seconds ---
batch_number = 120, loss = 1.271749, acc = 0.982059
--- 1730.5624079704285 seconds ---
batch_number = 130, loss = 1.266339, acc = 0.982236
--- 1739.7384116649628 seconds ---
batch_number = 140, loss = 1.263313, acc = 0.982201
--- 1749.3973896503448 seconds ---
batch_number = 150, loss = 1.259245, acc = 0.982239
--- 1756.2438378334045 seconds ---
batch_number = 160, loss = 1.268460, acc = 0.982118
[epoch 112]: train_loss = 0.160995, train_acc = 0.982208, validation_loss = 2.848521, validation_acc = 0.889704
--- 1772.0300867557526 seconds ---
batch_number = 10, loss = 1.375357, acc = 0.971824
--- 1781.2306425571442 seconds ---
batch_number = 20, loss = 1.347481, acc = 0.974249
--- 1789.3299112319946 seconds ---
batch_number = 30, loss = 1.362331, acc = 0.972159
--- 1798.3718993663788 seconds ---
batch_number = 40, loss = 1.354165, acc = 0.973329
--- 1809.8755838871002 seconds ---
batch_number = 50, loss = 1.309823, acc = 0.976008
--- 1817.354751110077 seconds ---
batch_number = 60, loss = 1.315203, acc = 0.976425
--- 1825.6014051437378 seconds ---
batch_number = 70, loss = 1.299548, acc = 0.977291
--- 1834.5509941577911 seconds ---
batch_number = 80, loss = 1.281013, acc = 0.977961
--- 1843.1599202156067 seconds ---
batch_number = 90, loss = 1.273677, acc = 0.978541
--- 1852.2132306098938 seconds ---
batch_number = 100, loss = 1.269349, acc = 0.978964
--- 1861.3393743038177 seconds ---
batch_number = 110, loss = 1.259594, acc = 0.979483
--- 1871.0879380702972 seconds ---
batch_number = 120, loss = 1.249300, acc = 0.979840
--- 1879.8491034507751 seconds ---
batch_number = 130, loss = 1.237405, acc = 0.980143
--- 1887.4009532928467 seconds ---
batch_number = 140, loss = 1.238015, acc = 0.980194
--- 1895.5756647586823 seconds ---
batch_number = 150, loss = 1.231013, acc = 0.980444
--- 1905.0775246620178 seconds ---
batch_number = 160, loss = 1.222040, acc = 0.980689
[epoch 113]: train_loss = 0.154924, train_acc = 0.980785, validation_loss = 2.875937, validation_acc = 0.889034
--- 1921.8862895965576 seconds ---
batch_number = 10, loss = 1.004721, acc = 0.984104
--- 1929.6997685432434 seconds ---
batch_number = 20, loss = 1.082855, acc = 0.984060
--- 1938.8893404006958 seconds ---
batch_number = 30, loss = 1.081956, acc = 0.985034
--- 1947.9138023853302 seconds ---
batch_number = 40, loss = 1.097676, acc = 0.984962
--- 1955.8935260772705 seconds ---
batch_number = 50, loss = 1.131640, acc = 0.984872
--- 1964.6949214935303 seconds ---
batch_number = 60, loss = 1.132830, acc = 0.984859
--- 1971.6742992401123 seconds ---
batch_number = 70, loss = 1.148865, acc = 0.984747
--- 1980.8249475955963 seconds ---
batch_number = 80, loss = 1.141034, acc = 0.984625
--- 1989.2409036159515 seconds ---
batch_number = 90, loss = 1.146515, acc = 0.984724
--- 1997.3403782844543 seconds ---
batch_number = 100, loss = 1.141898, acc = 0.984675
--- 2006.0811717510223 seconds ---
batch_number = 110, loss = 1.136765, acc = 0.984680
--- 2015.0977563858032 seconds ---
batch_number = 120, loss = 1.135385, acc = 0.984614
--- 2024.8167188167572 seconds ---
batch_number = 130, loss = 1.130379, acc = 0.984619
--- 2032.9178426265717 seconds ---
batch_number = 140, loss = 1.131450, acc = 0.984635
--- 2041.9564361572266 seconds ---
batch_number = 150, loss = 1.132121, acc = 0.984452
--- 2050.9144723415375 seconds ---
batch_number = 160, loss = 1.130133, acc = 0.984431
[epoch 114]: train_loss = 0.142815, train_acc = 0.984406, validation_loss = 3.050943, validation_acc = 0.883664
--- 2068.303825378418 seconds ---
batch_number = 10, loss = 1.015075, acc = 0.984582
--- 2075.329662799835 seconds ---
batch_number = 20, loss = 1.067768, acc = 0.984369
--- 2084.3044171333313 seconds ---
batch_number = 30, loss = 1.067081, acc = 0.985093
--- 2093.101345062256 seconds ---
batch_number = 40, loss = 1.056147, acc = 0.985441
--- 2103.215191602707 seconds ---
batch_number = 50, loss = 1.067437, acc = 0.985844
--- 2112.3920969963074 seconds ---
batch_number = 60, loss = 1.069105, acc = 0.985985
--- 2121.016204357147 seconds ---
batch_number = 70, loss = 1.062149, acc = 0.986093
--- 2127.554918527603 seconds ---
batch_number = 80, loss = 1.089311, acc = 0.985933
--- 2137.5876994132996 seconds ---
batch_number = 90, loss = 1.075143, acc = 0.986152
--- 2148.220495223999 seconds ---
batch_number = 100, loss = 1.069458, acc = 0.986160
--- 2156.4930284023285 seconds ---
batch_number = 110, loss = 1.069646, acc = 0.986183
--- 2163.3391377925873 seconds ---
batch_number = 120, loss = 1.080193, acc = 0.986068
--- 2172.8465571403503 seconds ---
batch_number = 130, loss = 1.075202, acc = 0.986063
--- 2181.913910627365 seconds ---
batch_number = 140, loss = 1.077084, acc = 0.985914
--- 2190.0126762390137 seconds ---
batch_number = 150, loss = 1.075036, acc = 0.985961
--- 2198.9192752838135 seconds ---
batch_number = 160, loss = 1.076469, acc = 0.985943
[epoch 115]: train_loss = 0.136863, train_acc = 0.985905, validation_loss = 3.009146, validation_acc = 0.884022
--- 2215.364090681076 seconds ---
batch_number = 10, loss = 0.891097, acc = 0.988585
--- 2223.736559867859 seconds ---
batch_number = 20, loss = 0.954759, acc = 0.988435
--- 2232.261717557907 seconds ---
batch_number = 30, loss = 0.978321, acc = 0.987678
--- 2240.925394296646 seconds ---
batch_number = 40, loss = 0.990330, acc = 0.987350
--- 2249.1975672245026 seconds ---
batch_number = 50, loss = 0.998980, acc = 0.986957
--- 2258.5486063957214 seconds ---
batch_number = 60, loss = 1.001535, acc = 0.986830
--- 2266.17037153244 seconds ---
batch_number = 70, loss = 1.008090, acc = 0.986707
--- 2275.540613412857 seconds ---
batch_number = 80, loss = 1.010369, acc = 0.986825
--- 2281.752655506134 seconds ---
batch_number = 90, loss = 1.024506, acc = 0.986603
--- 2290.2542259693146 seconds ---
batch_number = 100, loss = 1.030664, acc = 0.986447
--- 2300.337329149246 seconds ---
batch_number = 110, loss = 1.027285, acc = 0.986537
--- 2309.0878071784973 seconds ---
batch_number = 120, loss = 1.024051, acc = 0.986531
--- 2318.0331082344055 seconds ---
batch_number = 130, loss = 1.024240, acc = 0.986493
--- 2327.890765428543 seconds ---
batch_number = 140, loss = 1.016830, acc = 0.986619
--- 2336.163516521454 seconds ---
batch_number = 150, loss = 1.021106, acc = 0.986517
--- 2345.2029395103455 seconds ---
batch_number = 160, loss = 1.021428, acc = 0.986478
[epoch 116]: train_loss = 0.129326, train_acc = 0.986383, validation_loss = 3.132279, validation_acc = 0.876982
--- 2362.475921869278 seconds ---
batch_number = 10, loss = 0.983705, acc = 0.987225
--- 2369.6646630764008 seconds ---
batch_number = 20, loss = 1.030995, acc = 0.987290
--- 2377.8885402679443 seconds ---
batch_number = 30, loss = 1.034898, acc = 0.986484
--- 2386.493676662445 seconds ---
batch_number = 40, loss = 1.020528, acc = 0.986934
--- 2395.8349738121033 seconds ---
batch_number = 50, loss = 1.007457, acc = 0.986759
--- 2405.422099351883 seconds ---
batch_number = 60, loss = 1.011304, acc = 0.986694
--- 2414.7657368183136 seconds ---
batch_number = 70, loss = 1.005102, acc = 0.986829
--- 2421.7970695495605 seconds ---
batch_number = 80, loss = 1.014526, acc = 0.986618
--- 2429.8350400924683 seconds ---
batch_number = 90, loss = 1.016446, acc = 0.986394
--- 2439.021901845932 seconds ---
batch_number = 100, loss = 1.012567, acc = 0.986497
--- 2447.2065346240997 seconds ---
batch_number = 110, loss = 1.014611, acc = 0.986387
--- 2455.75568318367 seconds ---
batch_number = 120, loss = 1.017170, acc = 0.986472
--- 2463.454123735428 seconds ---
batch_number = 130, loss = 1.021772, acc = 0.986330
--- 2472.5062692165375 seconds ---
batch_number = 140, loss = 1.017264, acc = 0.986367
--- 2483.0920736789703 seconds ---
batch_number = 150, loss = 1.010757, acc = 0.986416
--- 2492.0422353744507 seconds ---
batch_number = 160, loss = 1.014212, acc = 0.986446
[epoch 117]: train_loss = 0.128990, train_acc = 0.986458, validation_loss = 3.096884, validation_acc = 0.884491
--- 2508.6951208114624 seconds ---
batch_number = 10, loss = 0.838502, acc = 0.986767
--- 2518.0316791534424 seconds ---
batch_number = 20, loss = 0.910020, acc = 0.986098
--- 2526.1059532165527 seconds ---
batch_number = 30, loss = 0.931102, acc = 0.986461
--- 2535.897398710251 seconds ---
batch_number = 40, loss = 0.920434, acc = 0.986950
--- 2543.1607360839844 seconds ---
batch_number = 50, loss = 0.940471, acc = 0.986849
--- 2552.5649807453156 seconds ---
batch_number = 60, loss = 0.949099, acc = 0.986507
--- 2561.7984981536865 seconds ---
batch_number = 70, loss = 0.953038, acc = 0.986420
--- 2570.434875011444 seconds ---
batch_number = 80, loss = 0.964615, acc = 0.986446
--- 2578.6491537094116 seconds ---
batch_number = 90, loss = 0.965560, acc = 0.986313
--- 2587.2211349010468 seconds ---
batch_number = 100, loss = 0.964522, acc = 0.986191
--- 2595.366712331772 seconds ---
batch_number = 110, loss = 0.971902, acc = 0.986312
--- 2605.0493471622467 seconds ---
batch_number = 120, loss = 0.974667, acc = 0.986298
--- 2613.8010330200195 seconds ---
batch_number = 130, loss = 0.973121, acc = 0.986403
--- 2622.6390182971954 seconds ---
batch_number = 140, loss = 0.975352, acc = 0.986505
--- 2630.2727098464966 seconds ---
batch_number = 150, loss = 0.988398, acc = 0.986397
--- 2638.410523891449 seconds ---
batch_number = 160, loss = 0.990350, acc = 0.986377
[epoch 118]: train_loss = 0.125708, train_acc = 0.986355, validation_loss = 3.141188, validation_acc = 0.879974
--- 2655.3177514076233 seconds ---
batch_number = 10, loss = 0.835205, acc = 0.987602
--- 2664.58877491951 seconds ---
batch_number = 20, loss = 0.885568, acc = 0.987892
--- 2673.426073074341 seconds ---
batch_number = 30, loss = 0.922812, acc = 0.988115
--- 2681.173344373703 seconds ---
batch_number = 40, loss = 0.955627, acc = 0.987912
--- 2690.1548280715942 seconds ---
batch_number = 50, loss = 0.945949, acc = 0.987507
--- 2698.885088443756 seconds ---
batch_number = 60, loss = 0.943385, acc = 0.987432
--- 2706.6043684482574 seconds ---
batch_number = 70, loss = 0.951286, acc = 0.987205
--- 2713.9987144470215 seconds ---
batch_number = 80, loss = 0.966956, acc = 0.986556
--- 2720.9161410331726 seconds ---
batch_number = 90, loss = 0.987772, acc = 0.986241
--- 2729.8532423973083 seconds ---
batch_number = 100, loss = 0.985882, acc = 0.986174
--- 2738.24928355217 seconds ---
batch_number = 110, loss = 0.986312, acc = 0.986118
--- 2747.5171616077423 seconds ---
batch_number = 120, loss = 0.987886, acc = 0.986076
--- 2756.3818321228027 seconds ---
batch_number = 130, loss = 0.982942, acc = 0.986127
--- 2765.1308403015137 seconds ---
batch_number = 140, loss = 0.981573, acc = 0.986143
--- 2774.2843029499054 seconds ---
batch_number = 150, loss = 0.978462, acc = 0.986293
--- 2783.258314371109 seconds ---
batch_number = 160, loss = 0.981836, acc = 0.986300
[epoch 119]: train_loss = 0.124560, train_acc = 0.986236, validation_loss = 3.145990, validation_acc = 0.882908
--- 2800.3580298423767 seconds ---
batch_number = 10, loss = 0.992472, acc = 0.980986
--- 2809.3324058055878 seconds ---
batch_number = 20, loss = 1.035018, acc = 0.979666
--- 2816.7705619335175 seconds ---
batch_number = 30, loss = 1.098341, acc = 0.978860
--- 2824.800641298294 seconds ---
batch_number = 40, loss = 1.138811, acc = 0.977209
--- 2833.475056409836 seconds ---
batch_number = 50, loss = 1.129118, acc = 0.976474
--- 2841.9888620376587 seconds ---
batch_number = 60, loss = 1.126978, acc = 0.976911
--- 2850.542822122574 seconds ---
batch_number = 70, loss = 1.106918, acc = 0.977772
--- 2860.925088405609 seconds ---
batch_number = 80, loss = 1.101270, acc = 0.978740
--- 2869.675481081009 seconds ---
batch_number = 90, loss = 1.101886, acc = 0.978681
--- 2878.2692663669586 seconds ---
batch_number = 100, loss = 1.103953, acc = 0.978494
--- 2887.170263528824 seconds ---
batch_number = 110, loss = 1.095489, acc = 0.978551
--- 2895.817762851715 seconds ---
batch_number = 120, loss = 1.085395, acc = 0.978979
--- 2903.5647802352905 seconds ---
batch_number = 130, loss = 1.083057, acc = 0.979152
--- 2912.761592388153 seconds ---
batch_number = 140, loss = 1.079639, acc = 0.979482
--- 2921.2387590408325 seconds ---
batch_number = 150, loss = 1.077728, acc = 0.979742
--- 2930.6457545757294 seconds ---
batch_number = 160, loss = 1.072185, acc = 0.979891
[epoch 120]: train_loss = 0.135365, train_acc = 0.980058, validation_loss = 3.108625, validation_acc = 0.877558
--- 2947.2873125076294 seconds ---
batch_number = 10, loss = 1.036214, acc = 0.983200
--- 2956.366736650467 seconds ---
batch_number = 20, loss = 1.012632, acc = 0.985262
--- 2964.7482397556305 seconds ---
batch_number = 30, loss = 0.995273, acc = 0.984579
--- 2974.057417154312 seconds ---
batch_number = 40, loss = 0.993579, acc = 0.984795
--- 2981.770712375641 seconds ---
batch_number = 50, loss = 0.992642, acc = 0.984449
--- 2990.096138715744 seconds ---
batch_number = 60, loss = 1.002463, acc = 0.984667
--- 2998.264553785324 seconds ---
batch_number = 70, loss = 1.002835, acc = 0.984967
--- 3006.6872799396515 seconds ---
batch_number = 80, loss = 0.999281, acc = 0.985156
--- 3014.032019138336 seconds ---
batch_number = 90, loss = 1.021596, acc = 0.985035
--- 3022.870844602585 seconds ---
batch_number = 100, loss = 1.012480, acc = 0.985238
--- 3031.829684972763 seconds ---
batch_number = 110, loss = 1.003421, acc = 0.985200
--- 3040.3709015846252 seconds ---
batch_number = 120, loss = 0.999840, acc = 0.985416
--- 3049.602191925049 seconds ---
batch_number = 130, loss = 0.995833, acc = 0.985256
--- 3058.467832326889 seconds ---
batch_number = 140, loss = 0.996872, acc = 0.985281
--- 3068.115942001343 seconds ---
batch_number = 150, loss = 0.992177, acc = 0.985326
--- 3077.144957780838 seconds ---
batch_number = 160, loss = 0.993131, acc = 0.985267
[epoch 121]: train_loss = 0.125314, train_acc = 0.985294, validation_loss = 3.256200, validation_acc = 0.876005
--- 3094.656602859497 seconds ---
batch_number = 10, loss = 0.843051, acc = 0.985275
--- 3102.108594894409 seconds ---
batch_number = 20, loss = 0.949434, acc = 0.982949
--- 3111.0199551582336 seconds ---
batch_number = 30, loss = 0.976351, acc = 0.983106
--- 3119.3838374614716 seconds ---
batch_number = 40, loss = 0.980795, acc = 0.983308
--- 3129.2160952091217 seconds ---
batch_number = 50, loss = 0.981048, acc = 0.983855
--- 3137.3054094314575 seconds ---
batch_number = 60, loss = 0.988298, acc = 0.983937
--- 3146.2823219299316 seconds ---
batch_number = 70, loss = 0.981815, acc = 0.984417
--- 3155.1513710021973 seconds ---
batch_number = 80, loss = 0.980996, acc = 0.984681
--- 3162.5777082443237 seconds ---
batch_number = 90, loss = 0.979187, acc = 0.984732
--- 3169.5872690677643 seconds ---
batch_number = 100, loss = 0.993415, acc = 0.984356
--- 3177.89009308815 seconds ---
batch_number = 110, loss = 1.044158, acc = 0.982056
--- 3185.9658234119415 seconds ---
batch_number = 120, loss = 1.104607, acc = 0.978557
--- 3195.0840005874634 seconds ---
batch_number = 130, loss = 1.209808, acc = 0.974481
--- 3203.560421228409 seconds ---
batch_number = 140, loss = 1.323156, acc = 0.969002
--- 3211.329301595688 seconds ---
batch_number = 150, loss = 1.425309, acc = 0.964422
--- 3220.2534143924713 seconds ---
batch_number = 160, loss = 1.485007, acc = 0.961039
[epoch 122]: train_loss = 0.193685, train_acc = 0.960011, validation_loss = 4.740047, validation_acc = 0.805235
--- 3237.7750408649445 seconds ---
batch_number = 10, loss = 3.939646, acc = 0.828836
--- 3245.557386636734 seconds ---
batch_number = 20, loss = 3.916566, acc = 0.811367
--- 3254.9102289676666 seconds ---
batch_number = 30, loss = 3.775139, acc = 0.816599
--- 3264.0145785808563 seconds ---
batch_number = 40, loss = 3.574498, acc = 0.829982
--- 3271.2292523384094 seconds ---
batch_number = 50, loss = 3.437870, acc = 0.832741
--- 3280.625343322754 seconds ---
batch_number = 60, loss = 3.347481, acc = 0.840417
--- 3288.234674692154 seconds ---
batch_number = 70, loss = 3.203372, acc = 0.847991
--- 3297.883348464966 seconds ---
batch_number = 80, loss = 3.071359, acc = 0.857997
--- 3306.0463786125183 seconds ---
batch_number = 90, loss = 2.971166, acc = 0.862514
--- 3314.3674051761627 seconds ---
batch_number = 100, loss = 3.235096, acc = 0.857827
--- 3323.0630099773407 seconds ---
batch_number = 110, loss = 3.334349, acc = 0.853502
--- 3330.192848920822 seconds ---
batch_number = 120, loss = 3.344304, acc = 0.855284
--- 3339.291864156723 seconds ---
batch_number = 130, loss = 3.478145, acc = 0.853428
--- 3347.423421382904 seconds ---
batch_number = 140, loss = 3.829410, acc = 0.838519
--- 3358.6480901241302 seconds ---
batch_number = 150, loss = 3.921747, acc = 0.833100
--- 3366.7613112926483 seconds ---
batch_number = 160, loss = 3.962953, acc = 0.829379
[epoch 123]: train_loss = 0.498904, train_acc = 0.829356, validation_loss = 4.566705, validation_acc = 0.783095
--- 3383.4909229278564 seconds ---
batch_number = 10, loss = 2.706517, acc = 0.881460
--- 3391.5626018047333 seconds ---
batch_number = 20, loss = 2.609764, acc = 0.901700
--- 3400.7059183120728 seconds ---
batch_number = 30, loss = 2.574353, acc = 0.918374
--- 3408.222946166992 seconds ---
batch_number = 40, loss = 2.488172, acc = 0.923415
--- 3417.543839454651 seconds ---
batch_number = 50, loss = 2.415138, acc = 0.929900
--- 3427.451629638672 seconds ---
batch_number = 60, loss = 2.329457, acc = 0.933758
--- 3435.485480070114 seconds ---
batch_number = 70, loss = 2.318325, acc = 0.934620
--- 3444.459322452545 seconds ---
batch_number = 80, loss = 2.319457, acc = 0.936575
--- 3452.9994699954987 seconds ---
batch_number = 90, loss = 2.304130, acc = 0.936989
--- 3462.1163148880005 seconds ---
batch_number = 100, loss = 2.282876, acc = 0.937664
--- 3471.0606429576874 seconds ---
batch_number = 110, loss = 2.264246, acc = 0.938929
--- 3480.4041380882263 seconds ---
batch_number = 120, loss = 2.222543, acc = 0.940698
--- 3489.7284665107727 seconds ---
batch_number = 130, loss = 2.185893, acc = 0.942651
--- 3498.2821550369263 seconds ---
batch_number = 140, loss = 2.148071, acc = 0.944439
--- 3505.311945915222 seconds ---
batch_number = 150, loss = 2.113257, acc = 0.945732
--- 3513.498512506485 seconds ---
batch_number = 160, loss = 2.081064, acc = 0.946847
[epoch 124]: train_loss = 0.262701, train_acc = 0.947165, validation_loss = 3.355448, validation_acc = 0.870821
--- 3529.327265024185 seconds ---
batch_number = 10, loss = 1.397735, acc = 0.975047
--- 3535.4115364551544 seconds ---
batch_number = 20, loss = 1.581263, acc = 0.970222
--- 3543.890193939209 seconds ---
batch_number = 30, loss = 1.555730, acc = 0.970106
--- 3553.536450624466 seconds ---
batch_number = 40, loss = 1.506582, acc = 0.972215
--- 3562.0101239681244 seconds ---
batch_number = 50, loss = 1.518645, acc = 0.971392
--- 3569.6823468208313 seconds ---
batch_number = 60, loss = 1.532033, acc = 0.970329
--- 3577.338907957077 seconds ---
batch_number = 70, loss = 1.554263, acc = 0.969849
--- 3586.442254781723 seconds ---
batch_number = 80, loss = 1.549528, acc = 0.969505
--- 3595.272974729538 seconds ---
batch_number = 90, loss = 1.548064, acc = 0.969498
--- 3604.613140106201 seconds ---
batch_number = 100, loss = 1.528216, acc = 0.970714
--- 3613.5660746097565 seconds ---
batch_number = 110, loss = 1.522386, acc = 0.971021
--- 3622.681081056595 seconds ---
batch_number = 120, loss = 1.506334, acc = 0.971801
--- 3631.3976895809174 seconds ---
batch_number = 130, loss = 1.495094, acc = 0.972397
--- 3639.86470079422 seconds ---
batch_number = 140, loss = 1.489247, acc = 0.972627
--- 3647.195859193802 seconds ---
batch_number = 150, loss = 1.479232, acc = 0.972936
--- 3654.947585582733 seconds ---
batch_number = 160, loss = 1.472424, acc = 0.973162
[epoch 125]: train_loss = 0.185356, train_acc = 0.973334, validation_loss = 3.065247, validation_acc = 0.884511
--- 3672.236348628998 seconds ---
batch_number = 10, loss = 1.107000, acc = 0.982838
--- 3681.2644708156586 seconds ---
batch_number = 20, loss = 1.138265, acc = 0.983019
--- 3689.1655032634735 seconds ---
batch_number = 30, loss = 1.191965, acc = 0.982001
--- 3697.1663360595703 seconds ---
batch_number = 40, loss = 1.191701, acc = 0.982266
--- 3704.6046640872955 seconds ---
batch_number = 50, loss = 1.200037, acc = 0.981900
--- 3712.922511100769 seconds ---
batch_number = 60, loss = 1.209176, acc = 0.982004
--- 3721.802400112152 seconds ---
batch_number = 70, loss = 1.199372, acc = 0.982561
--- 3730.5881197452545 seconds ---
batch_number = 80, loss = 1.189933, acc = 0.982950
--- 3739.234950065613 seconds ---
batch_number = 90, loss = 1.191918, acc = 0.982990
--- 3747.8931646347046 seconds ---
batch_number = 100, loss = 1.193811, acc = 0.983105
--- 3757.546292066574 seconds ---
batch_number = 110, loss = 1.183888, acc = 0.983237
--- 3765.560483455658 seconds ---
batch_number = 120, loss = 1.182383, acc = 0.983294
--- 3774.618790626526 seconds ---
batch_number = 130, loss = 1.182990, acc = 0.983329
--- 3784.3393726348877 seconds ---
batch_number = 140, loss = 1.177288, acc = 0.983404
--- 3792.289026260376 seconds ---
batch_number = 150, loss = 1.180823, acc = 0.983422
--- 3799.9226944446564 seconds ---
batch_number = 160, loss = 1.186311, acc = 0.983321
[epoch 126]: train_loss = 0.149478, train_acc = 0.983343, validation_loss = 2.957967, validation_acc = 0.888376
--- 3819.07635307312 seconds ---
batch_number = 10, loss = 0.965506, acc = 0.985669
--- 3829.8124260902405 seconds ---
batch_number = 20, loss = 0.990783, acc = 0.985242
--- 3836.696679353714 seconds ---
batch_number = 30, loss = 1.046960, acc = 0.984984
--- 3844.4447395801544 seconds ---
batch_number = 40, loss = 1.075774, acc = 0.985196
--- 3854.568011045456 seconds ---
batch_number = 50, loss = 1.060380, acc = 0.985593
--- 3862.66122674942 seconds ---
batch_number = 60, loss = 1.070777, acc = 0.985455
--- 3870.987612247467 seconds ---
batch_number = 70, loss = 1.082770, acc = 0.985755
--- 3879.244919538498 seconds ---
batch_number = 80, loss = 1.089056, acc = 0.985929
--- 3886.4847707748413 seconds ---
batch_number = 90, loss = 1.089220, acc = 0.985866
--- 3895.045708179474 seconds ---
batch_number = 100, loss = 1.087632, acc = 0.985559
--- 3902.017476081848 seconds ---
batch_number = 110, loss = 1.097793, acc = 0.985490
--- 3911.463019132614 seconds ---
batch_number = 120, loss = 1.090374, acc = 0.985636
--- 3920.9659354686737 seconds ---
batch_number = 130, loss = 1.090866, acc = 0.985630
--- 3928.1961526870728 seconds ---
batch_number = 140, loss = 1.091756, acc = 0.985560
--- 3935.7821683883667 seconds ---
batch_number = 150, loss = 1.093558, acc = 0.985639
--- 3944.22442984581 seconds ---
batch_number = 160, loss = 1.093786, acc = 0.985675
[epoch 127]: train_loss = 0.138163, train_acc = 0.985616, validation_loss = 3.018969, validation_acc = 0.891434
--- 3962.625220298767 seconds ---
batch_number = 10, loss = 0.885995, acc = 0.987430
--- 3971.1676383018494 seconds ---
batch_number = 20, loss = 0.955734, acc = 0.987611
--- 3977.4080123901367 seconds ---
batch_number = 30, loss = 1.012140, acc = 0.986798
--- 3986.4291653633118 seconds ---
batch_number = 40, loss = 1.020760, acc = 0.987118
--- 3995.993210554123 seconds ---
batch_number = 50, loss = 1.028792, acc = 0.987266
--- 4004.883618116379 seconds ---
batch_number = 60, loss = 1.025023, acc = 0.987388
--- 4011.645138025284 seconds ---
batch_number = 70, loss = 1.032067, acc = 0.987002
--- 4020.962012529373 seconds ---
batch_number = 80, loss = 1.029337, acc = 0.986942
--- 4029.5136282444 seconds ---
batch_number = 90, loss = 1.032684, acc = 0.987047
--- 4037.7310733795166 seconds ---
batch_number = 100, loss = 1.036451, acc = 0.987051
--- 4046.77818608284 seconds ---
batch_number = 110, loss = 1.040942, acc = 0.986968
--- 4055.5885841846466 seconds ---
batch_number = 120, loss = 1.038962, acc = 0.986850
--- 4065.4750249385834 seconds ---
batch_number = 130, loss = 1.031407, acc = 0.986887
--- 4074.441597223282 seconds ---
batch_number = 140, loss = 1.028792, acc = 0.986877
--- 4083.7844083309174 seconds ---
batch_number = 150, loss = 1.024479, acc = 0.986845
--- 4092.2402136325836 seconds ---
batch_number = 160, loss = 1.023070, acc = 0.986895
[epoch 128]: train_loss = 0.129177, train_acc = 0.986983, validation_loss = 3.143717, validation_acc = 0.884843
--- 4112.03715634346 seconds ---
batch_number = 10, loss = 0.866613, acc = 0.987919
--- 4121.205001592636 seconds ---
batch_number = 20, loss = 0.912311, acc = 0.988118
--- 4130.902643918991 seconds ---
batch_number = 30, loss = 0.939576, acc = 0.988346
--- 4139.988076925278 seconds ---
batch_number = 40, loss = 0.950712, acc = 0.988114
--- 4148.382420301437 seconds ---
batch_number = 50, loss = 0.954425, acc = 0.987988
--- 4156.265468120575 seconds ---
batch_number = 60, loss = 0.967880, acc = 0.987365
--- 4164.429582595825 seconds ---
batch_number = 70, loss = 0.977801, acc = 0.987131
--- 4173.317898273468 seconds ---
batch_number = 80, loss = 0.979099, acc = 0.987027
--- 4182.446583509445 seconds ---
batch_number = 90, loss = 0.975320, acc = 0.986874
--- 4191.304431438446 seconds ---
batch_number = 100, loss = 0.982131, acc = 0.986951
--- 4200.607558488846 seconds ---
batch_number = 110, loss = 0.977843, acc = 0.986978
--- 4209.317469835281 seconds ---
batch_number = 120, loss = 0.984137, acc = 0.986991
--- 4217.4743111133575 seconds ---
batch_number = 130, loss = 0.982852, acc = 0.986993
--- 4225.928064584732 seconds ---
batch_number = 140, loss = 0.982471, acc = 0.987042
--- 4234.425812005997 seconds ---
batch_number = 150, loss = 0.983221, acc = 0.987040
--- 4242.8786289691925 seconds ---
batch_number = 160, loss = 0.980951, acc = 0.987118
[epoch 129]: train_loss = 0.124220, train_acc = 0.987120, validation_loss = 2.972649, validation_acc = 0.892876
--- 4260.8998827934265 seconds ---
batch_number = 10, loss = 0.793546, acc = 0.989671
--- 4269.320123434067 seconds ---
batch_number = 20, loss = 0.878968, acc = 0.988763
--- 4277.925631523132 seconds ---
batch_number = 30, loss = 0.913671, acc = 0.988051
--- 4285.961092472076 seconds ---
batch_number = 40, loss = 0.946733, acc = 0.987474
--- 4295.732997894287 seconds ---
batch_number = 50, loss = 0.933561, acc = 0.987726
--- 4305.632218837738 seconds ---
batch_number = 60, loss = 0.928726, acc = 0.987900
--- 4313.003908157349 seconds ---
batch_number = 70, loss = 0.940931, acc = 0.987677
--- 4320.929627656937 seconds ---
batch_number = 80, loss = 0.946700, acc = 0.987532
--- 4329.27022767067 seconds ---
batch_number = 90, loss = 0.954513, acc = 0.987430
--- 4339.012984275818 seconds ---
batch_number = 100, loss = 0.946373, acc = 0.987591
--- 4346.746880531311 seconds ---
batch_number = 110, loss = 0.954266, acc = 0.987444
--- 4355.928988933563 seconds ---
batch_number = 120, loss = 0.952940, acc = 0.987525
--- 4363.999791145325 seconds ---
batch_number = 130, loss = 0.955078, acc = 0.987476
--- 4372.276754140854 seconds ---
batch_number = 140, loss = 0.961484, acc = 0.987386
--- 4381.21458363533 seconds ---
batch_number = 150, loss = 0.962098, acc = 0.987256
--- 4390.533464193344 seconds ---
batch_number = 160, loss = 0.960723, acc = 0.987268
[epoch 130]: train_loss = 0.121751, train_acc = 0.987235, validation_loss = 3.185608, validation_acc = 0.879480
--- 4407.908975601196 seconds ---
batch_number = 10, loss = 0.900299, acc = 0.984548
--- 4416.170454025269 seconds ---
batch_number = 20, loss = 0.945869, acc = 0.985418
--- 4425.481228590012 seconds ---
batch_number = 30, loss = 0.950547, acc = 0.986140
--- 4433.631530046463 seconds ---
batch_number = 40, loss = 0.954932, acc = 0.986447
--- 4443.07529258728 seconds ---
batch_number = 50, loss = 0.934507, acc = 0.986573
--- 4452.840337276459 seconds ---
batch_number = 60, loss = 0.917083, acc = 0.987039
--- 4463.651455402374 seconds ---
batch_number = 70, loss = 0.911203, acc = 0.987454
--- 4473.155161857605 seconds ---
batch_number = 80, loss = 0.907516, acc = 0.987561
--- 4481.5024790763855 seconds ---
batch_number = 90, loss = 0.917181, acc = 0.987339
--- 4489.990807771683 seconds ---
batch_number = 100, loss = 0.922441, acc = 0.987206
--- 4497.997841835022 seconds ---
batch_number = 110, loss = 0.931542, acc = 0.986938
--- 4506.110492706299 seconds ---
batch_number = 120, loss = 0.931333, acc = 0.986960
--- 4514.610524177551 seconds ---
batch_number = 130, loss = 0.931197, acc = 0.986929
--- 4522.742464542389 seconds ---
batch_number = 140, loss = 0.932289, acc = 0.986927
--- 4530.396106481552 seconds ---
batch_number = 150, loss = 0.938074, acc = 0.986784
--- 4539.610698461533 seconds ---
batch_number = 160, loss = 0.940513, acc = 0.986630
[epoch 131]: train_loss = 0.118775, train_acc = 0.986674, validation_loss = 2.954534, validation_acc = 0.894775
--- 4556.256685495377 seconds ---
batch_number = 10, loss = 0.888341, acc = 0.986803
--- 4565.856130599976 seconds ---
batch_number = 20, loss = 0.913297, acc = 0.987984
--- 4574.881455421448 seconds ---
batch_number = 30, loss = 0.904335, acc = 0.988139
--- 4583.964381694794 seconds ---
batch_number = 40, loss = 0.878162, acc = 0.988467
--- 4592.164599895477 seconds ---
batch_number = 50, loss = 0.891818, acc = 0.988227
--- 4600.7114107608795 seconds ---
batch_number = 60, loss = 0.904219, acc = 0.987990
--- 4609.041101932526 seconds ---
batch_number = 70, loss = 0.907710, acc = 0.987969
--- 4617.740805149078 seconds ---
batch_number = 80, loss = 0.907208, acc = 0.987820
--- 4628.5124335289 seconds ---
batch_number = 90, loss = 0.898855, acc = 0.987753
--- 4635.831778526306 seconds ---
batch_number = 100, loss = 0.904414, acc = 0.987758
--- 4644.275901556015 seconds ---
batch_number = 110, loss = 0.910626, acc = 0.987707
--- 4651.044261455536 seconds ---
batch_number = 120, loss = 0.918113, acc = 0.987546
--- 4660.969445705414 seconds ---
batch_number = 130, loss = 0.921666, acc = 0.987557
--- 4668.986362695694 seconds ---
batch_number = 140, loss = 0.921175, acc = 0.987592
--- 4677.332731246948 seconds ---
batch_number = 150, loss = 0.921969, acc = 0.987527
--- 4685.02846455574 seconds ---
batch_number = 160, loss = 0.926288, acc = 0.987580
[epoch 132]: train_loss = 0.117567, train_acc = 0.987535, validation_loss = 3.065887, validation_acc = 0.887640
--- 4700.983123064041 seconds ---
batch_number = 10, loss = 0.776272, acc = 0.988849
--- 4710.228972911835 seconds ---
batch_number = 20, loss = 0.814018, acc = 0.988221
--- 4718.940319299698 seconds ---
batch_number = 30, loss = 0.839200, acc = 0.988661
--- 4728.2545709609985 seconds ---
batch_number = 40, loss = 0.853223, acc = 0.988756
--- 4737.55887389183 seconds ---
batch_number = 50, loss = 0.858966, acc = 0.988832
--- 4745.419105768204 seconds ---
batch_number = 60, loss = 0.870857, acc = 0.988642
--- 4753.323781251907 seconds ---
batch_number = 70, loss = 0.876781, acc = 0.988471
--- 4761.651185274124 seconds ---
batch_number = 80, loss = 0.889264, acc = 0.988498
--- 4770.362668514252 seconds ---
batch_number = 90, loss = 0.892347, acc = 0.988387
--- 4779.7251925468445 seconds ---
batch_number = 100, loss = 0.887219, acc = 0.988398
--- 4788.170291662216 seconds ---
batch_number = 110, loss = 0.887725, acc = 0.988443
--- 4797.163456439972 seconds ---
batch_number = 120, loss = 0.882248, acc = 0.988448
--- 4805.965748548508 seconds ---
batch_number = 130, loss = 0.884135, acc = 0.988305
--- 4814.855311393738 seconds ---
batch_number = 140, loss = 0.882281, acc = 0.988375
--- 4822.968456029892 seconds ---
batch_number = 150, loss = 0.883801, acc = 0.988283
--- 4831.915025234222 seconds ---
batch_number = 160, loss = 0.880306, acc = 0.988340
[epoch 133]: train_loss = 0.111906, train_acc = 0.988307, validation_loss = 3.048048, validation_acc = 0.890616
--- 4849.4923620224 seconds ---
batch_number = 10, loss = 0.766410, acc = 0.989154
--- 4859.5174515247345 seconds ---
batch_number = 20, loss = 0.809110, acc = 0.989012
--- 4867.602488279343 seconds ---
batch_number = 30, loss = 0.849175, acc = 0.988784
--- 4876.083194255829 seconds ---
batch_number = 40, loss = 0.847248, acc = 0.988838
--- 4884.264273643494 seconds ---
batch_number = 50, loss = 0.853771, acc = 0.988864
--- 4893.334825515747 seconds ---
batch_number = 60, loss = 0.860342, acc = 0.988489
--- 4902.535064697266 seconds ---
batch_number = 70, loss = 0.867150, acc = 0.988297
--- 4911.964134931564 seconds ---
batch_number = 80, loss = 0.867015, acc = 0.988435
--- 4920.123921632767 seconds ---
batch_number = 90, loss = 0.869886, acc = 0.988415
--- 4928.584819316864 seconds ---
batch_number = 100, loss = 0.871076, acc = 0.988285
--- 4937.639874696732 seconds ---
batch_number = 110, loss = 0.868139, acc = 0.988332
--- 4945.585506439209 seconds ---
batch_number = 120, loss = 0.873917, acc = 0.988294
--- 4954.181235790253 seconds ---
batch_number = 130, loss = 0.876443, acc = 0.988265
--- 4963.472511768341 seconds ---
batch_number = 140, loss = 0.876598, acc = 0.988274
--- 4970.709227561951 seconds ---
batch_number = 150, loss = 0.881518, acc = 0.988137
--- 4978.01370215416 seconds ---
batch_number = 160, loss = 0.884260, acc = 0.987998
[epoch 134]: train_loss = 0.112448, train_acc = 0.987976, validation_loss = 3.026105, validation_acc = 0.889392
--- 4994.767802000046 seconds ---
batch_number = 10, loss = 0.799028, acc = 0.986969
--- 5004.682659626007 seconds ---
batch_number = 20, loss = 0.809762, acc = 0.988625
--- 5012.126598596573 seconds ---
batch_number = 30, loss = 0.842520, acc = 0.988261
--- 5019.871100187302 seconds ---
batch_number = 40, loss = 0.882951, acc = 0.987066
--- 5029.470175981522 seconds ---
batch_number = 50, loss = 0.878405, acc = 0.986945
--- 5038.3734295368195 seconds ---
batch_number = 60, loss = 0.878026, acc = 0.986961
--- 5046.745588302612 seconds ---
batch_number = 70, loss = 0.880248, acc = 0.986398
--- 5055.916290044785 seconds ---
batch_number = 80, loss = 0.891748, acc = 0.985676
--- 5064.015804052353 seconds ---
batch_number = 90, loss = 0.899511, acc = 0.985520
--- 5073.518495321274 seconds ---
batch_number = 100, loss = 0.896088, acc = 0.985613
--- 5080.8624494075775 seconds ---
batch_number = 110, loss = 0.901327, acc = 0.985747
--- 5088.624535322189 seconds ---
batch_number = 120, loss = 0.903639, acc = 0.985739
--- 5096.765392303467 seconds ---
batch_number = 130, loss = 0.904046, acc = 0.985946
--- 5105.519819498062 seconds ---
batch_number = 140, loss = 0.906608, acc = 0.986022
--- 5113.656592607498 seconds ---
batch_number = 150, loss = 0.906701, acc = 0.986112
--- 5122.615794658661 seconds ---
batch_number = 160, loss = 0.905014, acc = 0.986141
[epoch 135]: train_loss = 0.114190, train_acc = 0.986245, validation_loss = 3.218160, validation_acc = 0.882176
--- 5140.623712062836 seconds ---
batch_number = 10, loss = 0.819910, acc = 0.986674
--- 5150.178230047226 seconds ---
batch_number = 20, loss = 0.885201, acc = 0.983236
--- 5159.885788202286 seconds ---
batch_number = 30, loss = 0.889795, acc = 0.983229
--- 5167.391008853912 seconds ---
batch_number = 40, loss = 0.921702, acc = 0.982664
--- 5175.762991905212 seconds ---
batch_number = 50, loss = 0.947196, acc = 0.981132
--- 5184.018872261047 seconds ---
batch_number = 60, loss = 1.250376, acc = 0.970782
--- 5193.248781681061 seconds ---
batch_number = 70, loss = 1.629507, acc = 0.955410
--- 5200.124282836914 seconds ---
batch_number = 80, loss = 2.091144, acc = 0.932641
--- 5208.300004720688 seconds ---
batch_number = 90, loss = 2.973586, acc = 0.897933
--- 5216.689925670624 seconds ---
batch_number = 100, loss = 3.396557, acc = 0.865809
--- 5224.454283952713 seconds ---
batch_number = 110, loss = 3.766876, acc = 0.850943
--- 5233.306533575058 seconds ---
batch_number = 120, loss = 4.042900, acc = 0.835804
--- 5243.210839509964 seconds ---
batch_number = 130, loss = 4.157031, acc = 0.829168
--- 5251.193944454193 seconds ---
batch_number = 140, loss = 4.299069, acc = 0.821268
--- 5259.736123085022 seconds ---
batch_number = 150, loss = 4.323665, acc = 0.817635
--- 5269.285536766052 seconds ---
batch_number = 160, loss = 4.283025, acc = 0.820156
[epoch 136]: train_loss = 0.540389, train_acc = 0.820995, validation_loss = 5.144240, validation_acc = 0.781174
--- 5286.7125742435455 seconds ---
batch_number = 10, loss = 2.586174, acc = 0.915123
--- 5295.94017291069 seconds ---
batch_number = 20, loss = 2.696969, acc = 0.917926
--- 5305.040617227554 seconds ---
batch_number = 30, loss = 3.143838, acc = 0.896046
--- 5314.2409336566925 seconds ---
batch_number = 40, loss = 3.257570, acc = 0.894060
--- 5322.39265370369 seconds ---
batch_number = 50, loss = 3.697768, acc = 0.872165
--- 5329.949241638184 seconds ---
batch_number = 60, loss = 3.680634, acc = 0.869468
--- 5337.559443473816 seconds ---
batch_number = 70, loss = 3.670179, acc = 0.869990
--- 5346.176386594772 seconds ---
batch_number = 80, loss = 3.573438, acc = 0.873851
--- 5353.321999311447 seconds ---
batch_number = 90, loss = 3.545082, acc = 0.876926
--- 5362.021863460541 seconds ---
batch_number = 100, loss = 3.447667, acc = 0.882266
--- 5370.012615442276 seconds ---
batch_number = 110, loss = 3.345397, acc = 0.886866
--- 5378.398421287537 seconds ---
batch_number = 120, loss = 3.281354, acc = 0.890732
--- 5388.237347126007 seconds ---
batch_number = 130, loss = 3.206852, acc = 0.895611
--- 5396.930958032608 seconds ---
batch_number = 140, loss = 3.128282, acc = 0.900437
--- 5406.716402769089 seconds ---
batch_number = 150, loss = 3.054366, acc = 0.904244
--- 5414.764946222305 seconds ---
batch_number = 160, loss = 2.986000, acc = 0.907210
[epoch 137]: train_loss = 0.374763, train_acc = 0.908112, validation_loss = 4.154984, validation_acc = 0.811269
--- 5432.24764418602 seconds ---
batch_number = 10, loss = 2.679224, acc = 0.926587
--- 5441.799170255661 seconds ---
batch_number = 20, loss = 2.443657, acc = 0.936518
--- 5450.1528244018555 seconds ---
batch_number = 30, loss = 2.287961, acc = 0.940625
--- 5458.066331386566 seconds ---
batch_number = 40, loss = 2.252416, acc = 0.942875
--- 5467.579348087311 seconds ---
batch_number = 50, loss = 2.124738, acc = 0.947422
--- 5477.711457967758 seconds ---
batch_number = 60, loss = 2.038536, acc = 0.951852
--- 5485.928010463715 seconds ---
batch_number = 70, loss = 1.962099, acc = 0.954383
--- 5494.322899341583 seconds ---
batch_number = 80, loss = 1.920926, acc = 0.955991
--- 5503.169685602188 seconds ---
batch_number = 90, loss = 1.886225, acc = 0.957147
--- 5512.287833690643 seconds ---
batch_number = 100, loss = 1.852309, acc = 0.958945
--- 5520.427765130997 seconds ---
batch_number = 110, loss = 1.814636, acc = 0.960324
--- 5529.225988864899 seconds ---
batch_number = 120, loss = 1.785951, acc = 0.961610
--- 5537.943149089813 seconds ---
batch_number = 130, loss = 1.752951, acc = 0.962568
--- 5546.118989944458 seconds ---
batch_number = 140, loss = 1.734530, acc = 0.963461
--- 5553.395297050476 seconds ---
batch_number = 150, loss = 1.717171, acc = 0.964289
--- 5562.458094835281 seconds ---
batch_number = 160, loss = 1.701087, acc = 0.965003
[epoch 138]: train_loss = 0.214144, train_acc = 0.965447, validation_loss = 3.383794, validation_acc = 0.869779
--- 5578.813482046127 seconds ---
batch_number = 10, loss = 1.178462, acc = 0.980389
--- 5585.939197301865 seconds ---
batch_number = 20, loss = 1.296147, acc = 0.977874
--- 5594.182605743408 seconds ---
batch_number = 30, loss = 1.301936, acc = 0.978526
--- 5602.342850923538 seconds ---
batch_number = 40, loss = 1.278375, acc = 0.979320
--- 5611.241659641266 seconds ---
batch_number = 50, loss = 1.291020, acc = 0.979082
--- 5621.2312524318695 seconds ---
batch_number = 60, loss = 1.292221, acc = 0.979876
--- 5630.359892368317 seconds ---
batch_number = 70, loss = 1.294181, acc = 0.980147
--- 5639.2186505794525 seconds ---
batch_number = 80, loss = 1.294663, acc = 0.980456
--- 5647.590694904327 seconds ---
batch_number = 90, loss = 1.300017, acc = 0.980417
--- 5654.7303814888 seconds ---
batch_number = 100, loss = 1.305561, acc = 0.980574
--- 5662.971997499466 seconds ---
batch_number = 110, loss = 1.297276, acc = 0.980451
--- 5671.906975269318 seconds ---
batch_number = 120, loss = 1.300616, acc = 0.979988
--- 5679.622666597366 seconds ---
batch_number = 130, loss = 1.293152, acc = 0.980043
--- 5688.135630607605 seconds ---
batch_number = 140, loss = 1.286164, acc = 0.980167
--- 5697.840195417404 seconds ---
batch_number = 150, loss = 1.286386, acc = 0.980228
--- 5706.521536111832 seconds ---
batch_number = 160, loss = 1.278626, acc = 0.980416
[epoch 139]: train_loss = 0.161742, train_acc = 0.980554, validation_loss = 3.216153, validation_acc = 0.886220
--- 5723.359077692032 seconds ---
batch_number = 10, loss = 1.012070, acc = 0.983875
--- 5732.630211591721 seconds ---
batch_number = 20, loss = 1.032057, acc = 0.984790
--- 5740.641113996506 seconds ---
batch_number = 30, loss = 1.047995, acc = 0.984831
--- 5749.4407505989075 seconds ---
batch_number = 40, loss = 1.066807, acc = 0.984887
--- 5757.033446550369 seconds ---
batch_number = 50, loss = 1.096807, acc = 0.984827
--- 5764.716470479965 seconds ---
batch_number = 60, loss = 1.120950, acc = 0.984780
--- 5774.084478855133 seconds ---
batch_number = 70, loss = 1.112942, acc = 0.984935
--- 5781.72428894043 seconds ---
batch_number = 80, loss = 1.116897, acc = 0.984782
--- 5790.957958698273 seconds ---
batch_number = 90, loss = 1.106164, acc = 0.984842
--- 5798.772409915924 seconds ---
batch_number = 100, loss = 1.108787, acc = 0.984828
--- 5807.49093914032 seconds ---
batch_number = 110, loss = 1.110157, acc = 0.984821
--- 5817.406208515167 seconds ---
batch_number = 120, loss = 1.101371, acc = 0.984876
--- 5825.4287922382355 seconds ---
batch_number = 130, loss = 1.107138, acc = 0.984945
--- 5832.886754274368 seconds ---
batch_number = 140, loss = 1.109548, acc = 0.984921
--- 5843.23814368248 seconds ---
batch_number = 150, loss = 1.100175, acc = 0.985163
--- 5853.206018447876 seconds ---
batch_number = 160, loss = 1.099267, acc = 0.985248
[epoch 140]: train_loss = 0.138427, train_acc = 0.985314, validation_loss = 3.305062, validation_acc = 0.881997
--- 5871.4682097435 seconds ---
batch_number = 10, loss = 0.932093, acc = 0.986548
--- 5879.531368494034 seconds ---
batch_number = 20, loss = 1.005840, acc = 0.986288
--- 5888.800550937653 seconds ---
batch_number = 30, loss = 1.007137, acc = 0.986911
--- 5897.583415269852 seconds ---
batch_number = 40, loss = 1.020075, acc = 0.986752
--- 5905.389618396759 seconds ---
batch_number = 50, loss = 1.038307, acc = 0.986687
--- 5913.569724082947 seconds ---
batch_number = 60, loss = 1.038397, acc = 0.986565
--- 5921.833961009979 seconds ---
batch_number = 70, loss = 1.045050, acc = 0.986518
--- 5929.411748170853 seconds ---
batch_number = 80, loss = 1.047504, acc = 0.986575
--- 5937.338742017746 seconds ---
batch_number = 90, loss = 1.053660, acc = 0.986654
--- 5947.797050952911 seconds ---
batch_number = 100, loss = 1.047302, acc = 0.986719
--- 5956.726112365723 seconds ---
batch_number = 110, loss = 1.038678, acc = 0.986888
--- 5965.870753288269 seconds ---
batch_number = 120, loss = 1.033842, acc = 0.986946
--- 5974.727426767349 seconds ---
batch_number = 130, loss = 1.034414, acc = 0.987003
--- 5982.3733694553375 seconds ---
batch_number = 140, loss = 1.038070, acc = 0.987021
--- 5990.742706298828 seconds ---
batch_number = 150, loss = 1.041464, acc = 0.986995
--- 6000.25323677063 seconds ---
batch_number = 160, loss = 1.034781, acc = 0.986940
[epoch 141]: train_loss = 0.130559, train_acc = 0.986952, validation_loss = 3.265648, validation_acc = 0.881951
--- 6018.012122869492 seconds ---
batch_number = 10, loss = 0.839961, acc = 0.987874
--- 6026.7449696063995 seconds ---
batch_number = 20, loss = 0.901835, acc = 0.988043
--- 6035.458989143372 seconds ---
batch_number = 30, loss = 0.941208, acc = 0.987762
--- 6043.29345870018 seconds ---
batch_number = 40, loss = 0.961480, acc = 0.987805
--- 6050.808026313782 seconds ---
batch_number = 50, loss = 0.976958, acc = 0.987594
--- 6059.230726480484 seconds ---
batch_number = 60, loss = 0.980081, acc = 0.987729
--- 6067.516786813736 seconds ---
batch_number = 70, loss = 0.991592, acc = 0.987708
--- 6076.871926546097 seconds ---
batch_number = 80, loss = 0.989012, acc = 0.987748
--- 6086.540678739548 seconds ---
batch_number = 90, loss = 0.984905, acc = 0.987667
--- 6095.40270280838 seconds ---
batch_number = 100, loss = 0.978408, acc = 0.987512
--- 6104.49569606781 seconds ---
batch_number = 110, loss = 0.977564, acc = 0.987488
--- 6112.427661418915 seconds ---
batch_number = 120, loss = 0.979824, acc = 0.987519
--- 6122.330276012421 seconds ---
batch_number = 130, loss = 0.976865, acc = 0.987553
--- 6130.0792055130005 seconds ---
batch_number = 140, loss = 0.983355, acc = 0.987575
--- 6139.350196361542 seconds ---
batch_number = 150, loss = 0.979421, acc = 0.987631
--- 6147.832829475403 seconds ---
batch_number = 160, loss = 0.982801, acc = 0.987506
[epoch 142]: train_loss = 0.124498, train_acc = 0.987483, validation_loss = 3.219506, validation_acc = 0.885530
--- 6164.1198790073395 seconds ---
batch_number = 10, loss = 0.893024, acc = 0.989552
--- 6173.667350053787 seconds ---
batch_number = 20, loss = 0.906657, acc = 0.988687
--- 6182.804973125458 seconds ---
batch_number = 30, loss = 0.901661, acc = 0.988635
--- 6191.597061395645 seconds ---
batch_number = 40, loss = 0.913499, acc = 0.988647
--- 6198.972765207291 seconds ---
batch_number = 50, loss = 0.917408, acc = 0.988555
--- 6207.372527122498 seconds ---
batch_number = 60, loss = 0.921599, acc = 0.988269
--- 6216.523442745209 seconds ---
batch_number = 70, loss = 0.919885, acc = 0.988334
--- 6224.090616703033 seconds ---
batch_number = 80, loss = 0.930895, acc = 0.988143
--- 6232.681170940399 seconds ---
batch_number = 90, loss = 0.937678, acc = 0.988195
--- 6242.910063028336 seconds ---
batch_number = 100, loss = 0.928333, acc = 0.988251
--- 6251.209683179855 seconds ---
batch_number = 110, loss = 0.938648, acc = 0.988143
--- 6259.555170536041 seconds ---
batch_number = 120, loss = 0.940095, acc = 0.988066
--- 6268.302629709244 seconds ---
batch_number = 130, loss = 0.941379, acc = 0.988057
--- 6277.818213701248 seconds ---
batch_number = 140, loss = 0.940342, acc = 0.988033
--- 6286.2883496284485 seconds ---
batch_number = 150, loss = 0.938578, acc = 0.987976
--- 6294.104289054871 seconds ---
batch_number = 160, loss = 0.945032, acc = 0.987917
[epoch 143]: train_loss = 0.119894, train_acc = 0.987904, validation_loss = 3.334028, validation_acc = 0.880336
--- 6310.325391054153 seconds ---
batch_number = 10, loss = 0.832538, acc = 0.988670
--- 6319.1145005226135 seconds ---
batch_number = 20, loss = 0.868775, acc = 0.988376
--- 6328.829452514648 seconds ---
batch_number = 30, loss = 0.866964, acc = 0.988499
--- 6338.043623209 seconds ---
batch_number = 40, loss = 0.884841, acc = 0.988607
--- 6346.759823322296 seconds ---
batch_number = 50, loss = 0.899154, acc = 0.988496
--- 6354.448361158371 seconds ---
batch_number = 60, loss = 0.912001, acc = 0.988470
--- 6363.785617351532 seconds ---
batch_number = 70, loss = 0.911823, acc = 0.988543
--- 6372.864295721054 seconds ---
batch_number = 80, loss = 0.907453, acc = 0.988526
--- 6381.68648982048 seconds ---
batch_number = 90, loss = 0.904368, acc = 0.988483
--- 6390.979934930801 seconds ---
batch_number = 100, loss = 0.899690, acc = 0.988536
--- 6399.994355201721 seconds ---
batch_number = 110, loss = 0.902847, acc = 0.988519
--- 6409.162997245789 seconds ---
batch_number = 120, loss = 0.906938, acc = 0.988456
--- 6417.599925994873 seconds ---
batch_number = 130, loss = 0.906381, acc = 0.988496
--- 6426.57207942009 seconds ---
batch_number = 140, loss = 0.902870, acc = 0.988487
--- 6435.831290245056 seconds ---
batch_number = 150, loss = 0.901904, acc = 0.988508
--- 6443.431542634964 seconds ---
batch_number = 160, loss = 0.907726, acc = 0.988435
[epoch 144]: train_loss = 0.114808, train_acc = 0.988430, validation_loss = 3.240128, validation_acc = 0.879502
--- 6460.6988615989685 seconds ---
batch_number = 10, loss = 0.779517, acc = 0.989645
--- 6470.041598558426 seconds ---
batch_number = 20, loss = 0.851308, acc = 0.989255
--- 6479.0287663936615 seconds ---
batch_number = 30, loss = 0.858278, acc = 0.989052
--- 6487.423900842667 seconds ---
batch_number = 40, loss = 0.879539, acc = 0.988781
--- 6494.77220582962 seconds ---
batch_number = 50, loss = 0.885887, acc = 0.988519
--- 6503.50741815567 seconds ---
batch_number = 60, loss = 0.892998, acc = 0.988564
--- 6513.014108657837 seconds ---
batch_number = 70, loss = 0.908344, acc = 0.987584
--- 6521.88378238678 seconds ---
batch_number = 80, loss = 0.939342, acc = 0.985991
--- 6529.776047945023 seconds ---
batch_number = 90, loss = 0.961906, acc = 0.984982
--- 6537.628096818924 seconds ---
batch_number = 100, loss = 0.979281, acc = 0.984333
--- 6546.904007673264 seconds ---
batch_number = 110, loss = 0.983152, acc = 0.984192
--- 6555.568320512772 seconds ---
batch_number = 120, loss = 1.000853, acc = 0.983458
--- 6563.689102888107 seconds ---
batch_number = 130, loss = 1.018257, acc = 0.982769
--- 6572.427565097809 seconds ---
batch_number = 140, loss = 1.032607, acc = 0.982107
--- 6581.000517845154 seconds ---
batch_number = 150, loss = 1.058405, acc = 0.980545
--- 6590.193376302719 seconds ---
batch_number = 160, loss = 1.069683, acc = 0.980117
[epoch 145]: train_loss = 0.136280, train_acc = 0.980096, validation_loss = 3.246501, validation_acc = 0.875373
--- 6610.1087374687195 seconds ---
batch_number = 10, loss = 0.998125, acc = 0.979463
--- 6618.304253816605 seconds ---
batch_number = 20, loss = 1.069163, acc = 0.977850
--- 6625.463894844055 seconds ---
batch_number = 30, loss = 1.109467, acc = 0.979060
--- 6633.482904911041 seconds ---
batch_number = 40, loss = 1.109971, acc = 0.979667
--- 6642.547336339951 seconds ---
batch_number = 50, loss = 1.088484, acc = 0.980528
--- 6653.14727973938 seconds ---
batch_number = 60, loss = 1.052184, acc = 0.981955
--- 6662.918712854385 seconds ---
batch_number = 70, loss = 1.029458, acc = 0.982616
--- 6671.726873397827 seconds ---
batch_number = 80, loss = 1.017263, acc = 0.983051
--- 6680.088924884796 seconds ---
batch_number = 90, loss = 1.010887, acc = 0.983289
--- 6688.81526184082 seconds ---
batch_number = 100, loss = 1.009643, acc = 0.983577
--- 6697.159889698029 seconds ---
batch_number = 110, loss = 1.001613, acc = 0.983738
--- 6704.816116333008 seconds ---
batch_number = 120, loss = 1.002737, acc = 0.983809
--- 6713.124866962433 seconds ---
batch_number = 130, loss = 1.002155, acc = 0.983969
--- 6722.400599956512 seconds ---
batch_number = 140, loss = 0.995731, acc = 0.984152
--- 6731.869776964188 seconds ---
batch_number = 150, loss = 0.989482, acc = 0.984377
--- 6738.839185714722 seconds ---
batch_number = 160, loss = 0.991297, acc = 0.984407
[epoch 146]: train_loss = 0.124751, train_acc = 0.984505, validation_loss = 3.069478, validation_acc = 0.882313
--- 6754.884192943573 seconds ---
batch_number = 10, loss = 0.813540, acc = 0.986668
--- 6763.562682390213 seconds ---
batch_number = 20, loss = 0.859291, acc = 0.987265
--- 6772.131177663803 seconds ---
batch_number = 30, loss = 0.865657, acc = 0.987278
--- 6780.410148143768 seconds ---
batch_number = 40, loss = 0.901030, acc = 0.987294
--- 6789.09944486618 seconds ---
batch_number = 50, loss = 0.910057, acc = 0.986170
--- 6798.727632045746 seconds ---
batch_number = 60, loss = 0.913307, acc = 0.986099
--- 6809.155481100082 seconds ---
batch_number = 70, loss = 0.904892, acc = 0.986493
--- 6817.927489757538 seconds ---
batch_number = 80, loss = 0.906210, acc = 0.986493
--- 6827.566260099411 seconds ---
batch_number = 90, loss = 0.901293, acc = 0.986733
--- 6836.107410430908 seconds ---
batch_number = 100, loss = 0.895185, acc = 0.986753
--- 6844.983026742935 seconds ---
batch_number = 110, loss = 0.893063, acc = 0.986991
--- 6853.988206148148 seconds ---
batch_number = 120, loss = 0.890752, acc = 0.987178
--- 6861.6385679244995 seconds ---
batch_number = 130, loss = 0.894748, acc = 0.987228
--- 6870.61988401413 seconds ---
batch_number = 140, loss = 0.892476, acc = 0.987233
--- 6878.923765182495 seconds ---
batch_number = 150, loss = 0.890776, acc = 0.987210
--- 6888.265328884125 seconds ---
batch_number = 160, loss = 0.884576, acc = 0.987282
[epoch 147]: train_loss = 0.112092, train_acc = 0.987382, validation_loss = 3.204197, validation_acc = 0.882915
--- 6905.91419172287 seconds ---
batch_number = 10, loss = 0.715978, acc = 0.989221
--- 6914.210356235504 seconds ---
batch_number = 20, loss = 0.832438, acc = 0.988514
--- 6922.934966802597 seconds ---
batch_number = 30, loss = 0.825936, acc = 0.988163
--- 6932.770530700684 seconds ---
batch_number = 40, loss = 0.835538, acc = 0.988312
--- 6941.400500535965 seconds ---
batch_number = 50, loss = 0.838363, acc = 0.988481
--- 6948.502660751343 seconds ---
batch_number = 60, loss = 0.852776, acc = 0.988534
--- 6957.615618228912 seconds ---
batch_number = 70, loss = 0.850724, acc = 0.988754
--- 6965.958205461502 seconds ---
batch_number = 80, loss = 0.860842, acc = 0.988680
--- 6975.618865966797 seconds ---
batch_number = 90, loss = 0.852582, acc = 0.988750
--- 6984.779069900513 seconds ---
batch_number = 100, loss = 0.851099, acc = 0.988701
--- 6994.292843580246 seconds ---
batch_number = 110, loss = 0.853704, acc = 0.988713
--- 7004.091711997986 seconds ---
batch_number = 120, loss = 0.851146, acc = 0.988698
--- 7013.412844419479 seconds ---
batch_number = 130, loss = 0.851499, acc = 0.988599
--- 7021.799268484116 seconds ---
batch_number = 140, loss = 0.858115, acc = 0.988426
--- 7029.63720035553 seconds ---
batch_number = 150, loss = 0.865010, acc = 0.988301
--- 7036.908162355423 seconds ---
batch_number = 160, loss = 0.868372, acc = 0.988157
[epoch 148]: train_loss = 0.110743, train_acc = 0.988067, validation_loss = 3.266872, validation_acc = 0.877786
--- 7053.761839866638 seconds ---
batch_number = 10, loss = 0.785788, acc = 0.988351
--- 7063.1905126571655 seconds ---
batch_number = 20, loss = 0.807957, acc = 0.988043
--- 7072.395973682404 seconds ---
batch_number = 30, loss = 0.811272, acc = 0.987822
--- 7081.134907007217 seconds ---
batch_number = 40, loss = 0.830097, acc = 0.987569
--- 7090.728106498718 seconds ---
batch_number = 50, loss = 0.831065, acc = 0.987790
--- 7098.639578819275 seconds ---
batch_number = 60, loss = 0.839842, acc = 0.987888
--- 7106.274394035339 seconds ---
batch_number = 70, loss = 0.848467, acc = 0.987899
--- 7113.085173845291 seconds ---
batch_number = 80, loss = 0.860886, acc = 0.987873
--- 7121.795610427856 seconds ---
batch_number = 90, loss = 0.858967, acc = 0.988064
--- 7131.101567268372 seconds ---
batch_number = 100, loss = 0.852268, acc = 0.988097
--- 7139.0360469818115 seconds ---
batch_number = 110, loss = 0.853421, acc = 0.987997
--- 7146.93415760994 seconds ---
batch_number = 120, loss = 0.861984, acc = 0.988066
--- 7154.997280836105 seconds ---
batch_number = 130, loss = 0.861585, acc = 0.988027
--- 7164.136896371841 seconds ---
batch_number = 140, loss = 0.853640, acc = 0.988124
--- 7173.375885009766 seconds ---
batch_number = 150, loss = 0.851902, acc = 0.988144
--- 7182.558469772339 seconds ---
batch_number = 160, loss = 0.851209, acc = 0.988145
[epoch 149]: train_loss = 0.108066, train_acc = 0.988062, validation_loss = 3.284348, validation_acc = 0.880860
--- 7199.203229427338 seconds ---
batch_number = 10, loss = 0.787441, acc = 0.983639
--- 7208.352204084396 seconds ---
batch_number = 20, loss = 0.810389, acc = 0.986029
--- 7216.730829000473 seconds ---
batch_number = 30, loss = 0.850703, acc = 0.985981
--- 7224.6571888923645 seconds ---
batch_number = 40, loss = 0.852642, acc = 0.986391
--- 7233.781616926193 seconds ---
batch_number = 50, loss = 0.843648, acc = 0.986600
--- 7243.845809698105 seconds ---
batch_number = 60, loss = 0.841338, acc = 0.987313
--- 7254.202146053314 seconds ---
batch_number = 70, loss = 0.836818, acc = 0.987281
--- 7262.211601495743 seconds ---
batch_number = 80, loss = 0.882611, acc = 0.985534
--- 7270.556756973267 seconds ---
batch_number = 90, loss = 0.951169, acc = 0.983245
--- 7279.267469406128 seconds ---
batch_number = 100, loss = 0.986333, acc = 0.981296
--- 7287.519456863403 seconds ---
batch_number = 110, loss = 1.047823, acc = 0.978001
--- 7295.434536457062 seconds ---
batch_number = 120, loss = 1.071410, acc = 0.976712
--- 7303.423588752747 seconds ---
batch_number = 130, loss = 1.113961, acc = 0.975057
--- 7312.132026910782 seconds ---
batch_number = 140, loss = 1.134788, acc = 0.973866
--- 7320.455727338791 seconds ---
batch_number = 150, loss = 1.199953, acc = 0.970869
--- 7328.780106782913 seconds ---
batch_number = 160, loss = 1.246346, acc = 0.968626
[epoch 150]: train_loss = 0.160535, train_acc = 0.967946, validation_loss = 4.101783, validation_acc = 0.812034
